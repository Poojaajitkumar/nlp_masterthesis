{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pooja Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.image import ImageWriter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from pathlib import *\n",
    "\n",
    "import time\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import operator\n",
    "\n",
    "from nltk.chunk import tree2conlltags\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfRender():\n",
    "    global documentSet\n",
    "    global mydoc\n",
    "    mydoc ={}\n",
    "    pdf_files =[]\n",
    "    allLines =[]\n",
    "    FILE_PATH = Path(r'Final_LDA+KMeans')\n",
    "    #FILE_PATH = Path('E:/MasterThesis/FinalPapers')\n",
    "    pdf_files = list(FILE_PATH.glob('*.pdf'))\n",
    "    #An Array which stores the full text of each document\n",
    "    documentSet = pdfparser(pdf_files)\n",
    "    mydoc = dict(zip(pdf_files,documentSet))\n",
    "    #print(len(documentSet))\n",
    "    return documentSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(rawContents):    \n",
    "    cleaned = tokenizeContent(rawContents)    \n",
    "    cleaned1 = removeStopWordsFromTokenized(cleaned)    \n",
    "    cleaned2 = performPorterStemmingOnContents(cleaned1)    \n",
    "    cleaned3 = removePunctuationFromTokenized(cleaned2)    \n",
    "    cleaned4 = convertItemsToLower(cleaned3)    \n",
    "    return cleaned4    \n",
    "        \n",
    "def tokenizeContent(contentsRaw):    \n",
    "    tokenized = nltk.tokenize.sent_tokenize(contentsRaw)    \n",
    "    return tokenized    \n",
    "    \n",
    "def removeStopWordsFromTokenized(contentsTokenized):    \n",
    "    stop_word_set = set(nltk.corpus.stopwords.words(\"english\"))    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in stop_word_set]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def performPorterStemmingOnContents(contentsTokenized):    \n",
    "    porterStemmer = nltk.stem.PorterStemmer()    \n",
    "    filteredContents = [porterStemmer.stem(word) for word in contentsTokenized]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def removePunctuationFromTokenized(contentsTokenized):    \n",
    "    excludePuncuation = set(string.punctuation)    \n",
    "    \n",
    "    # manually add additional punctuation to remove    \n",
    "    doubleSingleQuote = '\\'\\''    \n",
    "    doubleDash = '--'    \n",
    "    doubleTick = '``'    \n",
    "    \n",
    "    excludePuncuation.add(doubleSingleQuote)    \n",
    "    excludePuncuation.add(doubleDash)    \n",
    "    excludePuncuation.add(doubleTick)    \n",
    "    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in excludePuncuation]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def convertItemsToLower(contentsRaw):    \n",
    "    filteredContents = [term.lower() for term in contentsRaw]    \n",
    "    return filteredContents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global fileName\n",
    "def pdfparser(pdffileS):\n",
    "    global finalDocumentSet\n",
    "    finalDocumentSet = []\n",
    "    global pdfEx\n",
    "    pdfEx = []\n",
    "    global files\n",
    "    global fullText\n",
    "    files = []\n",
    "    fileName = []\n",
    "    for pdffile in pdffileS:\n",
    "        #full= fullText\n",
    "        # Create a example words list(Please add all the related keywords needed)\n",
    "        words_list = [\"Introduction\", \"INTRODUCTION\", \"Background\", \"BACKGROUND\", \"Conclusion\", \"Conclusions\",\n",
    "                      \"CONCLUSION\", \"Acknowledgements\"]\n",
    "        #print(words_list)\n",
    "        pdfName = os.path.basename(pdffile)\n",
    "        files.append(pdfName)\n",
    "        fileName.append(pdfName)\n",
    "        with open(pdffile, mode='rb') as f:\n",
    "            fullText = np.array([])\n",
    "            print(pdfName)\n",
    "            #files.append(pdfName)\n",
    "            #documents = fullText\n",
    "            #words_list = []\n",
    "            #print(words_list)\n",
    "            #fp = open(data, 'rb')\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            retstr = io.StringIO()\n",
    "            codec = 'utf-8'\n",
    "            laparams = LAParams()\n",
    "            data =[]\n",
    "            details_page = []\n",
    "            abstract = []\n",
    "            device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "            # Create a PDF interpreter object.\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            # Process each page contained in the document.\n",
    "            count = 0\n",
    "            for page in PDFPage.get_pages(f):\n",
    "                interpreter.process_page(page)\n",
    "                data = retstr.getvalue()\n",
    "                details_page.append(data)\n",
    "\n",
    "            #print(\"There are\", len(words_list), \"in the words list\")\n",
    "            stri = \" \"\n",
    "            details = stri.join(details_page)\n",
    "            words = details.split()\n",
    "            place = []\n",
    "            dummy_check = []\n",
    "            removed_words = []\n",
    "\n",
    "            print(words_list)\n",
    "            for c, a in enumerate(words):\n",
    "                for b in words_list:\n",
    "                    if b == a and b not in dummy_check:\n",
    "                        print(b, a)\n",
    "                        place.append(details.find(\"{}\".format(b)))\n",
    "                        dummy_check.append(b)\n",
    "                    #  place.append(words.index(a))\n",
    "                    elif b not in words:\n",
    "                        print(b)\n",
    "                        removed_words.append(b)\n",
    "                        words_list.remove(b)\n",
    "                        print(\"The word\", b, \"was not found in the pdf file\")\n",
    "\n",
    "            #print(list(zip(words_list, place)))\n",
    "            final_array = list(zip(words_list, place))\n",
    "            #final_array.sort()\n",
    "            final_array.sort(key=operator.itemgetter(1))\n",
    "            # print(\"Sorting the final array\")\n",
    "            #print(final_array)\n",
    "\n",
    "            # print(\"Extracting the relevant texts from pdf\")\n",
    "            # print(\" \")\n",
    "            print(final_array)\n",
    "            if len(final_array) > 1:\n",
    "                listint = final_array[0]\n",
    "                list2int = final_array[1]\n",
    "                counter = 0\n",
    "\n",
    "                for each in (final_array):\n",
    "                    if counter < len(final_array) - 2:\n",
    "                        new = (details.split(listint[0])[1].split(list2int[0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #print(listint[0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        #print(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        counter = counter + 1\n",
    "                        listint = final_array[0 + counter]\n",
    "                        list2int = final_array[1 + counter]\n",
    "\n",
    "                    elif counter < len(final_array) - 1:\n",
    "                        new = (details.split(final_array[counter][0])[1].split(final_array[counter + 1][0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        counter = counter + 1\n",
    "\n",
    "                    else:\n",
    "                        new = (details.split(final_array[counter][0])[1])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "            else:\n",
    "                new = (details.split(final_array[0][0])[1])\n",
    "                # new = sent_tokenize(new)\n",
    "                #documents.append(new)\n",
    "                fullText = np.append(fullText, new)\n",
    "                # print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                # print(\" \")\n",
    "                \n",
    "        #finalDocumentSet = {pdfName : fullText}\n",
    "        \n",
    "        data=finalDocumentSet.append(fullText)\n",
    "        myName=pdfEx.append(pdfName)\n",
    "        #print(\"Testing==\",finalDocumentSet)\n",
    "        #data = finalDocumentSet.get(pdfName)\n",
    "        #finalDocumentSet = finalDocumentSet\n",
    "        data = str(data)\n",
    "        \n",
    "        data = processData(data)\n",
    "        #data = data.replace(r'\\\\n', \"\")\n",
    "        data = [i.replace('\\\\n', \"\") for i in data]\n",
    "        data = [i.replace('\\\\x0', \"\") for i in data]\n",
    "        words_list = words_list + removed_words\n",
    "        print(\"Updated words list:\")\n",
    "        print(words_list)\n",
    "\n",
    "    #print(len(finalDocumentSet))\n",
    "    \n",
    "    #mydoc = dict(zip(myName,data))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1002@asi.23250.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1649), ('Conclusion', 10356)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "A-systematic-literature-review-of-actionable-alert-identification-techniques-for-automated-static-code-analysis2011Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Acknowledgements Acknowledgements\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2948), ('Acknowledgements', 22793), ('Conclusions', 23242)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "A-systematic-literature-review-on-opinion-types-and-sentiment-analysis-techniques-Tasks-and-challenges2017Internet-Research.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 7026), ('Conclusion', 449265)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "Are-decision-trees-a-feasible-knowledge-representation-to-guide-extraction-of-critical-information-from-randomized-controlled-trial-reports2008BMC-Medical-Informatics-and-Decision-MakingOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 1059), ('Conclusion', 2672), ('Background', 3023), ('Acknowledgements', 379850)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'CONCLUSION']\n",
      "Clinical-case-in-digital-technology-for-nursing-students-learning-An-integrative-review2016Nurse-Education-Today.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2419), ('Conclusions', 117165)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "Entity-reconciliation-in-big-data-sources-A-systematic-mapping-study2017Expert-Systems-with-Applications.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2614), ('Conclusions', 352569)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "Factors-influencing-unsafe-behaviors-and-accidents-on-construction-sites-A-review2014International-Journal-of-Occupational-Safety-and-Ergonomics.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "INTRODUCTION INTRODUCTION\n",
      "CONCLUSION CONCLUSION\n",
      "Introduction Introduction\n",
      "[('Introduction', 4457), ('INTRODUCTION', 190672), ('CONCLUSION', 229725)]\n",
      "Updated words list:\n",
      "['Introduction', 'INTRODUCTION', 'CONCLUSION', 'Background', 'Conclusion', 'Acknowledgements', 'BACKGROUND', 'Conclusions']\n",
      "Faster-title-and-abstract-screening-Evaluating-Abstrackr-a-semiautomated-online-screening-program-for-systematic-reviewers2015Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 291), ('Conclusions', 2551), ('Acknowledgements', 93629)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "hassler2016.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "[('Introduction', 829)]\n",
      "Updated words list:\n",
      "['Introduction', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION', 'Conclusion']\n",
      "hassler2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 2844), ('Background', 10859), ('Conclusion', 683784)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "Identification-and-prioritization-of-SLR-search-tool-requirements-an-SLR-and-a-survey2019Empirical-Software-Engineering.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusions Conclusions\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1756), ('Conclusions', 1756), ('Conclusion', 4512)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements']\n",
      "idri2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 4871), ('Conclusion', 6855), ('Background', 12026)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "Knowledgebased-approaches-in-software-documentation-A-systematic-literature-review2014Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Acknowledgements Acknowledgements\n",
      "Conclusions Conclusions\n",
      "[('Acknowledgements', 2388), ('Introduction', 3425), ('Conclusions', 16037)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "kosar2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 1737), ('Conclusion', 300281), ('Conclusions', 301196)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements']\n",
      "lanera2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "[('Introduction', 2282)]\n",
      "Updated words list:\n",
      "['Introduction', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION', 'Conclusion']\n",
      "langlois2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusion Conclusion\n",
      "[('Conclusion', 414920)]\n",
      "Updated words list:\n",
      "['Conclusion', 'Introduction', 'Background', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'CONCLUSION', 'BACKGROUND']\n",
      "loureiro2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 1736), ('Conclusions', 479238)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "mahood2013.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 1767), ('Background', 8490), ('Conclusion', 249784), ('Acknowledgements', 399758)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'CONCLUSION']\n",
      "Monitoring-twitter-conversations-for-targeted-recruitment-in-cancer-trials-in-los-angeles-county-Protocol-for-a-mixedmethods-pilot-study2018Journal-of-Medical-Internet-ResearchOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "[('Introduction', 490)]\n",
      "Updated words list:\n",
      "['Introduction', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION', 'Conclusion']\n",
      "mortensen2017.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "BACKGROUND BACKGROUND\n",
      "[('BACKGROUND', 2256)]\n",
      "Updated words list:\n",
      "['BACKGROUND', 'Introduction', 'Background', 'Conclusion', 'CONCLUSION', 'INTRODUCTION', 'Conclusions', 'Acknowledgements']\n",
      "olofsson2017.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Background Background\n",
      "BACKGROUND BACKGROUND\n",
      "CONCLUSION CONCLUSION\n",
      "[('Background', 654), ('BACKGROUND', 1866), ('CONCLUSION', 89245)]\n",
      "Updated words list:\n",
      "['Background', 'BACKGROUND', 'CONCLUSION', 'Introduction', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'Conclusions']\n",
      "Online-knowledge-sharing-mechanisms-a-systematic-review-of-the-state-of-the-art-literature-and-recommendations-for-future-research2016Information-Systems-Frontiers.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1780), ('Conclusion', 291992)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "paton2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 1740), ('Conclusions', 260863)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "Process-mining-through-artificial-neural-networks-and-support-vector-machines-A-systematic-literature-review2015Business-Process-Management-Journal.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 2434), ('Conclusion', 807344)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "Reproducibility-of-studies-on-text-mining-for-citation-screening-in-systematic-reviews-Evaluation-and-checklist2017Journal-of-Biomedical-Informatics.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "[('Introduction', 2988), ('Background', 16054)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Conclusion', 'CONCLUSION']\n",
      "Research-state-of-the-art-on-GoF-design-patterns-A-mapping-study2013Journal-of-Systems-and-Software.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 2775), ('Conclusions', 631578), ('Acknowledgements', 634736)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "Screening-nonrandomized-studies-for-medical-systematic-reviews-A-comparative-study-of-classifiers2012Artificial-Intelligence-in-Medicine.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "[('Conclusion', 3170), ('Introduction', 4213), ('Acknowledgements', 326870)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Background', 'CONCLUSION']\n",
      "Securing-web-applications-from-injection-and-logic-vulnerabilities-Approaches-and-challenges2016Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2676), ('Background', 13930), ('Conclusions', 961702)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Conclusion', 'Acknowledgements']\n",
      "Semiautomated-screening-of-biomedical-citations-for-systematic-reviews2010BMC-BioinformaticsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 299), ('Conclusions', 1890), ('Acknowledgements', 251668)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "sharma2017.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusions Conclusions\n",
      "[('Introduction', 2085), ('Conclusions', 427889)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "shemilt2013.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 2120), ('Acknowledgements', 703866)]\n",
      "Updated words list:\n",
      "['Introduction', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Background', 'CONCLUSION', 'Conclusion']\n",
      "Supporting-systematic-reviews-using-LDAbased-document-representations2015Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 346), ('Conclusions', 1710), ('Acknowledgements', 260371)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "Supporting-the-semiautomatic-semantic-annotation-of-web-services-A-systematic-literature-review2015Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Conclusion', 2070), ('Introduction', 2313), ('Background', 2541)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "Systematic-review-of-Kinect-applications-in-elderly-care-and-stroke-rehabilitation2014Journal-of-NeuroEngineering-and-RehabilitationOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 1840), ('Conclusions', 1077527), ('Acknowledgements', 1184851)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "Test-case-design-for-contextaware-applications-Are-we-there-yet2017Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Conclusion', 2632), ('Introduction', 3099), ('Background', 13617)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "The-artificial-neural-network-for-solar-radiation-prediction-and-designing-solar-systems-A-systematic-literature-review2015Journal-of-Cleaner-Production.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 2755), ('Conclusion', 358676)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "Use-of-costeffectiveness-analysis-to-compare-the-efficiency-of-study-identification-methods-in-systematic-reviews2016Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 310), ('Conclusions', 2460), ('Acknowledgements', 361990)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "Using-text-mining-for-study-identification-in-systematic-reviews-A-systematic-review-of-current-approaches2015Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "Introduction Introduction\n",
      "[('Introduction', 335), ('Background', 2158), ('Conclusion', 1073282), ('Acknowledgements', 1180821)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'CONCLUSION']\n",
      "yeom2019.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 13635), ('Conclusions', 794666)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['none']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalDocumentSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1002@asi.23250.pdf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the objectives for QA questions\n",
    "final_dataset_QA = {'fileName': [], 'content': [] }\n",
    "for a,b in zip(files, finalDocumentSet):    \n",
    "    final_dataset_QA['fileName'].append(a)\n",
    "    final_dataset_QA['content'].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the results to .xslx\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame(final_dataset_QA, columns= ['fileName', 'content'])\n",
    "export_excel = df.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\DataSet_QA_31.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract introduction, methods, conclusion portions of the paper\n",
    "extractedContent = []\n",
    "global keyword\n",
    "def extractIntroduction():\n",
    "    count = 0\n",
    "    for i in range(len(finalDocumentSet)):\n",
    "        doc = str(finalDocumentSet[i])\n",
    "        intro=re.search(\"|\".join([r'Background(.*?)Methods', r'2. Study objective(.*?)3. Methods', r'Introduction(.*?)Methods', r'Purpose(.*?)Methods', r'Introduction(.*?)Overview', r'Introduction(.*?)Method', r'Background(.*?)Main Text', r'Introduction(.*?)Methodology', r'Introduction(.*?) Related work', r'Context(.*?)Methods', r'Introduction(.*?)Methodology', r'Objectives(.*?)Methods', r'Introduction(.*?)Study Objective', r'Objective(.*?)Method', r'Introduction(.*?)Background' ]), str(doc)).group()           \n",
    "        print(\"Introduction is extracted successfully\")\n",
    "        extractedContent.append(intro) \n",
    "        return extractedContent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_content = []\n",
    "for i in range(len(finalDocumentSet)):\n",
    "    content = str(finalDocumentSet[i])\n",
    "    #Text pre-processing\n",
    "    content = content.lower()\n",
    "    content = re.sub(r'\\d+', '', content)\n",
    "    #data = re.sub(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+','', data)\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    #data = data.strip()\n",
    "    content = sent_tokenize(content)\n",
    "    other_content.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in f:\\python\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: numpy in f:\\python\\lib\\site-packages (from rank-bm25) (1.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens_questions(question):\n",
    "    tokenized_question = question.split()\n",
    "    create_chunks = nltk.ne_chunk(nltk.pos_tag(tokenized_question))\n",
    "    assign_pos_tags = tree2conlltags(create_chunks)\n",
    "    return assign_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos(question):\n",
    "    noun_add = []\n",
    "    assign_pos_tags = create_tokens_questions(question)\n",
    "    print(assign_pos_tags)\n",
    "    for i in range(0, len(assign_pos_tags) - 1):\n",
    "        if (assign_pos_tags[i][1] == 'NN' and assign_pos_tags[i + 1][1] == 'NN'):\n",
    "            extract_nouns = assign_pos_tags[i] + assign_pos_tags[i + 1]\n",
    "            noun_add.append(extract_nouns)\n",
    "        elif assign_pos_tags[i][1] == 'NNP':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "        elif assign_pos_tags[i][1] == 'NN':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "    return noun_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "introFinalData = []\n",
    "global keyword\n",
    "def extractIntroduction(inputDoc):\n",
    "    for j in range(len(inputDoc)):\n",
    "        question = \"what is the aim and objective of this paper?\"\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in inputDoc[j]]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        noun_add = extract_pos(question)\n",
    "        #print(noun_add)\n",
    "        get_final_results = bm25.get_top_n(noun_add, inputDoc[j], n=5)\n",
    "        introFinalData.append(get_final_results)\n",
    "        #print(get_final_results)\n",
    "    return introFinalData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherContent = []\n",
    "global keyword\n",
    "def extractMethods(inputDoc):\n",
    "    for j in range(len(inputDoc)):\n",
    "        question = \"what is the method used in this paper?\"\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in inputDoc[j]]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        noun_add = extract_pos(question)\n",
    "        #print(noun_add)\n",
    "        get_final_results = bm25.get_top_n(noun_add, inputDoc[j], n=10)\n",
    "        otherContent.append(get_final_results)\n",
    "        #print(get_final_results)\n",
    "    return otherContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclu = []\n",
    "global keyword\n",
    "def extractConclusion(inputDoc):\n",
    "    for j in range(len(inputDoc)):\n",
    "        question = \"what is the conclusion and discussion and justification of this paper?\"\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in inputDoc[j]]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        noun_add = extract_pos(question)\n",
    "        #print(noun_add)\n",
    "        get_final_results = bm25.get_top_n(noun_add, inputDoc[j], n=10)\n",
    "        Conclu.append(get_final_results)\n",
    "        #print(get_final_results)\n",
    "    return Conclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n"
     ]
    }
   ],
   "source": [
    "#To fetch the conclusion for each paper\n",
    "QA1 = extractIntroduction(other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['warner’s () differentiation between\\\\nthe computer science traditions and an older library-\\\\noriented tradition seems important; the former aim to\\\\ntransform queries automatically into (ranked) sets of\\\\nrelevant documents, whereas the latter aims to increase\\\\nthe “selection power” of users.',\n",
       "  'warner’s () differentiation between\\\\nthe computer science traditions and an older library-\\\\noriented tradition seems important; the former aim to\\\\ntransform queries automatically into (ranked) sets of\\\\nrelevant documents, whereas the latter aims to increase\\\\nthe “selection power” of users.',\n",
       "  \"this section also contains a subsection that pres-\\\\nents empirical studies on searching for systematic reviews.\\\\nin the ']\",\n",
       "  'the term information retrieval\\\\nwas introduced by mooers (–), who deﬁned it\\\\nthus:\\\\n\\\\ninformation retrieval is the name for the process or method\\\\nwhereby a prospective user of information is able to convert his\\\\nneed for information into an actual list of citations to documents\\\\nin storage containing information useful to him.',\n",
       "  'an\\\\nunderlying issue is the kind of retrieval system for which\\\\none should aim.',\n",
       "  'the boolean retrieval\\\\nmodel is valuable in providing users with the power to\\\\nmake informed searches and have full control over what\\\\nis found and what is not.',\n",
       "  \"these issues may have signiﬁ-\\\\ncant implications for the maintenance of information\\\\nscience and ko as research ﬁelds as well as for the\\\\ninformation profession as a profession in its own right.\\\\n\\\\n' ' it is claimed that not only searchers\\\\nbut also the entire ﬁeld of\\\\ninformation science may\\\\nsuffer if concepts such as “recall devices” and “precision\\\\ndevices” no longer have well-deﬁned meanings due to the\\\\nexistence of retrieval models without well-deﬁned matching\\\\ncriteria.\\\\n\\\\nthe field of information retrieval\\\\n\\\\nthe s saw the introduction of the computer into the\\\\nﬁeld of documentation together with the idea of informa-\\\\ntion storage and retrieval.\",\n",
       "  'this concept led some library\\\\nresearchers and documentalists to approach their ﬁeld\\\\nfrom a new theoretical perspective: libraries could be\\\\nunderstood as information-processing systems (and so\\\\ncould scientiﬁc and scholarly communication—journals,\\\\nconferences, informal communication, reviews, etc.).',\n",
       "  'the\\\\nconcept of information storage and retrieval gave rise to\\\\nthe ﬁeld of information science, considered by some a new\\\\nﬁeld, by others as just a new and better name for library\\\\nscience and documentation.',\n",
       "  'it is the ﬁnding\\\\nor discovery process with respect to stored information.'],\n",
       " [\"\\\\n']\", '.', '.', '.', '.', '.', '.', '.', '.', '.'],\n",
       " ['the research aim is to provide a rich resource for implicit and explicit\\\\nknowledge that is ordered in the human mind.',\n",
       "  'after defining our research goals and questions, we started with\\\\nthe formulation of a formal search strategy to analyze all available empirical materials\\\\nspecific to the objective of this review.',\n",
       "  'the main goal of sa is to extract\\\\nopinions about entities (such as products or services) in order to attain useful information.\\\\nmoreover, its purpose is to present the information in such a way that serves the objective of\\\\nboth customers and manufacturers.',\n",
       "  'the main goal of sa is to extract\\\\nopinions about entities (such as products or services) in order to attain useful information.\\\\nmoreover, its purpose is to present the information in such a way that serves the objective of\\\\nboth customers and manufacturers.',\n",
       "  'the aim is to understand how\\\\ntraditional classification technique issues can be addressed through the adoption of improved methods.\\\\ndesign/methodology/approach – a systematic review of literature was used to search published articles\\\\nbetween  and  and identified  papers that discuss regular, comparative, and suggestive reviews\\\\nand the related sa techniques.',\n",
       "  'the aim is to understand how\\\\ntraditional classification technique issues can be addressed through the adoption of improved methods.\\\\ndesign/methodology/approach – a systematic review of literature was used to search published articles\\\\nbetween  and  and identified  papers that discuss regular, comparative, and suggestive reviews\\\\nand the related sa techniques.',\n",
       "  'the valence of\\\\nconsumer reviews such as helpfulness, star rating and facial avatar plays an important role in\\\\npurchase decision making (lee et al., ).\\\\n\\\\nas the volume of information continues to increase on the internet, it becomes increasingly\\\\ndifficult and time consuming to make decisions about the purchase of products and services.\\\\nopinion and sa are techniques that aim to automate the analysis of information and thereby\\\\nsave the user time and effort.',\n",
       "  'we are motivated to\\\\nhighlight this gap between keyword-based approaches and common sense knowledge for\\\\nonline opinions used for sa related to multiple opinion types.',\n",
       "  'the purpose is to deepen the\\\\nanalysis of multiple opinion types, their benefits and how the issues raised from keyword-\\\\nbased approaches can be solved by common sense knowledge-based approaches.\\\\n\\\\nthis review paper is organized as follows: section  presents our research questions and\\\\nthe method followed for the review of opinion types and techniques used for sa and section \\\\nsummaries the key findings of our study.',\n",
       "  'our study\\\\nidentifies recent research issues in different types of opinions in order to determine knowledge\\\\ngaps and to highlight future challenges.\\\\n\\\\nthe existing om approaches mostly use keyword-based reasoning and rely on the vector\\\\nspace representation based on text features.'],\n",
       " ['table  reports\\\\nthe location of the sentence(s) describing assignment of\\\\nintervention at each arm within the structured abstracts in\\\\nr, with respect to the mapped heading class.\\\\n\\\\ntable : number of abstracts in each subcategory in a randomly selected corpus of  rct abstracts.\\\\n\\\\nclasses total\\\\n\\\\nr\\\\n\\\\nr\\\\n\\\\nr\\\\n\\\\nn\\\\n\\\\nn\\\\n\\\\nn\\\\n\\\\nsingle rct complex rct rct substudy\\\\n\\\\nsystematic review other study\\\\n\\\\nrct protocol or \\\\nannouncement\\\\n\\\\nn (%)\\\\n\\\\n\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\npage  of \\\\n(page number not for citation purposes)\\\\n\\\\n\\\\xcbmc medical informatics and decision making , :\\\\n\\\\nhttp://www.biomedcentral.com/-//\\\\n\\\\ntable : the number of unstructured and structured abstracts in group a, the original set of abstracts and group r, the primary \\\\nrct reports from the randomly selected subset.\\\\n\\\\nnumber of abstracts in a\\\\n\\\\nnumber of abstracts in r\\\\n\\\\ntotal abstracts\\\\n\\\\nunstructured abstracts\\\\n\\\\nstructured abstracts\\\\n\\\\nstructured abstracts with explicit heading for intervention\\\\n\\\\nstructured abstracts with explicit heading for population\\\\n\\\\nstructured abstracts with explicit heading for outcome measures\\\\n\\\\nstructured abstracts with explicit heading for all three subheadings\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\nthe  intervention  was  described  in  the  method  section\\\\n(%), in aim (.%), design (.%) or results (.%).\\\\nwhen  there  is  no  method  section,  %  of  intervention\\\\nsentences  appear  in  the  aim  and  %  in  design.',\n",
       "  'the actual interven-\\\\ntion procedure might be described further in the abstract\\\\n\\\\ntable : examples of equivalence classes of pre-defined sub-headings in structured abstracts.\\\\n\\\\nclass\\\\n\\\\naim\\\\n\\\\nsetting\\\\n\\\\nexample heading names\\\\n\\\\ngoal, aim of the study, purpose\\\\n\\\\nsetting, study setting, settings and location\\\\n\\\\nparticipants\\\\n\\\\nstudy population, type of participants, patients or participants, sample\\\\n\\\\noutcome measure\\\\n\\\\nmeasurements, primary outcome measure, study endpoints, major outcome measures\\\\n\\\\npage  of \\\\n(page number not for citation purposes)\\\\n\\\\n\\\\xcbmc medical informatics and decision making , :\\\\n\\\\nhttp://www.biomedcentral.com/-//\\\\n\\\\ntable : examples of the patterns that occur in the section headings of structured rct abstracts of group a.\\\\n\\\\nstructure of abstracts\\\\n\\\\n% of corpus\\\\n\\\\nbackground, method, result conclusion\\\\n\\\\naim, method, result, conclusion\\\\n\\\\naim, patient and method, result, conclusion\\\\n\\\\nbackground, aim, method, result, conclusion\\\\n\\\\nbackground, method and results, conclusion\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n.\\\\n\\\\n.\\\\n\\\\n.\\\\n\\\\n< \\\\n\\\\n< \\\\n\\\\n< \\\\n\\\\naim, participants, design, measurements, result conclusion\\\\n\\\\ncontext, design, setting, participants, outcome measures, result, conclusion\\\\n\\\\naim, design and setting, participants, intervention, measurements and main results, conclusion\\\\n\\\\nor  elsewhere,  possibly  only  in  the  article  because  these\\\\ninterventions can be quite complex to describe in full in\\\\nthe abstract e.g.',\n",
       "  '% of these primary rct abstracts were structured.',\n",
       "  'an exploratory\\\\nanalysis of rct abstracts is undertaken to investigate the feasibility of using decision trees as a\\\\nsemantic structure.',\n",
       "  'quality-of-paper measures are also examined.\\\\nmethods: a subset of  abstracts (randomly selected from a set of  retrieved from medline\\\\nfrom  – ) are examined for the quality of rct reporting, the identifiability of rcts from\\\\nabstracts, and the completeness and complexity of rct abstracts with respect to key decision tree\\\\nelements.',\n",
       "  'abstracts  were  manually  assigned  to    sub-groups  distinguishing  whether  they  were\\\\nprimary rcts versus other design types.',\n",
       "  'for primary rct studies, we analyzed and annotated the\\\\nreporting  of  intervention  comparison,  population  assignment  and  outcome  values.',\n",
       "  'to  measure\\\\ncompleteness,  the  frequencies  by  which  complete  intervention,  population  and  outcome\\\\ninformation are reported in abstracts were measured.',\n",
       "  'a qualitative examination of the reporting\\\\nlanguage was conducted.\\\\nresults: decision tree elements are manually identifiable in the majority of primary rct abstracts.\\\\n.% of a random subset was primary studies with a single population assigned to two or more\\\\ninterventions.',\n",
       "  '% contained pharmaceutical\\\\ninterventions.'],\n",
       " [\"the content\\\\nof this instrument was: identiﬁcation data, aim and type of research\\\\nquestion, methodology, main outcomes, analysis of cognitive, procedural\\\\nand attitudinal learning, use of technology resources, general features of\\\\nthe case study and conclusions.\\\\n\\\\ninstrument validation occurred according to its appearance and\\\\ncontent by six registered nurses with age between  and  years —\\\\nﬁve professors acting in nursing education and research ﬁeld for more\\\\nthan  years, and one registered nurse doctoral student with history\\\\nof intensive course training and experience on research methods.\\\\n\\\\nexperts' recommendations resulted in inclusion of items to evidence\\\\ngreater wealth of information to achieve the research objectives and\\\\nwere consider as relevant by the researchers.\\\\n\\\\ntwo reviewers accomplished all stages of this study independently\\\\nsince search stage until the completion of the instrument described\\\\nabove.\",\n",
       "  'it reinforces\\\\nthe range of possibilities that case studies inserted in digital technolo-\\\\ngies can provide for nursing education.\\\\n\\\\n\"]',\n",
       "  '(),\\\\n–.',\n",
       "  '(), –.\\\\n\\\\nduarte, a.p.p., ellensohn, l., .',\n",
       "  'acta paul\\\\nenferm.',\n",
       "  'proposta educacional on-\\\\nline sobre úlcera por pressão para alunos e proﬁssionais de enfermagem.',\n",
       "  'f. tese\\\\n(doutorado) universidade federal do rio grande do sul, porto alegre.\\\\n\\\\ncosta, j.b., peres, h.h.c., rogenski, n.m.b., baptista, c.m.c., .',\n",
       "  'construção coletiva do conhecimento em ambiente virtual:\\\\naprendizagem da anamnese e do exame físico de enfermagem.',\n",
       "  '(), – set.\\\\n\\\\ncogo, a.l.p., .',\n",
       "  'gaúcha enferm.'],\n",
       " ['they represent a great variety of intelligent proposals that aim to \\\\nsolve er.',\n",
       "  'they represent a great variety of intelligent proposals that aim to \\\\nsolve er.',\n",
       "  '\\\\n\\\\nthe objective of this sms is to identify what has been already \\\\ndone and what must be done in the future in the context of er \\\\nin big data sources.',\n",
       "  '() present an overview of research on \\\\ndata deduplication with the aim to provide a general assessment \\\\nof  useful  references  and  ideas  on  this  topic.',\n",
       "  '\\\\n\\\\n... formulating research questions \\\\n\\\\nfulﬁlling  the  objective  of  understanding  the  existing  research \\\\nproposals  within  er  problem  in  big  data  sources,  it  was  neces- \\\\nsary  to  formulate  some  research  questions  (rq).',\n",
       "  '\\\\nsmss ( genero, cruz-lemus, & piattini,  ) are secondary studies \\\\nwith a broader scope than slrs that aim to provide an overview of \\\\nan interesting topic and identify the number and type of research \\\\nas well as the available related results.',\n",
       "  '\\\\nas this selection was known to be relevant for the quality of re- \\\\nsults, general terms have been used with the aim of conﬁrming \\\\nthat  most  of  the  research  papers  are  included  in  the  study.',\n",
       "  '\\\\n\\\\nlibrary \\\\n\\\\nacm \\\\nieee \\\\nscopus \\\\nwok \\\\n\\\\ntotal \\\\n\\\\npercentage \\\\n\\\\n .% \\\\n .% \\\\n .% \\\\n .% \\\\n\\\\nstandable when researchers aim to provide their proposals with a \\\\ncertain level of quality, and just a few studies show a validation \\\\n+\\\\nwith synthetic datasets and real-world \\\\n\\\\n synthetic datasets.',\n",
       "  '\\\\n\\\\nrq asked: “what methods, techniques or tools have been in- \\\\nvestigated  for  er  in  the  big  data  environment?” following  uni- \\\\nﬁed  modeling  language  (uml)  speciﬁcation  ( group,   )  that \\\\nclassiﬁes diagrams in two categories: (i) structure-based diagrams, \\\\nwhich show the static structure of the system and its parts on dif- \\\\nferent abstraction and implementation levels and how they are re- \\\\nlated to each other, (ii) and behavior-based diagrams, which show \\\\nthe dynamic behavior of the objects in a system extrapolating it \\\\nto our problem, we have organized the selected primary studies \\\\nin  two  big  groups  with  the  aim  of  ﬁnding  out  what  methods, \\\\ntechniques  or  tools  have  been  investigated:  (i)  structural-based \\\\nand algorithmic-based solutions, understanding structural-based as \\\\nthose studies that propose a solution supported by data structures, \\\\n(ii) and algorithmic-based solutions, which refer to those studies \\\\nin which the solution comes from applying an algorithm.',\n",
       "  'method \\\\n\\\\nthe  method  proposed  by  kitchenham  and  charters  ( ) \\\\nis  one  of  the  most  widely  accepted  in  the  ﬁeld  of  soft- \\\\nware  engineering  although  it  has  received  some  critics  and \\\\n\\\\n\\\\xc \\\\n\\\\nj.g.'],\n",
       " ['the aim of this methodological and theoretical review is to explore \\\\nthe empirical factors influencing unsafe behaviors and accidents on construction sites.',\n",
       "  'the aim of this methodological and theoretical review is to explore \\\\nthe empirical factors influencing unsafe behaviors and accidents on construction sites.',\n",
       "  'the aim of this methodological and theoretical review is to explore \\\\nthe empirical factors influencing unsafe behaviors and accidents on construction sites.',\n",
       "  'the  aim  of  this  study  is  to  (a) \\\\nexplore the empirical factors influencing unsafe \\\\nbehaviors and accidents on construction sites, (b) \\\\nperform content analysis of previous studies to \\\\ncategorize  such  influencing  factors,  and  (c) \\\\nreview the quality of previous studies to evaluate \\\\nthe strength of evidence provided in each study.\\\\n\\\\n.',\n",
       "  'however, further \\\\nresearch should be conducted to determine which \\\\nfactors consistently cause unsafe behaviors and \\\\naccidents and to define the influence mechanism \\\\nof distal factors on proximal factors.',\n",
       "  '\\\\n\\\\n\\\\xc international journal of occupational safety and\\\\nergonomics\\\\n\\\\nissn: - (print) - (online) journal homepage: https://www.tandfonline.com/loi/tose\\\\n\\\\nfactors influencing unsafe behaviors and\\\\naccidents on construction sites: a review\\\\n\\\\nyahya khosravi, hassan asilian-mahabadi, ebrahim hajizadeh, narmin\\\\nhassanzadeh-rangi, hamid bastani & amir h. behzadan\\\\n\\\\nto cite this article: yahya khosravi, hassan asilian-mahabadi, ebrahim hajizadeh, narmin\\\\nhassanzadeh-rangi, hamid bastani & amir h. behzadan () factors influencing unsafe\\\\nbehaviors and accidents on construction sites: a review, international journal of occupational\\\\nsafety and ergonomics, :, -, doi: ./..\\\\nto link to this article:  https://doi.org/./..\\\\n\\\\npublished online:  jan .\\\\n\\\\nsubmit your article to this journal \\\\n\\\\narticle views: \\\\n\\\\nview related articles \\\\n\\\\nview crossmark data\\\\n\\\\nciting articles:  view citing articles \\\\n\\\\nfull terms & conditions of access and use can be found at\\\\n\\\\nhttps://www.tandfonline.com/action/journalinformation?journalcode=tose\\\\n\\\\n\\\\xcinternational journal of occupational safety and ergonomics (jose) , vol.',\n",
       "  ', no.',\n",
       "  ', –\\\\n\\\\nfactors influencing unsafe behaviors and \\\\naccidents on construction sites: a review\\\\n\\\\nfaculty of medical sciences, tarbiat modares university, tehran, iran\\\\n\\\\nyahya khosravi \\\\n\\\\nhassan asilian-mahabadi \\\\n\\\\nebrahim hajizadeh\\\\n\\\\nnarmin hassanzadeh-rangi\\\\n\\\\noccupational health research center (ohrc), iran university of medical sciences, tehran, iran\\\\n\\\\nhealth, safety and environment management, mapna group co., tehran, iran\\\\n\\\\nhamid bastani\\\\n\\\\namir h. behzadan\\\\n\\\\norlando, usa\\\\n\\\\ndepartment of civil, environmental, and construction engineering, university of central florida, \\\\n\\\\nobjective.',\n",
       "  'construction is a hazardous occupation due to the unique nature of activities involved and the \\\\nrepetitiveness of several field behaviors.',\n",
       "  'methods.'],\n",
       " ['the aim of this\\\\nstudy was to evaluate the performance of the abstrackr\\\\nalgorithm.',\n",
       "  'pattern recogni-\\\\ntion algorithms aim to provide the most likely matching\\\\nof the inputs, taking into account their statistical variation.\\\\nthey have been applied in a variety of ways in evidence-\\\\nbased medicine to expedite tasks that would otherwise be\\\\nomitted due to the time and cost involved if they were\\\\nperformed manually.',\n",
       "  \"th and pg contributed to the manuscript and all the revisions.\\\\nall authors read and approved the final manuscript.\\\\n\\\\n']\",\n",
       "  'this is an open access article distributed under the terms of the creative commons attribution\\\\nlicense (http://creativecommons.org/licenses/by/.',\n",
       "  'systematic reviews have also be-\\\\ncome more time consuming due to the growth in the\\\\nvolume and scatter of randomised trials [], additional\\\\nreporting steps [–], and the incorporation of more\\\\ncomplex methodologies such as network meta-analysis\\\\nand the acquisition of clinical study reports [].',\n",
       "  'this produces imprecise search results; some-\\\\ntimes less than  % of studies screened are included in a\\\\nsystematic review [, ].',\n",
       "  'the large number of citations re-\\\\ntrieved is partly due to the inadequate coding of studies\\\\nindexed in biomedical databases such as medline and\\\\n\\\\n* correspondence: jrathbon@bond.edu.au\\\\ncentre for research in evidence-based practice, bond university, gold coast,\\\\naustralia\\\\n\\\\nembase.',\n",
       "  'typically, this involves a team of reviewers\\\\ninspecting thousands of records that are produced from\\\\ndatabase searches.',\n",
       "  '%) and increased the number of missed citations.\\\\nconclusions: semi-automated title and abstract screening with abstrackr has the potential to save time and\\\\nreduce research waste.\\\\n\\\\nbackground\\\\nsystematic reviews require a comprehensive search and\\\\nappraisal of the literature to identify all relevant studies\\\\nfor inclusion.',\n",
       "  'sensitivity analysis performed with the larger echo dataset increased the workload saving ( %)\\\\nbut reduced the precision (.'],\n",
       " [\"while rq examines the\\\\noverall priority, it is quite likely that novice slr authors will\\\\n\\\\n\\\\xc information and software technology  () –\\\\n\\\\ncontents lists available at sciencedirect\\\\n\\\\ninformation and software technology\\\\n\\\\njournal homepage: www.elsevier.com/locate/infsof\\\\n\\\\nidentiﬁcation of slr tool needs – results of a community workshop\\\\nedgar hassler a, jeffrey c. carver b,∗\\\\n\\\\n, david hale a, ahmed al-zubidy b\\\\n\\\\na department of information systems, statistics, and management sciences, the university of alabama, tuscaloosa, al , united states\\\\nb department of computer science, the university of alabama, tuscaloosa, al , united states\\\\n\\\\na r t i c l e\\\\n\\\\ni n f o\\\\n\\\\na b s t r a c t\\\\n\\\\narticle history:\\\\nreceived  september \\\\nrevised  october \\\\naccepted  october \\\\navailable online  october \\\\n\\\\nkeywords:\\\\nsystematic literature review\\\\ncommunity workshops\\\\nresearch infrastructure\\\\ntool features\\\\n\\\\n. ']\",\n",
       "  'therefore, to help focus develop-\\\\nment efforts of tool builders, it is important to prioritize those\\\\nfeatures.\\\\n\\\\nrq: does the experience level of the slr author affect the de-\\\\nvelopment priority of the features?',\n",
       "  'objective:the goal of this work was to consult the software engineering\\\\nresearchers who conduct slrs to identify and prioritize the necessary slr tool features.',\n",
       "  'method: to gather\\\\ninformation required to address this goal, we invited slr authors to participate in an interactive  h workshop\\\\nstructured around the nominal group technique.',\n",
       "  'results: the workshop outcomes indicated that search &\\\\nselection and collaboration are the two highest priority tool features.',\n",
       "  'the results also showed that most of\\\\nthe high-priority features are not well-supported in current tools.',\n",
       "  'conclusion: these results support and\\\\nextend the results of prior work.',\n",
       "  'slr tool authors can use these ﬁndings to guide future development efforts.\\\\n\\\\n©  elsevier b.v. all rights reserved.\\\\n\\\\nthe systematic literature review (slr) process is a formal, re-\\\\npeatable, documented process for identifying, evaluating, and ana-\\\\nlyzing the literature relevant to a speciﬁc topic or question [].',\n",
       "  'with\\\\nthe increase in frequency of various type of empirical studies in soft-\\\\nware engineering (se), slrs are becoming increasingly important\\\\nas a method to systematically gather and analyze the results from\\\\nthese studies.',\n",
       "  'a  mapping study identiﬁed  slrs published\\\\nin the se literature [] between  and .'],\n",
       " ['the monte-carlo method\\\\nwas chosen over the k-fold technique to meet the research objective of\\\\nidentifying algorithms that reduce the number of corpus studies that\\\\nmust be manually reviewed (thus improving researcher eﬃciency).\\\\nusing the k-fold technique, the majority of corpus studies (k- folds)\\\\nwould be included in the training set, all of which must be manually\\\\nreviewed, thus minimizing the use and eﬃciency beneﬁt of the algo-\\\\nrithm.',\n",
       "  \"the potential bias was minimized by expert\\\\nreview of the protocol, review of the sms publication selection by two\\\\nindependent researchers, followed by conducting a test/retest sample.\\\\nhowever, one must cognizant of the risk regardless.\\\\n\\\\n. ']\",\n",
       "  'this process was found to\\\\nsigniﬁcantly improve recall, but not precision.\\\\n\\\\n... document clustering techniques\\\\n\\\\ndocument clustering techniques [,] group sets of documents\\\\nbased on the similarity of topics covered and are used for improving\\\\ninformation retrieval eﬀectiveness, organizing search results, and\\\\ncreating document taxonomies.',\n",
       "  'each bag of words representation is then translated\\\\ninto an n-dimensional vector in which each cell in the vector equates to\\\\nthe frequency count of a term used in the document.',\n",
       "  'the vector space\\\\nmodel (vsm) represents a common algorithm basis for processing,\\\\ncomparing, and visualizing the document vector.',\n",
       "  'vsm is proposed here\\\\nas an automated study selection / classiﬁer algorithm, and is further\\\\ndiscussed in section ..\\\\n\\\\nhierarchical models [] produce a tree of document clusters (a\\\\ndendrogram), with a single, all-inclusive cluster at the top, intermediate\\\\nclusters underneath, and individual singleton clusters at the bottom.\\\\nthe resulting dendrogram provides a corpus taxonomy or hierarchical\\\\nindex.\\\\n\\\\npartitional models (including vsm) build un-nested, single-level\\\\nclusters of related studies [].',\n",
       "  'one common clustering method is the\\\\nk-means algorithm, in which a centroid is calculated representing the\\\\nmean or median point of a study cluster.',\n",
       "  'from this, the primary\\\\ndocument topic(s) are determined, which must be assigned meaning by\\\\nthe researcher.',\n",
       "  'document clustering allows the researchers to focus on\\\\nthe core set of primary topics and reduces distractions from irrelevant\\\\nterms.\\\\n\\\\n... visual text mining\\\\n\\\\nvisual text mining (vtm) is emerging as a popular and eﬀective\\\\ntechnique to support slrs [], building on and supporting the natural\\\\nhuman power of visual information processing.',\n",
       "  'vtm combines text\\\\nmining methods (extracting patterns and knowledge from unstructured\\\\ntextual data) and data visualization tools (such as maps and graphs) to\\\\nsupport interactive data exploration.'],\n",
       " [\"we also describe the tools currently\\\\nused by slr researchers.\\\\n']\",\n",
       "  'these barriers\\\\nresult from limitations in digital library search facilities, lack of complete tool support,\\\\nand limited infrastructure to support se slrs (hassler et al.',\n",
       "  'when performing\\\\nslrs, se researchers face more barriers than medical researchers because the medical\\\\nfield is more mature with respect to slrs and has better infrastructure and digital library\\\\nsupport (kitchenham et al.',\n",
       "  ').',\n",
       "  'problems\\\\nthat occur during search have implications throughout the slr process (kitchenham and\\\\ncharters ).\\\\n\\\\nse researchers tend to follow a similar slr process as used in other fields, i.e.\\\\ndevelop research questions, identify key words, and systematically search relevant dig-\\\\nital libraries for potentially relevant studies (tranfield et al.',\n",
       "  'in this paper, we focus specifically\\\\non the search phase because it is critical to the success of the systematic study.',\n",
       "  'conversely, the goal\\\\nof the selection phase is to assess the studies identified during the search phase to identify\\\\nthose that provide evidence about the research questions.',\n",
       "  'the rigor of the search process is one of the key factors that\\\\ndifferentiates a systematic review from other types of literature reviews.',\n",
       "  'the goal of the\\\\nsearch phase is to use an unbiased search process, driven by the research questions, to find\\\\nas many studies as possible.',\n",
       "  'differentiate the search phase from the selection phase.'],\n",
       " ['the objective of this paper is to review the use of preprocessing techniques in clinical datasets.',\n",
       "  'the objective of this paper is to review the use of preprocessing techniques in clinical datasets.',\n",
       "  'data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for dm techniques.',\n",
       "  'please\\\\nnote that during the production process errors may be discovered which could affect the content, and\\\\nall legal disclaimers that apply to the journal pertain.\\\\n\\\\n \\\\xcaccepted manuscriptaccepted manuscripthighlights \\\\ufb perform a systematic map of  studies on the application of data preprocessing in healthcare.',\n",
       "  '\\\\ufb analyze and classify the selected studies according to their publication years and channels, research type, empirical type and contribution type.',\n",
       "  '\\\\ufb researchers have paid a considerable amount of attention to preprocessing in medical dm in last decade  \\\\ufb a significant number of the selected studies used data reduction and cleaning preprocessing tasks \\\\ufb the discipline in which preprocessing has received most attention are: cardiology, endocrinology and oncology   \\\\xcaccepted manuscriptaccepted manuscripta systematic map of medical data preprocessing in knowledge discovery  a. idri a,*, h. benhar a,, j.l.',\n",
       "  'fernández-alemán b,, i. kadi a, asoftware project management research team, ensias,university mohammed v of rabat, morocco bdepartment of informatics and systems, faculty of computer science, university of murcia, spain abstract background and objective: datamining (dm) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns.',\n",
       "  'however, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data.',\n",
       "  'these challenges lead to a serious bias in predictive modeling and reduce the performance of dm techniques.',\n",
       "  \"fernández-alemán b,, i. kadi a, asoftware project management research team, ensias,university mohammed v of rabat, morocco bdepartment of informatics and systems, faculty of computer science, university of murcia, spain abstract ']\"],\n",
       " ['meanwhile, knowledge-based approaches have been extensively used in software\\\\ndevelopment for decades, however, the software engineering community lacks a comprehensive under-\\\\nstanding on how knowledge-based approaches are used in software documentation, especially documen-\\\\ntation of software architecture design.\\\\nobjective: the objective of this work is to explore how knowledge-based approaches are employed in\\\\nsoftware documentation, their inﬂuences to the quality of software documentation, and the costs and\\\\nbeneﬁts of using these approaches.\\\\nmethod: we use a systematic literature review method to identify the primary studies on knowledge-\\\\nbased approaches in software documentation, following a pre-deﬁned review protocol.\\\\nresults: sixty studies are ﬁnally selected, in which twelve quality attributes of software documents, four\\\\ncost categories, and nine beneﬁt categories of using knowledge-based approaches in software documen-\\\\ntation are identiﬁed.',\n",
       "  'meanwhile, knowledge-based approaches have been extensively used in software\\\\ndevelopment for decades, however, the software engineering community lacks a comprehensive under-\\\\nstanding on how knowledge-based approaches are used in software documentation, especially documen-\\\\ntation of software architecture design.\\\\nobjective: the objective of this work is to explore how knowledge-based approaches are employed in\\\\nsoftware documentation, their inﬂuences to the quality of software documentation, and the costs and\\\\nbeneﬁts of using these approaches.\\\\nmethod: we use a systematic literature review method to identify the primary studies on knowledge-\\\\nbased approaches in software documentation, following a pre-deﬁned review protocol.\\\\nresults: sixty studies are ﬁnally selected, in which twelve quality attributes of software documents, four\\\\ncost categories, and nine beneﬁt categories of using knowledge-based approaches in software documen-\\\\ntation are identiﬁed.',\n",
       "  \"the cost of retrieving information from documents is the major concern\\\\nwhen using knowledge-based approaches in software documentation.\\\\n']\",\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.'],\n",
       " ['sms is a secondary study, a special\\\\nform of\\\\nsystematic review (sr), that reviews primary studies with the aim of\\\\nsynthesizing\\\\n(kitchenham and\\\\ncharters, ).',\n",
       "  'sms is a secondary study, a special\\\\nform of\\\\nsystematic review (sr), that reviews primary studies with the aim of\\\\nsynthesizing\\\\n(kitchenham and\\\\ncharters, ).',\n",
       "  'the main objective of the described work was to\\\\ndecrease the assessment cost of primary studies by stopping the process of classiﬁcation of primary studies when\\\\nenough evidence has been collected.',\n",
       "  'the main objective of the described work was to\\\\ndecrease the assessment cost of primary studies by stopping the process of classiﬁcation of primary studies when\\\\nenough evidence has been collected.',\n",
       "  'our aim is not only to reduce the screening process, but\\\\nalso the classiﬁcation process, which is yet another challenging task in\\\\nperforming srs.',\n",
       "  'yet another form of sr is a systematic literature re-\\\\nview (slr), with the aim to identify, analyze and interpret all available\\\\nevidence on speciﬁc research questions.',\n",
       "  'yet another form of sr is a systematic literature re-\\\\nview (slr), with the aim to identify, analyze and interpret all available\\\\nevidence on speciﬁc research questions.',\n",
       "  \"(b).\\\\n\\\\n. ']\",\n",
       "  'for the proposed sms driven by the margin of\\\\nerror, this step is not diﬀerent than in other approaches.',\n",
       "  'sms procedure driven by the margin of error.\\\\n\\\\nshould be made to ﬁnd a good sample of existing primary studies in the\\\\ntopic under discussion.'],\n",
       " [\"(cid:)  elsevier inc. all rights reserved.\\\\n\\\\nkeywords: systematic review; meta-analysis; clinical trial registry; indexed search engine; machine learning; text mining\\\\n\\\\n. ']\",\n",
       "  'this operational step\\\\nis prone to potential bias related to the source of information,\\\\nspeciﬁcity, and completeness of search strings.',\n",
       "  'an\\\\nsr is the synthesis and evaluation of all relevant literature\\\\non a speciﬁc topic, aimed to make the available knowledge\\\\nmore accessible to physicians, care providers, and decision\\\\nmakers [].',\n",
       "  'conducting an sr is not an easy task because\\\\nit must follow speciﬁc guidelines and protocols to ensure\\\\n\\\\nfunding: this research did not receive any speciﬁc grant from funding\\\\n\\\\nagencies in the public, commercial, or not-for-proﬁt sectors.\\\\n\\\\nconﬂicts of interest: none.\\\\n the work was performed during an internship at the unit of biosta-\\\\ntistics, epidemiology, and public health, department of cardiac, thoracic,\\\\nand vascular sciences, university of padova, via loredan ,  pa-\\\\ndova, italy.\\\\nfax: þ \\\\n\\\\n* corresponding author.',\n",
       "  'tel.',\n",
       "  ': þ  ;\\\\n\\\\n.\\\\n\\\\ne-mail address: ileana.baldi@unipd.it (i. baldi).\\\\n\\\\nhttps://doi.org/./j.jclinepi...\\\\n-/(cid:)  elsevier inc. all rights reserved.\\\\n\\\\nreproducibility of the methods.',\n",
       "  'after the deﬁnition of review\\\\nquestions, researchers should accurately identify evidence\\\\nfrom articles, studies, and any other relevant documentation.\\\\nthis selection process consists of an active search through\\\\nonline and ofﬂine literature repositories and the identiﬁca-\\\\ntion of evidence from a large amount of irrelevant informa-\\\\ntion [].',\n",
       "  'in the search phase, researchers use keyword\\\\ncombinations to create queries that are able to ﬁlter docu-\\\\nmentations in large medical databases.',\n",
       "  'after appli-\\\\ncation of queries, researchers manually complete the study\\\\nselection process by a screening of titles, abstracts, and full\\\\ntexts and assess the papers’ eligibility.',\n",
       "  'the ability of the instru-\\\\n\\\\nment to distinguish on-topic from off-topic articles ranged from an area under the receiver operator characteristic curve of .% to .%.\\\\n\\\\nconclusion: the proposed machine learning instrument has the potential to help researchers identify relevant studies in the sr process\\\\nby reducing workload, without losing sensitivity and at a small price in terms of speciﬁcity.'],\n",
       " ['based on risk minimization, the objective of the \\\\nalgorithm is to find the optimal hyperplane           that separate two pre-defined categories.',\n",
       "  'therefore, the objective of this study \\\\nwas  to  identify  the  most  performant  algorithmto  distinguish  empirical  studies  from  non \\\\nempirical works; thereby, facilitating the search and filtering of qualitative, quantitative and \\\\nmixed methods studies.',\n",
       "  \"\\\\n\\\\n']\",\n",
       "  'using  our  text  collection,  information  gain  and     \\\\nstatistic  test  generated  zero  values  for  terms  excluded  from  the  top  ,.',\n",
       "  'the values can be calculated as follows:   \\\\n\\\\n    \\\\n   \\\\n\\\\n \\\\n  \\\\n\\\\n           \\\\n\\\\n           \\\\n\\\\n() \\\\n\\\\nwhere        is the frequency of term t in document d,       is the length of document d, n is the \\\\ntotal number of documents and      is the number of documents containing term t.   \\\\n \\\\ncwww.ncbi.nlm.nih.gov/books/nbk/table/pubmedhelp.t.stopwords \\\\n\\\\nthis article is protected by copyright.',\n",
       "  'all rights reserved.',\n",
       "  '\\\\n\\\\n\\\\xc \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\nfeature selection approaches \\\\n\\\\nnot all of the selected terms  may be useful  for the task of classification.',\n",
       "  'thus, to  eliminate \\\\nirrelevant  terms  and  decrease  computational  load,  features  were  filtered  using  a  feature \\\\nselection  approach.',\n",
       "  'we  compared  three  different  feature  selection  methods:  information \\\\ngain,      statistic  test,  and  document  frequency.',\n",
       "  'information  gain  can  be  translated  as  the \\\\ndifference between the portion of irrelevant entries considering all features and the portion of \\\\nirrelevant entries givena specific feature:   \\\\n \\\\n() \\\\nwhere h(e) is the portion of irrelevant entries in the collection e and          is the portion of \\\\nirrelevant entries in e given a feature t.   \\\\nthe       statistic  test  method  measures  the  dependency  between  a  term  and  its  category \\\\n(empirical or nonempirical):   \\\\n\\\\n                   \\\\n\\\\n          \\\\n\\\\n \\\\n                                     \\\\n\\\\n              \\\\n\\\\n() \\\\n\\\\nwhere  a  is  the  number  of  times  term  t  and  category  c  co-occur,  b  is  the  number  of  times  t \\\\noccurs without c, c is the number of times  c occurs without xtitt, d is the number of times \\\\nneither c nor t occurs and n is the number of documents.'],\n",
       " ['in this vein, future research could analyse how vr\\\\ntechnology could contribute to service recovery or engagement pro-\\\\ncesses.\\\\n\\\\noverall, when considering the whole set of studies analysed on vr\\\\nin marketing, we can highlight four major gaps: (i) a lack of studies\\\\ndevoted to the post-purchase phase and in the second place the studies\\\\nassociated to the pre-purchase phase, (ii) no studies examining how\\\\nconsumers\\' past experience can inﬂuence their decision-making process\\\\nand consumption behaviour, (iii) the majority of studies using graduate\\\\nand undergraduate students to participant in experiments and surveys,\\\\nwhich is not representative of other consumers, (iv) sample size is\\\\nusually <  for\\\\nsettings\\\\n(without a real existence) and higher in the case of real ﬁlms about a\\\\nlandscape, a hotel or a store which researchers ask participants to vi-\\\\nsualize using vr technology, (v) although second life (sl) is one of the\\\\nmost mature virtual worlds (vws), we ﬁnd only four studies conducting\\\\nexperiments in this scenario.\\\\n\\\\nthat develop artiﬁcial virtual\\\\n\\\\nstudies\\\\n\\\\n. \"]',\n",
       "  \"immersion relates to what the system delivers from a\\\\ntechnical perspective and can be objectively measured, while presence\\\\nrelates to the human experience of the given environment.\\\\n\\\\nimmersion is a ve system's ability to deliver an inclusive (where the\\\\nphysical reality is shut out), extensive (concerning the inclusion of\\\\nsensory modalities), surrounding (how panoramic the vr is) and vivid\\\\n(resolution, ﬁdelity, variety of energy) illusion of reality to the senses of\\\\na human participant (slater & wilbur, ).\",\n",
       "  'users\\\\ncan experience ar through a direct vision device like a head-mounted\\\\nsee-through device (e.g., hololens, other ar glasses and retinal dis-\\\\nplays), or an indirect vision display like a hand-held see-through display\\\\n(e.g., tablets and smartphones).',\n",
       "  'both types of devices have a limited\\\\nﬁeld of vision which does not provide the user with a complete view of\\\\n\\\\n\\\\n\\\\n\\\\xcs.m.c.',\n",
       "  'loureiro et al.\\\\n\\\\njournal of business research xxx (xxxx) xxx–xxx\\\\n\\\\nthe reality that is augmented or a full sense of presence.',\n",
       "  'sar is com-\\\\npletely detached from the users, allowing them to have free hands, eyes\\\\nand head and can assume diﬀerent techniques as explained by bimber\\\\nand raskar (), such as screen-based video see-through displays,\\\\nspatial optical see-through displays and projection-based spatial dis-\\\\nplays.',\n",
       "  'projector-based spatial displays project images directly on the\\\\nsurfaces of a physical object and usually take advantage of the volumes\\\\nof that object.',\n",
       "  'these projections can be performed by static, steerable\\\\nand multiple projectors and may be based on static or video digital\\\\ncontent, with or without stereoscopy.\\\\n\\\\nwith ve, the notions of immersion and sense of presence were in-\\\\ntroduced.',\n",
       "  'these notions are intrinsically related because greater im-\\\\nmersion is commonly related to a stronger sense of presence as well as\\\\nthe opposite.',\n",
       "  've can be fully immersive\\\\n(e.g., cave, hdm with a wide ﬁeld of vision), semi-immersive (e.g.\\\\nstereoscopic powerwall) and non-immersive (e.g., desktops).'],\n",
       " ['the objective of our search was to be\\\\nbroad, inclusive and capture as much relevant literature as possible while striving to follow systematic review\\\\nmethodology (e.g.',\n",
       "  'the objective of our search was to be\\\\nbroad, inclusive and capture as much relevant literature as possible while striving to follow systematic review\\\\nmethodology (e.g.',\n",
       "  \")\\\\nsimple two-term search strategy example –\\\\nindex to theses – great britain, ireland (july , )\\\\n\\\\ngoogle.ca (testing of different searches – november , )\\\\nsearch for “all of these words”, terms occur anywhere in text, english language\\\\n\\\\n(participat* and ergonomic*)\\\\n\\\\ns# participatory ergonomic\\\\ns# participatory ergonomics\\\\ns# participative ergonomic\\\\ns# participative ergonomics\\\\n\\\\nappendix b: listing of conference proceedings that were handsearched\\\\nconference proceeding\\\\n\\\\nyear\\\\n\\\\nassociation of canadian ergonomists\\\\nhealthcare ergonomics conference\\\\nhuman factors association of canada\\\\ninternational ergonomists association\\\\ninternational conference on computer-aided ergonomics and safety\\\\npremus\\\\n\\\\n–, –, –\\\\n\\\\n, , , , \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\",\n",
       "  'at the time, the full or modiﬁed search strategy was not possible\\\\nin four of the grey literature databases, and so the simple two-term strategy was used instead: canada institute\\\\nfor scientiﬁc and technical information, foreign doctoral dissertations, index to theses – great britain and ireland,\\\\nand proceedings first.',\n",
       "  'searching for the terms as a “phrase” or for “all of these words” found “anywhere in text” produced\\\\nbetween   and   hits, respectively in google (english language only), and  and  in google\\\\nscholar.',\n",
       "  'testing of the simple search (participatory\\\\nand ergonomic) in both web search engines, using the advanced search screen, produced predictably large\\\\nresults.',\n",
       "  'it should be noted that these are less a feature\\\\nof the search strategies themselves than the indexing and search functionality of the various sources.\\\\n\\\\n.. web searches using google.ca, google scholar and repositories\\\\n\\\\nit was not possible to run the full search in google.ca or google scholar.',\n",
       "  'this was the case for the following databases: business source premier,\\\\nccinfoweb, cinahl, embase, ergonomic abstracts, and medline.',\n",
       "  'this is in contrast to the peer-reviewed literature, where a greater percentage of documents was captured\\\\nby the full or modiﬁed strategies.',\n",
       "  'however, the simple search strategy was effective in capturing a greater percentage of the\\\\ngrey literature progressing to data extraction than the full/modiﬁed search in isi proceedings, papersfirst and\\\\nscopus.'],\n",
       " [\"instead, most organizations are using social and digital media\\\\n communities on select programs in an experimental fashion.\\\\n\\\\nthis whitepaper summarizes high-level findings from this nine-month study beginning with an\\\\nassessment of current practices and usage for each of the primary areas outlined above and ending\\\\nwith considerations, recommended best practices and top reference citations to inform further\\\\nthinking and discussion.\\\\n\\\\nsocial and digital media communities\\\\nin clinical research\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\xc industry usage of social and \\\\ndigital media communities \\\\n\\\\nin clinical research\\\\n\\\\na tufts center for the study of drug development white paper\\\\n\\\\nj u n e      \\\\n\\\\n\\\\xc\\\\xc']\",\n",
       "  '\\\\n\\\\nto date, research sponsors and cros have neither established specific company policies nor for-\\\\nmalized coordinated processes.',\n",
       "  '\\\\n\\\\nfive primary areas were explored:\\\\n\\\\n() general policies and principles of social and digital media use in clinical research\\\\n\\\\n() social and digital media community use in patient recruitment and retention \\\\n\\\\n() use of social and digital media communities for development planning and study design\\\\n\\\\n() social and digital media community use in pharmacovigilance and adverse event reporting\\\\n\\\\n() use of digital and social media for social listening \\\\n\\\\nsocial and digital media—here defined as websites, technologies and software applications used\\\\ninteractively to communicate and share information—are gaining ground as important means to\\\\nimprove the clinical research process through more effective engagement of patient communities.\\\\nat this time, however, regulatory agencies – specifically the u.s. food and drug administration\\\\n(fda) and the european medicines agency (ema) – have not provided clarity or guidelines specifi-\\\\ncally addressing the use of social and digital media communities in clinical research.',\n",
       "  'tufts csdd also conducted an online\\\\nsurvey among english-speaking adult patients to assess their reactions to providing input into pro-\\\\ntocol design.',\n",
       "  '\\\\n\\\\nas part of this effort, tufts csdd conducted landscape assessments to gather case examples and to\\\\nidentify vendors offering social and digital media solutions.',\n",
       "  \"['\\\\n\\\\nbetween march and december , the tufts center for the study of drug development (tufts\\\\ncsdd) convened a working group of  pharmaceutical and biotechnology companies, and\\\\n contract research organizations (cros) to assess current and anticipated use of social and digital\\\\nmedia communities in clinical research; to identify challenges, receptivity and concerns about\\\\nusage; and to develop a comprehensive set of management principles and policies designed to\\\\n optimize the value and minimize risk posed by social and digital media use in clinical research.\"],\n",
       " [\"crowdsourcing\\\\nmay represent a useful approach to reducing the cost of identifying literature for\\\\nsystematic reviews.\\\\n\\\\nkeywords\\\\ncrowdsourcing (mesh), evidence‐based medicine (mesh), review literature as topic (mesh), study\\\\nselection, systematic review methods\\\\n\\\\n | ']\",\n",
       "  'crowdworkers completed screening in  to  days, costing $\\\\nto $, a cost reduction of up to % compared to trained experts.',\n",
       "  'other algorithms\\\\nincreased the fraction of irrelevant articles excluded at some cost to the inclusion of\\\\nrelevant studies.',\n",
       "  'the most inclusive algorithm (designating a citation as relevant if\\\\nany worker did) identified % to % of the citations that were ultimately included\\\\nin the reviews while excluding % to % of irrelevant citations.',\n",
       "  'we aggregated responses from multiple workers\\\\ninto an overall decision to include or exclude the citation using  of  algorithms and\\\\ncompared the performance of these algorithms to the corresponding decisions of\\\\ntrained experts.',\n",
       "  'for each citation, workers answered  or  questions that were\\\\nequivalent to the eligibility criteria.',\n",
       "  'we used\\\\namazon mechanical turk as our platform and  previously conducted systematic\\\\nreviews as examples.',\n",
       "  'we explore the use of crowdsourcing (distributing tasks to\\\\nuntrained workers via the web) to reduce the cost of screening citations.',\n",
       "  ';–.\\\\n\\\\nwileyonlinelibrary.com/journal/jrsm\\\\n\\\\n\\\\n\\\\n\\\\xc received:  february \\\\n\\\\nrevised:  may \\\\n\\\\naccepted:  may \\\\n\\\\ndoi: ./jrsm.\\\\n\\\\no r i g i n a l a r t i c l e\\\\n\\\\nan exploration of crowdsourcing citation screening for\\\\nsystematic reviews\\\\n\\\\nmichael l. mortensen | gaelen p. adam\\\\nbyron c. wallace\\\\n\\\\n| thomas a. trikalinos | tim kraska |\\\\n\\\\n netcompany a/s, aarhus c, denmark\\\\n health services, policy and practice, brown\\\\nuniversity, providence, ri, usa\\\\n computer science, brown university,\\\\nprovidence, ri, usa\\\\n college of computer and information\\\\nscience, northeastern university, boston,\\\\nma, usa\\\\n\\\\ncorrespondence\\\\nbyron c wallace, northeastern university,\\\\nboston ma , usa.\\\\nemail: byron@ccs.neu.edu\\\\nfunding information\\\\nagency for healthcare research (ahrq),\\\\ngrant/award number: rhs;\\\\nnational institutes of health, grant/award\\\\nnumber: uhca; brown university\\\\n\\\\nsystematic reviews are increasingly used to inform health care decisions, but are\\\\nexpensive to produce.',\n",
       "  'research synthesis methods published by john wiley & sons ltd\\\\n\\\\nres syn meth.'],\n",
       " ['out of .\\\\ndiscussion the text mining function in rayyan successfully helped reviewers\\\\nidentify relevant studies early in the screening process.\\\\n\\\\nkeywords\\\\nabstract screening, review efficiency, systematic reviews, text mining\\\\n\\\\n | \\' \"\\\\n\\\\nsystematic reviews aim to provide an exhaustive summary of\\\\nthe current evidence relevant\\\\nto a research question.\\\\nresearchers use pre‐established methods to frame one or\\\\nmore questions,\\\\nidentify all potentially relevant research,\\\\ndetermine which studies directly address the questions posed,\\\\nand then analyze those studies determined to be relevant.\\\\n\\\\na reproducible and thorough literature search from differ-\\\\nent sources, designed to identify as many potentially relevant\\\\nstudies as possible, is one important step to minimize bias in\\\\nthe review process.\\\\n\\\\nas bastian et al point out, the body of scientific literature\\\\nis rapidly growing.',\n",
       "  'https://doi.org/\\\\n./jrsm.\\\\n\\\\n\\\\xc\"]',\n",
       "  'one promising approach\\\\nfor reducing this burden uses text mining technology to identify those abstracts that\\\\nare potentially most relevant for a project, allowing those abstracts to be screened\\\\nfirst.\\\\nobjectives to examine the effectiveness of the text mining functionality of the\\\\nabstract screening tool rayyan.',\n",
       "  'in: higgins j, green s, eds.',\n",
       "  'lefebvre c, manheimer e, glanville j. chapter : searching for\\\\nstudies.',\n",
       "  'since rayyan helps\\\\nscreeners identify potentially relevant abstracts early in the\\\\nscreening process, the full text retrieval process could begin\\\\nwhile continuing screening abstracts.\\\\n\\\\nreference\\\\n\\\\n.',\n",
       "  'rayyan‐assisted screening might help the review team\\\\nattain a higher workflow efficiency.',\n",
       "  'the blinding and\\\\nrecord labelling functions were considered particularly use-\\\\nful.',\n",
       "  'the screeners found that rayyan was\\\\nuser friendly, and that it helped create a more enjoyable,\\\\n\\\\neffective, and consistent review process.',\n",
       "  \"we can there-\\\\nfore confirm that rayyan's performance met or exceeded the\\\\nclaims made by its developers at cochrane colloquium .\\\\nin addition, our small user survey indicated that rayyan may\\\\nprovide other advantages to the review process (over manual\\\\nscreening methods).\"],\n",
       " ['therefore, the main aim of this paper,\\\\nthe comprehensive, detailed, and systematic study, and survey\\\\nof the state-of-the-art knowledge sharing mechanisms in an\\\\nonline environments is provided.',\n",
       "  'therefore, the main aim of this paper,\\\\nthe comprehensive, detailed, and systematic study, and survey\\\\nof the state-of-the-art knowledge sharing mechanisms in an\\\\nonline environments is provided.',\n",
       "  'other con-\\\\nstructs such as personal value, organization\\'s commit-\\\\nment or social norm may be determinants of the ethical\\\\ndimension that influencing knowledge sharing.\\\\n\\\\n \"]',\n",
       "  'in total, the  results are obtained.',\n",
       "  'in\\\\nthis section, an slr is used to perform a comprehensive and\\\\nsystematic study of the online knowledge sharing mecha-\\\\nnisms.',\n",
       "  'then, the validity of the study selection procedure\\\\nwas evaluated as described below.',\n",
       "  'in the following subsec-\\\\ntions, we describe the search process, including the article\\\\nselection process and classification.\\\\n\\\\n\\\\xcinf syst front () :–\\\\n\\\\n.',\n",
       "  'article selection process\\\\n\\\\nthe article selection strategy is consisted three main stages as\\\\nfollow:\\\\n\\\\nstage : automated search based on the keyword bonline\\\\nknowledge sharing^, via an electronic search using\\\\nonline scientific databases.\\\\n\\\\nstage : selection based on the title of the papers.\\\\nstage : selection based on the reputation and validity of the\\\\n\\\\njournals.\\\\n\\\\nin stage , google scholar and electronic databases such as\\\\nsciencedirect, springerlink, web of science, ieee are used in\\\\nthe slr process.',\n",
       "  'for keyword (knowledge sharing online), to\\\\nfind relevant articles.',\n",
       "  'the study was based on articles that\\\\nwere found in the electronic databases depicted in table .\\\\n\\\\nstage  begins by setting certain practical screening\\\\ncriteria.'],\n",
       " ['these research questions have formed the basis of a larger research investigation, with the aim of\\\\ngenerating an empirical understanding of the factors surrounding retention and engagement in vet moocs.\\\\n\\\\ngiven the extent of the connections made between the ﬁndings and existing literature, it can be argued that the outcomes of this\\\\nstudy support the contextual factors of retention and engagement for learners completing moocs or vet online courses.',\n",
       "  'as this research wanted to extend current empirical\\\\nknowledge, the period from  until the research concluded in august  was nominated.\\\\n\\\\n. \"]',\n",
       "  'paton), andrew.ﬂuck@utas.edu.au (a.e.',\n",
       "  'scanlan).\\\\n\\\\nhttps://doi.org/./j.compedu...\\\\nreceived  january ; received in revised form  june ; accepted  june \\\\navailable online  june \\\\n-/ ©  elsevier ltd. all rights reserved.\\\\n\\\\n\\\\xcr.m.',\n",
       "  'paton et al.\\\\n\\\\ncomputers & education  () –\\\\n\\\\nsectors are attentive to the world of work but it is the application of knowledge and skills that diﬀer.',\n",
       "  \"another point of diﬀerence is the\\\\nlearner's educational level on course entry.\",\n",
       "  'vet courses typically have no, or low-level entry requirements, whereas universities\\\\nrequire the completion of year  and an academic achievement score that meets the intellectual and competitive demands of each\\\\ncourse.',\n",
       "  'vet courses also have a relatively short timeframe with most qualiﬁcations completed in three to  months of full-time\\\\nstudy.',\n",
       "  'for universities, the course length is considerably longer and it can take the learner three-four years of full-time study to ﬁnish.\\\\npaton, scanlan, and fluck () in their detailed study of moocs oﬀered by australian universities, international universities and\\\\nvet providers found signiﬁcant diﬀerences between the proportions of learners that completed mooc courses for each educational\\\\ncontext.',\n",
       "  'the ﬁndings indicated that % of vet learners completed their courses as opposed to % for australian universities and\\\\n% for transnational universities.'],\n",
       " ['the overall objective of this study was to propose and validate a system\\\\nthat works as resource manager allocated to workflows.',\n",
       "  'its goal\\\\nis to extract knowledge about events/data from the work carried out in the different\\\\nphases of a business process, seeking to improve it, discovering associations between\\\\nvariables, behavior or misbehavior patterns (van der aalst, ).\\\\n\\\\nin this context, the main objective of this paper is to present the results of a study\\\\nthat identified and analyzed the primary studies related to process mining that\\\\nexclusively use ann or svm as the data mining technique.',\n",
       "  'what types of process mining are treated by ann and svm when these\\\\n\\\\ntechniques are used to address data mining tasks in this context?\\\\n\\\\nwith regards to the type of process mining, whose objective is to verify the ann and\\\\nsvm applications in the area of interest, the data in table x show that two studies\\\\n\\\\nid supervised learning unsupervised learning reinforcement learning fixed-weight networks\\\\n\\\\nx\\\\nx\\\\nx\\\\nx\\\\nx\\\\nx\\\\nx\\\\n\\\\nj-\\\\nj-\\\\nc-\\\\nc-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nnote: x means that the evaluated attributes (at the first line) were found in the evaluated primary\\\\nstudies (at the first column)\\\\n\\\\nx\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\ntable viii.\\\\nclassification of\\\\nprimary studies\\\\nregarding ann and\\\\nsvm learning type\\\\n\\\\nnumeric prediction\\\\n\\\\ncategorical\\\\nprediction (or\\\\nclassification)\\\\n\\\\nid\\\\n\\\\n“regression”\\\\n\\\\nidentification”\\\\n\\\\n“trends\\\\n\\\\ntype\\\\n\\\\nclustering\\\\nanalysis\\\\n\\\\nfrequent patterns discovery,\\\\n\\\\nassociation and correlation rules\\\\n\\\\ndiscovery\\\\n\\\\ntype\\\\n\\\\nx\\\\n\\\\nx\\\\nx\\\\n\\\\nx\\\\nx\\\\n\\\\nj-\\\\nj-\\\\nc-\\\\nc-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nnote: x means that the evaluated attributes (at the first line) were found in the evaluated primary\\\\nstudies (at the first column)\\\\n\\\\nx\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\ntable ix.\\\\nclassification of\\\\nprimary studies\\\\nregarding data\\\\nmining task type\\\\n\\\\n\\\\xcid\\\\n\\\\ndiscovery\\\\n\\\\nconformance\\\\n\\\\nenhancement\\\\n\\\\nx\\\\n\\\\nj-\\\\nj-\\\\nc-\\\\nc-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nc-\\\\nj-\\\\nj-\\\\nnote: x means that the evaluated attributes (at the first line) were found in the evaluated primary\\\\nstudies (at the first column)\\\\n\\\\nx\\\\nx\\\\nx\\\\n\\\\nx\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nx\\\\n\\\\nann and\\\\nsupport vector\\\\nmachines\\\\n\\\\n\\\\n\\\\ntable x.\\\\nclassification of\\\\nprimary studies\\\\nregarding the\\\\nprocess mining type\\\\n\\\\nrelate to the discovery type, three to enhancement, and six to conformance.',\n",
       "  'considering the\\\\npurpose of this slr, as well as its respective identified research questions, we defined\\\\nthe following criteria:\\\\n\\\\nb.. inclusion criteria\\\\nic- the paper essentially addresses data mining, i.e., data mining is directly related\\\\nto the main scope of the work rather than to data mining terms merely mentioned in a\\\\ngeneralized manner.\\\\n\\\\nic- the paper essentially addresses business processes (including workflow),\\\\ni.e., business processes and/or workflow rely directly to the main scope of the work rather\\\\nthan to business processes/workflow terms merely mentioned in a generalized manner.\\\\n\\\\nic- both data mining and business processes are addressed together in the paper to\\\\npresent a process mining approach rather than each one of them being addressed\\\\nindependently.\\\\n\\\\nic- the paper presents as its main objective the use of ann or svm as a technique\\\\n\\\\nto implement data mining tasks in the process mining context.\\\\n\\\\nb.. exclusion criteria\\\\nec- the paper is not electronically available on the web.\\\\nec- the paper is not presented entirely in the english language.\\\\nec- the paper is not related primarily to the computer science or information\\\\nthe paper is related primarily to medicine or industrial\\\\n\\\\nsystems fields (e.g.\\\\nengineering).\\\\n\\\\nec- the data register identified after applying the search string does not actually\\\\nrefer to a scientific paper, but to some non-peer reviewed publication, such as: technical\\\\nreports; books and book chapters; proceedings’ prefaces; and journal’s editorials.\\\\n\\\\nec- the paper presents some type of review, such as a survey or some slr\\\\n(i.e.',\n",
       "  \"thus, there is no guarantee that other researchers could\\\\nachieve the same result as the primary studies classification presented herein.\\\\n\\\\n. ']\",\n",
       "  'first, the search\\\\nstring seeks to find works that are generically related to process mining; and second,\\\\nthe string seeks to limit this search to works that specifically deal with some aspect\\\\nrelated to ann, including its main architectures, or svm, including its two main\\\\nvariants.',\n",
       "  'we chose the following data sources to search\\\\nfor works in this slr: scopus[] and isi web of science (wos)[].',\n",
       "  'these data sources\\\\nwere used in order to maximize the number of candidate works found, since together\\\\nthey index most of the existing papers in the most important digital libraries, such as:\\\\nieeexplore, acm digital library and springerlink.\\\\n\\\\n\\\\xcbpmj\\\\n,\\\\n\\\\n\\\\n\\\\nfor the search strategy, the search string shown in table i was built using\\\\nkeywords derived from the aforementioned research questions, connected through the\\\\nlogical connectives and and or.',\n",
       "  'we elaborated this search string seeking to maximize\\\\nthe number of candidate works to be found for this slr.',\n",
       "  'therefore we sought to use a\\\\nbroad range of options (among words, expressions, and acronyms).'],\n",
       " [\"finally, section  proposes a\\\\nreproducibility checklist and summarizes the conclusions of this\\\\nresearch.\\\\n\\\\n. ']\",\n",
       "  'the application of text mining\\\\ntechniques to citation screening in the context of systematic literature reviews is a relatively young and\\\\ngrowing computational ﬁeld with high relevance for software engineering, medical research and other\\\\nﬁelds.',\n",
       "  '[,] advised\\\\ncultivating reproducibility into a habit and everyday research cul-\\\\nture before its effect can be successfully noticed in publications.\\\\n\\\\nexplicit and unambiguous description of process and results is\\\\nthe ﬁrst step towards ensuring independent researchers can clearly\\\\nunderstand a study to the level that it can be reproduced by them\\\\n[].',\n",
       "  'undocumented implicit knowledge is often the main impedi-\\\\nment to the implementation of proposed algorithms and models\\\\n[].\\\\n\\\\ntechnology can support reproducibility [].',\n",
       "  'for example, it has\\\\nbeen suggested that researchers should utilize whenever they can,\\\\navailable libraries and packages that are easily accessible to the\\\\npublic, are robust and are continually maintained [,].',\n",
       "  'cross\\\\nplatform software should be chosen where possible for experiment\\\\n\\\\n\\\\xc journal of biomedical informatics  () –\\\\n\\\\ncontents lists available at sciencedirect\\\\n\\\\njournal of biomedical informatics\\\\n\\\\nj o u r n a l h o m e p a g e : w w w .',\n",
       "  'e l s e v i e r .',\n",
       "  'c o m / l o c a t e / y j b i n\\\\n\\\\nreproducibility of studies on text mining for citation screening in\\\\nsystematic reviews: evaluation and checklist\\\\n\\\\nbabatunde kazeem olorisade\\\\n\\\\n⇑\\\\n, pearl brereton, peter andras\\\\n\\\\nschool of computing and mathematics, keele university, staffs st bg, uk\\\\n\\\\na r t i c l e\\\\n\\\\ni n f o\\\\n\\\\na b s t r a c t\\\\n\\\\narticle history:\\\\nreceived  november \\\\nrevised  july \\\\naccepted  july \\\\navailable online  july \\\\n\\\\nkeywords:\\\\ncitation screening\\\\nsystematic review\\\\nreproducibility\\\\ntext mining\\\\nreproducible research\\\\n\\\\ncontext: independent validation of published scientiﬁc results through study replication is a pre-\\\\ncondition for accepting the validity of such results.',\n",
       "  'in computation research, full replication is often\\\\nunrealistic for independent results validation, therefore, study reproduction has been justiﬁed as the\\\\nminimum acceptable standard to evaluate the validity of scientiﬁc claims.',\n",
       "  'however, there is little work so far on reproduction studies in the ﬁeld.\\\\nobjective: in this paper, we investigate the reproducibility of studies in this area based on information\\\\ncontained in published articles and we propose reporting guidelines that could improve reproducibility.\\\\nmethods: the study was approached in two ways.'],\n",
       " ['for  this  reason,  we  preferred  to  use  an  objective  (directly\\\\nmeasurable)  criterion  for  characterizing  the  intensity  of  research.\\\\nfinally,  having  not  merged  multiple  papers  under  one  study,  might\\\\nhave  slightly  altered  our  results.',\n",
       "  'this  aim  was   not  a  part,  of  any  other  brief\\\\ndescription.',\n",
       "  'the  keywords  that  are  presented  in  the  tables  aim  at\\\\n\\\\n http://students.csd.auth.gr/∼apamp/mapping  study.html.\\\\n\\\\n\\\\xca.',\n",
       "  'meta-programming  languages,   or  the  actual  aim  of\\\\nthe  study,  e.g.,  visualization  of  patterns.',\n",
       "  'in\\\\nour  study,  we  do  not  aim  only  on  summarizing  empirical  evidence,\\\\nbut  to  gather  a  broader  dataset,  concerning  gof  design  pattern\\\\nresearch.',\n",
       "  'the  main  difference  of  zhang  and  budgen  ()  with\\\\nrespect  to  this  paper  is  the  aim  of  the  two  literature  reviews.',\n",
       "  'in  [p  and\\\\np]  the  authors  aim  at  improving  the  accuracy  of  design  pattern\\\\nidentiﬁcation  algorithms  by  machine  learning  and  formal  pattern\\\\nspeciﬁcations  respectively.',\n",
       "  'for  example,  keywords  detection,  detection  algorithm,\\\\ndetection  tool,  detection  tool  accuracy  and  detection  technique  all\\\\nshare  the  common  aim  of  identifying  gof  design  pattern  instances\\\\nfrom  existing  projects.',\n",
       "  '/  the  journal  of  systems  and  software   () –  \\\\n\\\\ndesign  pattern  formalization \\\\n\\\\n  (.%) \\\\n\\\\n  (.%) \\\\n\\\\ndesign  pattern  detection \\\\n\\\\n  (.%) \\\\n\\\\n  (.%) \\\\n\\\\n#  papers \\\\n\\\\n#  studies \\\\n\\\\npapers\\\\n\\\\ndesign  patterns  and  software  quality \\\\n\\\\n  (.%) \\\\n\\\\n  (.%) \\\\n\\\\ndesign  pattern  application\\\\n\\\\n  (.%)\\\\n\\\\n  (.%)\\\\n\\\\nmiscellaneous  issues \\\\n\\\\n  (.%) \\\\n\\\\n  (.%) \\\\n\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,\\\\np,  p,  p\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,p,  p,  p,  p,  p,  p,  p,\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,\\\\np,  p\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,\\\\np,  p\\\\np,  p,  p,  p,  p,  p,  p,  p,  p,  p,  p,p,  p,  p,  p,  p,\\\\np,  p\\\\np,  p,  p,  p,  p,  p,  p,  p,  p\\\\n\\\\nproviding  indications  on  research  intensity  around  these  keywords\\\\nand  not  to  clearly  describe  the  primary  study.\\\\n\\\\n...  design  patterns  formalization\\\\n\\\\nthe  articles  that  deal  with  pattern  formalizations  all  share  the\\\\ncommon  aim  of  investigating,  identifying,  and  specifying  innova-\\\\ntive  approaches  that  deal  with  modeling  and  formalizing  patterns.\\\\nin  [p,  p,  and  p]  the  authors  deal  with  the  visualization  of\\\\ndesign  patterns  with  uml   artifacts.',\n",
       "  'the  clos-\\\\nest  iso-based  attribute  is  stability  which  is  the  opposite  of  change\\\\nproneness,  i.e.,  the  probability  of  a  class  not  to  change.'],\n",
       " [\"further, stability of performance for\\\\noptimized classiﬁers needs to be demonstrated over various med-\\\\nical review topics.\\\\n\\\\n']\",\n",
       "  'the task is binary because we want to classify primary\\\\nstudies as being eligible or not for further consideration by the\\\\nreview team.',\n",
       "  '[].',\n",
       "  'their work entailed supervised machine learn-\\\\ning methods and natural language processing to identify rigorous\\\\nclinical trials in broad domains, such as therapy, rather than top-\\\\nical domains deﬁned by review questions.',\n",
       "  'based on the work of\\\\nhaynes and colleagues in a series of papers (e.g., see []), rigor\\\\nwas presumed if trials comparing treatments were randomized and\\\\ncontrolled.',\n",
       "  'however, identifying nonrandomized (nr) studies for\\\\ninclusion in systematic reviews is an important problem because\\\\nrandomized controlled trials (rcts) may be unlikely or even uneth-\\\\nical for some research questions [,].',\n",
       "  'for example, nr studies,\\\\nsuch as case-control, cross-sectional, and cohort studies, are com-\\\\nmonly employed to investigate exposure to environmental hazards,\\\\ndiagnostic test accuracy, disease etiology, human development,\\\\ninvasive surgery, adverse events, and rare disorders.',\n",
       "  'notably, in\\\\nwhat is perhaps the ﬁrst study to use machine learning methods to\\\\nidentify topically relevant trials for inclusion in systematic reviews,\\\\nclassiﬁcation involved randomized and controlled drug trials [],\\\\nwhich is in keeping with the foundational research of [].\\\\n\\\\nfor many review questions, the classiﬁcation task involves a mix\\\\nof designs because reviewers search for nr studies (if eligible) in\\\\naddition to rcts.',\n",
       "  'the latter are preferred because they tend to be\\\\nless biased relative to nr studies.',\n",
       "  'however, when nr studies are\\\\neligible for inclusion in a systematic review, the cochrane non-\\\\nrandomised studies methods group enjoins investigators to not\\\\ninclude design terms in their search ﬁlters [].'],\n",
       " ['\\\\n\\\\nobjective: the objective of this literature review is to summarize the current state of the art for securing \\\\nweb applications from major ﬂaws such as injection and logic ﬂaws.',\n",
       "  '\\\\n\\\\nobjective: the objective of this literature review is to summarize the current state of the art for securing \\\\nweb applications from major ﬂaws such as injection and logic ﬂaws.',\n",
       "  '\\\\n\\\\nobjective: the objective of this literature review is to summarize the current state of the art for securing \\\\nweb applications from major ﬂaws such as injection and logic ﬂaws.',\n",
       "  '\\\\n\\\\nthe studies by halfond et al.',\n",
       "  'thus, there is \\\\na  demand  to  build  a  knowledge-base  to  discuss  the  set  of  facts \\\\nand challenges involved in this domain.',\n",
       "  'the systematic literature review on xss [] high- \\\\nlights various mechanisms for detection and mitigation of xss at- \\\\ntacks, but does not focus on the challenges ahead.',\n",
       "  'the latest review on sqli [] published in  \\\\ndoes not follow a systematic methodology that limits the spectrum \\\\nof their study.',\n",
       "  '\\\\n\\\\nall  the  aforementioned  reviews  focus  on  any  one  of  the  fol- \\\\nlowing aspects: (i) developing a taxonomy for classifying attacks \\\\nand vulnerabilities, (ii) identifying the coding faults that are ex- \\\\nploited for launching attacks, and (iii) classifying the fault monitor- \\\\ning approaches.',\n",
       "  'li and xue [] discussed the various mech- \\\\nanisms employed at the server -side for protecting the web appli- \\\\ncations from vulnerabilities.',\n",
       "  '[] submitted a detailed review \\\\nabout the vulnerable points targeted to launch session hijacking at- \\\\ntacks and the mechanisms available for protecting the users from \\\\nthese types of attacks.'],\n",
       " ['in particular, the requirement of\\\\nidentifying all of the eligible citations changes the goal\\\\nof the classification task; rather than attaining high\\\\naccuracy, as is usually the objective in classification, we\\\\naim to eliminate the need to review clearly irrelevant\\\\ncitations without wrongly excluding eligible ones.',\n",
       "  'in the semi-automated\\\\napproach the aim is to retain a yield of % while\\\\nminimizing the burden.\\\\nexperimental setup\\\\nwe simulated the application of our semi-automated\\\\ncitation screening approach on datasets from three sys-\\\\ntematic reviews recently conducted by our team.',\n",
       "  'the aim of our approach is to reduce the reviewers’\\\\nworkload, allowing them to focus on the more intellec-\\\\ntually demanding steps of the systematic review (e.g.,\\\\ninterpretation and analysis), while reducing costs.\\\\nprevious work\\\\nin this section we review related work.',\n",
       "  'our results over\\\\nthis hold-out dataset, which we did not experiment with\\\\nduring the development of our algorithm, satisfied our\\\\nstated aim of achieving % yield while significantly\\\\nreducing the burden using our simple stopping\\\\ncriterion.\\\\n\\\\nthese initial results are promising, but there is room\\\\nfor improvement.',\n",
       "  'in that\\\\nwe aim to semi-automate the citation screening step\\\\nwhile conducting systematic reviews, rather than semi-\\\\nautomating the process of updating previously con-\\\\nducted systematic reviews.\\\\nactive learning with svms\\\\nas discussed above, reviewers conducting systematic\\\\nreviews first search a database (e.g., pubmed) with a\\\\ncarefully constructed query tailored to the medical ques-\\\\ntion being investigated.',\n",
       "  'and %, while maintaining a sensitivity of % to\\\\nthe eligible citations.',\n",
       "  'for a recent survey of active learning, see\\\\nsettle’s literature review [].',\n",
       "  'we shall eluci-\\\\ndate why simple must be tailored to the problem of\\\\n\\\\ncitation screening in later sections.',\n",
       "  'this method\\\\nhas been shown to work well empirically [], and we\\\\nuse it as the foundation of our approach.',\n",
       "  'repeat this\\\\nprocess until some stopping criterion is met (e.g., the\\\\nexpert refuses to provide any more labels).'],\n",
       " ['\\\\n\\\\nwe aim to understand how the term “smell” is deﬁned by \\\\nvarious  researchers.',\n",
       "  '\\\\nobjective:  we aim to present the current knowledge related to software smells and identify challenges \\\\nas well as opportunities in the current practices.',\n",
       "  '\\\\nobjective:  we aim to present the current knowledge related to software smells and identify challenges \\\\nas well as opportunities in the current practices.',\n",
       "  'sharma, d. spinellis / the journal of systems and software  () – \\\\n\\\\ntable  \\\\nstudies selected in the phase .',\n",
       "  '\\\\n\\\\ninclusion criteria \\\\n\\\\n• studies that discuss smells in software development, present a \\\\ncatalog of one of the different types of software smells (such \\\\nas code smells, test smells, and conﬁguration smells), produce \\\\nfactors that cause smells, or explore their impact on any facet \\\\nof software development (for instance, artifacts, people, or pro- \\\\ncess).',\n",
       "  '\\\\nthe inclusion/exclusion criteria are listed below.',\n",
       "  '\\\\n\\\\n... literature search – phase  \\\\n\\\\nin the third phase, we deﬁned inclusion and exclusion criteria \\\\nto ﬁlter out irrelevant studies and to prepare a consolidated library.',\n",
       "  'table  shows the searched digital libraries and correspond- \\\\ning number of selected studies.',\n",
       "  'additionally,  we \\\\napply ﬁlters such as “computer science” and “software engineer- \\\\ning” wherever it was possible and relevant to reﬁne the search re- \\\\nsults.',\n",
       "  'we appended the term “software” to the search \\\\nterms  in  order  to  obtain  more  relevant  results.'],\n",
       " ['the objective of locating all available studies\\\\nis relaxed to some extent in scoping reviews, which prioritise conceptual breadth over depth.',\n",
       "  'study objective\\\\n\\\\nour study objective was to assess the performance of tm technologies to support title-abstract screening in two\\\\nextremely large-scale scoping reviews of public health evidence (ca and ee), compared with conventional\\\\nscreening (an unobserved counterfactual).\\\\n\\\\ntable .',\n",
       "  'we reﬁned draft search strategies until they retrieved % of\\\\ninitial corpus records indexed in each database, with a concurrent aim to minimise search yields (so far as\\\\npossible).',\n",
       "  'in both scoping\\\\nreviews (ca and ee), the principal aim of using tm technologies was to improve the efﬁciency of the screening\\\\nprocess, by identifying as many provisionally eligible records as possible whilst reducing manual screening workload\\\\nto practicable levels.',\n",
       "  'snowball\\\\nsearches aim to locate further eligible studies by checking references lists of eligible study reports that have\\\\nalready been located, coupled with forward citation tracking from those reports, using online platforms such as\\\\npubmed and google scholar (lefebvre et al., ).',\n",
       "  'as a result, their use in these scoping reviews also\\\\nfacilitated development of a reﬁned conceptual understanding of complex and heterogeneous sets of interventions\\\\nthat aim to alter environments with the goal of changing health behaviours and their proposed mechanisms of\\\\naction.',\n",
       "  'second, the obligation to identify every eligible study may be relaxed to some extent,\\\\nas scoping reviews typically prioritise conceptual breadth (the aim to assemble a range and distribution of eligible\\\\nstudies that are representative of the target evidence base in terms of key study characteristics) over depth (the aim\\\\nto assemble all eligible studies) (brunton et al., ).',\n",
       "  'application of the techniques is not limited to the\\\\nextreme quantities of records retrieved in these two examples).\\\\n\\\\n.. the example scoping reviews\\\\n\\\\nwe conducted two scoping reviews to explore, delimit and describe broad evidence bases for two classes of\\\\ninterventions that involve altering environments with the aim of encouraging change in health behaviours at\\\\npopulation level (marteau et al., ; house of lords science and technology select committee, ): choice\\\\narchitecture (‘nudge’) interventions (hollands et al., ) and economic environment interventions (shemilt\\\\net al., ; shemilt et al., in press).',\n",
       "  'in the ee\\\\nreview, we identiﬁed and selected a further  provisionally eligible records after the point at which use\\\\nof tm was initiated.',\n",
       "  'a similar picture emerges from figure , in that initial\\\\nresults from using atr are good, but performance tails off before most relevant studies have been identiﬁed;\\\\na key difference in figure  is that the performance of rt was clearly much poorer than in the ca review\\\\n(figure ).'],\n",
       " [\"all authors have read\\\\nand approved the final manuscript.\\\\n\\\\n']\",\n",
       "  'according to\\\\nwallace et al.',\n",
       "  'we then represent each study as a distribution of lda topics.',\n",
       "  'additionally, we enrich topics\\\\nderived using lda with multi-word terms identified by using an automatic term recognition (atr) tool.',\n",
       "  'for evaluation\\\\npurposes, we carry out automatic identification of relevant studies using support vector machine (svm)-based\\\\nclassifiers that employ both our novel topic-based representation and the bow representation.\\\\nresults: our results show that the svm classifier is able to identify a greater number of relevant studies when using\\\\nthe lda representation than the bow representation.',\n",
       "  'these observations hold for two systematic reviews of the\\\\nclinical domain and three reviews of the social science domain.\\\\nconclusions: a topic-based feature representation of documents outperforms the bow representation when\\\\napplied to the task of automatic citation screening.',\n",
       "  'the proposed term-enriched topics are more informative and less\\\\nambiguous to systematic reviewers.\\\\nkeywords: topic model, text mining, machine learning, systematic reviews\\\\n\\\\nbackground\\\\nthe screening phase of systematic reviews aims to iden-\\\\ntify citations relevant to a research topic, according to a\\\\ncertain pre-defined protocol [–] known as the popula-\\\\ntion, the intervention, the comparator and the outcome\\\\n(pico) framework.',\n",
       "  'this framework seeks to identify\\\\nthe population, the intervention, the comparator and\\\\nthe outcome.',\n",
       "  'this process is usually performed man-\\\\nually, which means that reviewers need to read thou-\\\\nsands of citations during the screening phase, due to the\\\\nrapid growth of the biomedical literature [], making it\\\\nan expensive and time-consuming process.',\n",
       "  '[], an experienced reviewer is able to screen\\\\n\\\\n*correspondence: maxmo@gmail.com\\\\nschool of computer science, national centre for text mining, the university of\\\\nmanchester, manchester, uk\\\\n\\\\ntwo abstracts per minute on average, with more com-\\\\nplex abstracts taking longer.'],\n",
       " ['therefore, the support of well-known\\\\nand agreed ontologies and tools for the semantical annotation of web services is becoming a key concern\\\\nto help the diffusion of semantic web services.\\\\nobjective: the objective of this systematic literature review is to summarize the current state-of-the-art for\\\\nsupporting the semantical annotation of web services by providing answers to a set of research questions.\\\\nmethod: the review follows a predeﬁned procedure that involves automatically searching well-known dig-\\\\nital libraries.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.'],\n",
       " ['[]\\\\ndeveloped a serious game which functioned by estimating\\\\nparticipants’ foot locations and then creating two virtual\\\\nfeet on a screen with the game objective of using these vir-\\\\ntual feet to step on randomly rising targets that emerged\\\\nfrom the floor.',\n",
       "  '[]\\\\ndeveloped a serious game which functioned by estimating\\\\nparticipants’ foot locations and then creating two virtual\\\\nfeet on a screen with the game objective of using these vir-\\\\ntual feet to step on randomly rising targets that emerged\\\\nfrom the floor.',\n",
       "  'exergames (a term for\\\\nexercise games) aim to combine natural human move-\\\\nments and the entertainment of video games to promote\\\\nelderly exercise and enable built-in unobtrusive diag-\\\\nnostics, whereas serious games intend to simultaneously\\\\nrehabilitate motor-impaired users while evaluating patient\\\\nprogress and monitoring for potential patient injury.',\n",
       "  'exergames (a term for\\\\nexercise games) aim to combine natural human move-\\\\nments and the entertainment of video games to promote\\\\nelderly exercise and enable built-in unobtrusive diag-\\\\nnostics, whereas serious games intend to simultaneously\\\\nrehabilitate motor-impaired users while evaluating patient\\\\nprogress and monitoring for potential patient injury.',\n",
       "  'utilizing the d environment of the kinect may be an approach\\\\nwhich could more accurately stimulate the visual cortex and enable\\\\nmore authentic rehabilitation feedback than the current d feedback\\\\nparadigm, ultimately leading to better outcomes.\\\\n\\\\nthe main objective of the proposed system is to stimulate patient par-\\\\nticipation in upper limb rehabilitation activities.',\n",
       "  'utilizing the d environment of the kinect may be an approach\\\\nwhich could more accurately stimulate the visual cortex and enable\\\\nmore authentic rehabilitation feedback than the current d feedback\\\\nparadigm, ultimately leading to better outcomes.\\\\n\\\\nthe main objective of the proposed system is to stimulate patient par-\\\\nticipation in upper limb rehabilitation activities.',\n",
       "  'visual representation of the article search and inclusion/exclusion process during different phases\\\\nof the conducted review process.\\\\n\\\\nthree methods aim to overcome this pitfall by utilizing a\\\\nd bounding box, pre-occlusion velocity data analysis for\\\\nfalls which end in an occluded state, and the orientation\\\\nof a participant’s derived “spine” in respect to a ground\\\\nplane.\\\\n\\\\nfirst, mastorakis and makris’s [] bounding box\\\\nmethod utilized a participant’s width, height and depth\\\\ninstead of a more standard method of skeletization;\\\\ncalculations derived from a center of mass; or spe-\\\\ncific measurements of predetermined body points.',\n",
       "  'visual representation of the article search and inclusion/exclusion process during different phases\\\\nof the conducted review process.\\\\n\\\\nthree methods aim to overcome this pitfall by utilizing a\\\\nd bounding box, pre-occlusion velocity data analysis for\\\\nfalls which end in an occluded state, and the orientation\\\\nof a participant’s derived “spine” in respect to a ground\\\\nplane.\\\\n\\\\nfirst, mastorakis and makris’s [] bounding box\\\\nmethod utilized a participant’s width, height and depth\\\\ninstead of a more standard method of skeletization;\\\\ncalculations derived from a center of mass; or spe-\\\\ncific measurements of predetermined body points.',\n",
       "  'the guidelines\\\\nfor gestures selection reported is as follows and were derived using a\\\\nhuman-based approach which constructs the gesture lexicon based on\\\\nstudying how potential users interact with each other rather than what\\\\nwould be easy for the system to recognize: () select gestures that do\\\\nnot strain the muscles; () select gestures that do not require much\\\\noutward elbow joint extension; () select gestures that do not require\\\\nmuch outward shoulder joint extension; () select gestures that avoid\\\\nouter positions; () select dynamic gestures instead of static gestures;\\\\n() select vertical plane gestures where hands’ extension is avoided; ()\\\\nrelaxed neutral position is in the middle between outer positions, and\\\\n() select gestures that do not require wrist joint extension caused by\\\\nhand rotation.\\\\n\\\\na kinect-based stepping exercise game for clinical effectiveness.\\\\nin\\\\nthis study an exergame was created with an objective of stepping on\\\\nrandomly rising objects that emerged from the floor surrounding the\\\\npatient.',\n",
       "  'the guidelines\\\\nfor gestures selection reported is as follows and were derived using a\\\\nhuman-based approach which constructs the gesture lexicon based on\\\\nstudying how potential users interact with each other rather than what\\\\nwould be easy for the system to recognize: () select gestures that do\\\\nnot strain the muscles; () select gestures that do not require much\\\\noutward elbow joint extension; () select gestures that do not require\\\\nmuch outward shoulder joint extension; () select gestures that avoid\\\\nouter positions; () select dynamic gestures instead of static gestures;\\\\n() select vertical plane gestures where hands’ extension is avoided; ()\\\\nrelaxed neutral position is in the middle between outer positions, and\\\\n() select gestures that do not require wrist joint extension caused by\\\\nhand rotation.\\\\n\\\\na kinect-based stepping exercise game for clinical effectiveness.\\\\nin\\\\nthis study an exergame was created with an objective of stepping on\\\\nrandomly rising objects that emerged from the floor surrounding the\\\\npatient.'],\n",
       " [\"\\\\n\\\\n. ']\",\n",
       "  'thus, the \\\\ntesting is performed with a ﬁnite set of test cases, suitably selected \\\\nfrom the usually inﬁnite executions domain, against the expected \\\\nbehavior” [] .',\n",
       "  'furthermore, some of them take into \\\\naccount the changes in the context by providing speciﬁc test cases for each context conﬁguration (static \\\\nperspective) during the test execution.',\n",
       "  'these  studies revealed ﬁve challenges affecting the design of \\\\ntest cases and  challenges regarding the testing of cass.',\n",
       "  'besides, seven tcdt are not empirically eval- \\\\nuated.',\n",
       "  '\\\\nconclusion: a few tcdt partially support the testing of cass.',\n",
       "  'however, it has not been observed evidence \\\\non any tcdt supporting the truly context-aware testing, which that can adapt the expected output based \\\\non the context variation (dynamic perspective) during the test execution.',\n",
       "  'it is an open issue deserving \\\\ngreater attention from researchers to increase the testing coverage and ensure users conﬁdence in cass.',\n",
       "  '\\\\n©  elsevier b.v. all rights reserved.',\n",
       "  \"\\\\n\\\\n. '\"],\n",
       " ['() aim to estimate\\\\nmonthly solar radiation in india at ten stations for different climatic\\\\nconditions.',\n",
       "  'the following steps present the data\\\\n\\\\nsources, search strategies, the publication selection and screening\\\\ncriteria.\\\\n\\\\n... review objective and research questions\\\\n\\\\nwith the increased use of neural network methods in predic-\\\\ntion, it has become important to study the role of neural network in\\\\nsolar radiation prediction.',\n",
       "  'this will enable to deter-\\\\nmine which techniques get the most/least attractive results and can\\\\nbe most adventitious.\\\\n\\\\nrq: how effective is the ann modeling in the ﬁeld?\\\\nthe aim of this second research question is to assess the current\\\\nmaturity of predictive data mining method such as artiﬁcial neural\\\\nnetwork techniques.',\n",
       "  'the current research will help researchers and solar\\\\npower plant installers to deﬁne solar radiation data with greater\\\\nprecision in situations where meteorological stations are lacking.\\\\n\\\\n... search strategy\\\\n\\\\nafter deﬁning the research goals and questions, we started with\\\\nthe formulation of a formal search strategy to analyze all available\\\\nempirical materials speciﬁc to the objective of this review.',\n",
       "  'the data matrix employs data preprocessing tech-\\\\nniques to increase the data input quality.',\n",
       "  'it should be highlighted that one of the key concepts\\\\nthat guide this research is that of solar radiation predication and\\\\nsolar systems.',\n",
       "  'this is successfully growing by the use of predictive\\\\ndata mining techniques.\\\\nin this context, the artiﬁcial neural\\\\nnetwork is competently performing.',\n",
       "  'the details of important con-\\\\ncepts are described in the following sections and sub sections.\\\\n\\\\n.. data mining\\\\n\\\\ndata mining is the process of discovering hidden patterns and\\\\nanalyzing data from diverse aspects and summarizing it into\\\\npractical knowledge.',\n",
       "  'this can be used to enhance revenue, decrease\\\\ncost, or at times both.',\n",
       "  'data mining usage in prediction and\\\\nmanufacturing started in the s (suehrcke and mccormick,\\\\n).'],\n",
       " ['its aim was to compare\\\\nthe costs and effects of using each of four variant ap-\\\\nproaches, or ‘process models’ (i.e.',\n",
       "  'with evidence from well-conducted\\\\neconomic evaluations in hand, decisions and choices\\\\nabout methods can be made on grounds of efficiency.\\\\n\\\\nin this article, we aim to demonstrate the application of\\\\nan economic evaluation framework to compare the costs\\\\nand effects of four (x) variant approaches to identifying\\\\nstudies for inclusion in systematic reviews.',\n",
       "  'in the ‘case study’ review, reviewers in prac-\\\\ntice recorded one of eight hierarchical ‘excluded’ codes\\\\nfor each full-text report, each denoting a specific exclu-\\\\nsion criterion (for example ‘excluded—not in the uk’, and\\\\n‘excluded—learning not in general practice’—see []\\\\nfor further details).\\\\n\\\\nsince the objective of the study identification process in\\\\nsystematic reviews is to identify all those studies that\\\\nwould meet their pre-specified eligibility criteria, we ope-\\\\nrationalised the analytic unit of effect as ‘a citation saved\\\\nfrom inappropriate exclusion’ (i.e.',\n",
       "  'in this preliminary\\\\nstage of the process, screening of each batch is followed by\\\\na teleconference between the reviewers to discuss disagree-\\\\nments in their application of study eligibility criteria, with\\\\nthe aim of establishing a high level of inter-rater reliability\\\\nin advance of the main tranche of title-abstract screening.\\\\n\\\\nin the main tranche of title-abstract screening that fol-\\\\nlows, the two reviewers independently screen and assign\\\\none of three mutually exclusive codes to each of the\\\\n‘included’ (i.e.',\n",
       "  'next, two reviewers (r and r) are allocated se-\\\\nquential batches of the same – title-abstract records\\\\nfor independent manual screening.',\n",
       "  'systematic reviews  () : \\\\n\\\\npage  of \\\\n\\\\nsafety first\\\\nthe first step in the ‘safety first’ process model (as in all\\\\nfour approaches) is that all title-abstract records retrieved\\\\nby electronic searches and other search methods are\\\\nuploaded to a screening platform [] and de-duplicated,\\\\nwith unique records entering the title-abstract screening\\\\nstage.',\n",
       "  'each of the four variant\\\\napproaches (process models) is described below.\\\\n\\\\n\\\\xcshemilt et al.',\n",
       "  'finally, the ‘single screening\\\\nwith text mining’ model was selected because text mining\\\\nhas,\\\\nin recent years, been advanced as a tool that can\\\\nsubstantively reduce screening workload in systematic\\\\nreviews; however, further evaluation is needed before it can\\\\nbe considered a reliable and widely accepted approach\\\\n[–].\\\\n‘safety first’ was the method actually applied in\\\\nthe ‘case study’ systematic review.',\n",
       "  'these can be viewed,\\\\nrespectively, as representing more (‘safety first’) and less\\\\n(‘single screening’) cautious approaches to the title-abstract\\\\nscreening stage (see below).',\n",
       "  'two of\\\\nthe other three ‘process models’ were selected for investiga-\\\\ntion because they are commonly used variants on a conven-\\\\ntional ‘double screening’ approach.'],\n",
       " ['pubmed), a wide range of smaller databases\\\\nneeds to be searched in order to identify research for re-\\\\nviews that aim to maximise external validity [].',\n",
       "  ').\\\\n\\\\nfinally, the methods, their relative success and the\\\\nmetrics used to evaluate them have not yet been pulled\\\\n\\\\ntogether in a systematic way; this current study aims to\\\\nfill that research gap.\\\\n\\\\naims and research questions of the review\\\\nthe primary aim of this review is to gather and present\\\\nthe available research evidence on existing methods for\\\\ntext mining related to the title and abstract screening\\\\nstage in a systematic review, including the performance\\\\nmetrics used to evaluate these technologiesa.',\n",
       "  \"all authors read and approved the final manuscript.\\\\n\\\\n']\",\n",
       "  'some of\\\\nthe assumptions of text mining technologies in other appli-\\\\ncations do not hold when transferred to the review context.\\\\nfor instance, systematic reviewers generally place strong em-\\\\nphasis on high recall—that is, a desire to identify all the rele-\\\\nvant includable studies—even if that means a vast number of\\\\nirrelevant studies need to be considered to find them.',\n",
       "  'any implementation\\\\nissues need to be identified and resolved before rolling\\\\nsuch technologies out to the intended users.\\\\n\\\\nthirdly, there are various ways in which workload\\\\ncould be reduced through these technologies (reducing\\\\nnumber needed to screen;\\\\ntext mining as a second\\\\nscreener;\\\\nincreasing the rate (speed) of screening and\\\\nimproving workflow through screening prioritisation).\\\\nhowever, not all technologies allow all types of workload\\\\nreduction to be achieved.',\n",
       "  'specialist advice may be required,\\\\nbut it should be akin to the need for occasional special-\\\\nist statistical advice, rather than being at the level of op-\\\\nerating the text mining tools.',\n",
       "  'this means that they are not particularly ac-\\\\ncessible to systematic reviewers who need to make decisions\\\\nabout their review processes, both in terms of the level of\\\\ntechnical detail presented in the reports and in the exposure\\\\nsuch papers would have in systematic review communities.\\\\n\\\\nsecondly, for these technologies to achieve broad up-\\\\ntake, they should be accessible to systematic reviewers\\\\nwithout the need for a computer scientist to write be-\\\\nspoke code or undertake custom processing of text for\\\\nindividual reviews.',\n",
       "  'the vast majority of papers on this topic are pro-\\\\nduced by computer scientists in journals and conference\\\\nproceedings in the field of medical informatics or artificial\\\\nintelligence.',\n",
       "  'firstly, there is not a lot of informa-\\\\ntion about\\\\ntext mining written for systematic review\\\\naudiences.',\n",
       "  'systematic reviews , :\\\\nhttp://www.systematicreviewsjournal.com/content///\\\\n\\\\npage  of \\\\n\\\\nthe research problem\\\\nwhilst the logic behind applying text mining to the screen-\\\\ning stage of systematic reviews has intuitive appeal, there are\\\\nobvious concerns that might be raised by the systematic re-\\\\nview community [].'],\n",
       " [\"\\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\nmanuscript acceptedaccepted manuscript\\\\xc. ']\",\n",
       "  '*  .',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n.']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('method', 'NN', 'O'), ('used', 'VBN', 'O'), ('in', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word method is extracted and added to the query list\n"
     ]
    }
   ],
   "source": [
    "#To fetch the methods for each paper\n",
    "QA2 = extractMethods(other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"this section also contains a subsection that pres-\\\\nents empirical studies on searching for systematic reviews.\\\\nin the ']\",\n",
       "  'the term information retrieval\\\\nwas introduced by mooers (–), who deﬁned it\\\\nthus:\\\\n\\\\ninformation retrieval is the name for the process or method\\\\nwhereby a prospective user of information is able to convert his\\\\nneed for information into an actual list of citations to documents\\\\nin storage containing information useful to him.',\n",
       "  'the paper examines this claim and argues for\\\\nthe continued value of boolean systems, and suggests\\\\ntwo further considerations: (a) the important role of\\\\nhuman expertise in searching (expert searchers and\\\\n“information literate” users) and (b) the role of library\\\\nand information science and knowledge organization\\\\n(ko) in the design and use of classical databases.',\n",
       "  'an\\\\nunderlying issue is the kind of retrieval system for which\\\\none should aim.',\n",
       "  'warner’s () differentiation between\\\\nthe computer science traditions and an older library-\\\\noriented tradition seems important; the former aim to\\\\ntransform queries automatically into (ranked) sets of\\\\nrelevant documents, whereas the latter aims to increase\\\\nthe “selection power” of users.',\n",
       "  'the boolean retrieval\\\\nmodel is valuable in providing users with the power to\\\\nmake informed searches and have full control over what\\\\nis found and what is not.',\n",
       "  \"these issues may have signiﬁ-\\\\ncant implications for the maintenance of information\\\\nscience and ko as research ﬁelds as well as for the\\\\ninformation profession as a profession in its own right.\\\\n\\\\n' ' it is claimed that not only searchers\\\\nbut also the entire ﬁeld of\\\\ninformation science may\\\\nsuffer if concepts such as “recall devices” and “precision\\\\ndevices” no longer have well-deﬁned meanings due to the\\\\nexistence of retrieval models without well-deﬁned matching\\\\ncriteria.\\\\n\\\\nthe field of information retrieval\\\\n\\\\nthe s saw the introduction of the computer into the\\\\nﬁeld of documentation together with the idea of informa-\\\\ntion storage and retrieval.\",\n",
       "  'this concept led some library\\\\nresearchers and documentalists to approach their ﬁeld\\\\nfrom a new theoretical perspective: libraries could be\\\\nunderstood as information-processing systems (and so\\\\ncould scientiﬁc and scholarly communication—journals,\\\\nconferences, informal communication, reviews, etc.).',\n",
       "  'the\\\\nconcept of information storage and retrieval gave rise to\\\\nthe ﬁeld of information science, considered by some a new\\\\nﬁeld, by others as just a new and better name for library\\\\nscience and documentation.',\n",
       "  'it is the ﬁnding\\\\nor discovery process with respect to stored information.'],\n",
       " ['\\\\noverview of systematic literature review method .',\n",
       "  '\\\\noverview of systematic literature review method .',\n",
       "  '\\\\noverview of systematic literature review method .',\n",
       "  \"\\\\n']\",\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.'],\n",
       " ['the authors propose a weakly supervised bootstrapping method to find the\\\\ncomparator from comparable questions.',\n",
       "  'this method is based on two types of sequential rules: class\\\\nsequential rules, used in the classification of sentences, and label sequential rules, used in\\\\nrelation item extraction.',\n",
       "  'described below are different tasks carried out by machine learning approaches.\\\\n\\\\n\\\\xcintr\\\\n,\\\\n\\\\n\\\\n\\\\nthumbs up/thumbs down methods have been used for polarity classification.\\\\naccording to this method proposed by pang et al.',\n",
       "  'the research by xu, liao, li and song () corrected these aforementioned\\\\nshortcomings by providing a method of comparative relation extraction that not only\\\\ndetects the occurrence of relations, but also recognizes direction.',\n",
       "  'product strengths and\\\\nweaknesses identification is carried out by a novel svm-based method proposed by xu,\\\\nwang, ren, xu, liu and liao () which identifies product strengths and weaknesses by\\\\nautomatically identifying comparative opinions.',\n",
       "  'the proposed bootstrapping method was applied\\\\nto source data (m questions), where , unique comparator pairs were extracted from\\\\n, automatically identified comparative questions.\\\\n\\\\nsuggestive identification has been recently carried out by qazi, raj, tahir, cambria and\\\\nsyed () for enhancement of business intelligence.',\n",
       "  'the purpose is to deepen the\\\\nanalysis of multiple opinion types, their benefits and how the issues raised from keyword-\\\\nbased approaches can be solved by common sense knowledge-based approaches.\\\\n\\\\nthis review paper is organized as follows: section  presents our research questions and\\\\nthe method followed for the review of opinion types and techniques used for sa and section \\\\nsummaries the key findings of our study.',\n",
       "  'such approaches should use new techniques capable of\\\\nbetter grasping the conceptual rules that govern sentiment and the clues that can convey\\\\nthese concepts from realization to verbalization in the human mind.',\n",
       "  'which are the sentic computing techniques that resolved the challenges for sa of\\\\n\\\\nopinions?\\\\n\\\\n.. search strategy.',\n",
       "  'by following the search strategy ( previously explained\\\\nin section ..), the selected electronic databases were searched and the studies retrieved.\\\\nin this original search, we retrieved  studies as shown in table iii.'],\n",
       " ['journal of  the  royal\\\\nsociety of medicine , ():-.\\\\nsim i, owens dk, lavori pw, rennels gd: electronic trial banks:\\\\na complementary method for reporting randomized tri-\\\\nals.',\n",
       "  'examples are the design of the randomized\\\\nassignment (conventional, crossover, parallel group,  × \\\\nfactorial)  or  the  method  of  blinding  (single  or  double\\\\nblinded,  open  label).',\n",
       "  'aguirre-junco  a,  colombet  i,  zunino  s,  jaulent  m,  leneveut  l,\\\\nchatellier  g:  computerization  of  guidelines:  a  knowledge\\\\nspecification  method  to  convert  text  to  detailed  decision\\\\ntree for electronic implementation.',\n",
       "  'we speculate that like structured\\\\nabstracts, key facts in unstructured abstracts such as inter-\\\\nvention  and  population  are  not  necessarily  located  in\\\\nwhat would be considered a method sentence.\\\\n\\\\ncomplexity\\\\na sizeable portion of our corpus of studies consists of sim-\\\\nple rcts with a single population group assigned to two\\\\nor  more  interventions.',\n",
       "  'how complete is the reporting of decision tree elements\\\\nwithin rct abstracts?\\\\n\\\\nthe ultimate goal of our work is to automate the processes\\\\ninvolved in creating meta-analyses which are multi-docu-\\\\nment summaries that bring together the results from mul-\\\\n\\\\ntiple rcts into a single evidence-based recommendation.\\\\nour analysis of rct structure has a further purpose as it\\\\nsuggests a method of automatically testing rct reports for\\\\nquality, in terms of completeness, uniformity, and accu-\\\\nracy.\\\\n\\\\ninformation overload in evidence-based medicine\\\\nthe  practice  of  ebm  is  hampered  by  the  overwhelming\\\\namount of information now available [].',\n",
       "  'table  reports\\\\nthe location of the sentence(s) describing assignment of\\\\nintervention at each arm within the structured abstracts in\\\\nr, with respect to the mapped heading class.\\\\n\\\\ntable : number of abstracts in each subcategory in a randomly selected corpus of  rct abstracts.\\\\n\\\\nclasses total\\\\n\\\\nr\\\\n\\\\nr\\\\n\\\\nr\\\\n\\\\nn\\\\n\\\\nn\\\\n\\\\nn\\\\n\\\\nsingle rct complex rct rct substudy\\\\n\\\\nsystematic review other study\\\\n\\\\nrct protocol or \\\\nannouncement\\\\n\\\\nn (%)\\\\n\\\\n\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\npage  of \\\\n(page number not for citation purposes)\\\\n\\\\n\\\\xcbmc medical informatics and decision making , :\\\\n\\\\nhttp://www.biomedcentral.com/-//\\\\n\\\\ntable : the number of unstructured and structured abstracts in group a, the original set of abstracts and group r, the primary \\\\nrct reports from the randomly selected subset.\\\\n\\\\nnumber of abstracts in a\\\\n\\\\nnumber of abstracts in r\\\\n\\\\ntotal abstracts\\\\n\\\\nunstructured abstracts\\\\n\\\\nstructured abstracts\\\\n\\\\nstructured abstracts with explicit heading for intervention\\\\n\\\\nstructured abstracts with explicit heading for population\\\\n\\\\nstructured abstracts with explicit heading for outcome measures\\\\n\\\\nstructured abstracts with explicit heading for all three subheadings\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\n (.%)\\\\n\\\\nthe  intervention  was  described  in  the  method  section\\\\n(%), in aim (.%), design (.%) or results (.%).\\\\nwhen  there  is  no  method  section,  %  of  intervention\\\\nsentences  appear  in  the  aim  and  %  in  design.',\n",
       "  'these\\\\nare  factors  which  should \\\\nideally  be  automatically\\\\nextracted in a text processing system as well as the basic\\\\ndecision tree structure in order to answer all the questions\\\\nthat may arise.\\\\n\\\\nin our analysis, the authors automatically computed the\\\\nnumber of structured abstracts in group a by a method\\\\nthat uses regular expressions to look for section headings.\\\\nthis  method  was  not  evaluated  and  some  errors  may\\\\npotentially exist.\\\\n\\\\nour  data  analysis  is  a  preliminary  study  to  characterize\\\\nrct  reports  across  a  set  of  typical  conditions.',\n",
       "  'the actual interven-\\\\ntion procedure might be described further in the abstract\\\\n\\\\ntable : examples of equivalence classes of pre-defined sub-headings in structured abstracts.\\\\n\\\\nclass\\\\n\\\\naim\\\\n\\\\nsetting\\\\n\\\\nexample heading names\\\\n\\\\ngoal, aim of the study, purpose\\\\n\\\\nsetting, study setting, settings and location\\\\n\\\\nparticipants\\\\n\\\\nstudy population, type of participants, patients or participants, sample\\\\n\\\\noutcome measure\\\\n\\\\nmeasurements, primary outcome measure, study endpoints, major outcome measures\\\\n\\\\npage  of \\\\n(page number not for citation purposes)\\\\n\\\\n\\\\xcbmc medical informatics and decision making , :\\\\n\\\\nhttp://www.biomedcentral.com/-//\\\\n\\\\ntable : examples of the patterns that occur in the section headings of structured rct abstracts of group a.\\\\n\\\\nstructure of abstracts\\\\n\\\\n% of corpus\\\\n\\\\nbackground, method, result conclusion\\\\n\\\\naim, method, result, conclusion\\\\n\\\\naim, patient and method, result, conclusion\\\\n\\\\nbackground, aim, method, result, conclusion\\\\n\\\\nbackground, method and results, conclusion\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n.\\\\n\\\\n.\\\\n\\\\n.\\\\n\\\\n< \\\\n\\\\n< \\\\n\\\\n< \\\\n\\\\naim, participants, design, measurements, result conclusion\\\\n\\\\ncontext, design, setting, participants, outcome measures, result, conclusion\\\\n\\\\naim, design and setting, participants, intervention, measurements and main results, conclusion\\\\n\\\\nor  elsewhere,  possibly  only  in  the  article  because  these\\\\ninterventions can be quite complex to describe in full in\\\\nthe abstract e.g.',\n",
       "  '% of these primary rct abstracts were structured.',\n",
       "  'quality-of-paper measures are also examined.\\\\nmethods: a subset of  abstracts (randomly selected from a set of  retrieved from medline\\\\nfrom  – ) are examined for the quality of rct reporting, the identifiability of rcts from\\\\nabstracts, and the completeness and complexity of rct abstracts with respect to key decision tree\\\\nelements.'],\n",
       " ['(), that reported the preference\\\\nfor blended learning style because it combines the beneﬁts of individual\\\\nstudy online (respect pace of learning and offer ﬂexibility) and collabo-\\\\nrative study in presence (provide opportunity to share and discuss with\\\\nthe colleagues).\\\\n\\\\non the other hand, the results also show the importance of individ-\\\\nual participation without mediator (n = /.%), considering that\\\\nthe investigated studies which adopted this method of participation\\\\nwere published since , transmitting the idea of a recent trend to\\\\nstimulate student autonomy.',\n",
       "  'case studies\\\\nand simulations facilitate the creation of work situations similar to\\\\nreality, so the student can train decision-making, problem identiﬁca-\\\\ntion, hypothesis development, relevant information selection, context\\\\nanalysis and seek for solutions (rodrigues and peres, ).\\\\n\\\\nclinical simulations have been a widely used resource in nursing\\\\neducation, especially in the last decade, because of its valuable feature\\\\nof scenario replication of clinical practice (martins et al., ) and\\\\nbecause it integrates real world to teaching learning process in order\\\\nto achieve educational goals (arthur et al., ).\\\\n\\\\ncomputer simulation can enhance the operation of more complex\\\\nmodels, compared with the static method of paper.',\n",
       "  '(), –.\\\\n\\\\nduarte, a.p.p., ellensohn, l., .',\n",
       "  'acta paul\\\\nenferm.',\n",
       "  'proposta educacional on-\\\\nline sobre úlcera por pressão para alunos e proﬁssionais de enfermagem.',\n",
       "  'f. tese\\\\n(doutorado) universidade federal do rio grande do sul, porto alegre.\\\\n\\\\ncosta, j.b., peres, h.h.c., rogenski, n.m.b., baptista, c.m.c., .',\n",
       "  'construção coletiva do conhecimento em ambiente virtual:\\\\naprendizagem da anamnese e do exame físico de enfermagem.',\n",
       "  '(), – set.\\\\n\\\\ncogo, a.l.p., .',\n",
       "  'gaúcha enferm.',\n",
       "  'rev.'],\n",
       " ['\\\\nsection  presents the method used for the systematic mapping \\\\nstudy and its execution.',\n",
       "  'details  of  the  complete  method  step  by \\\\nstep can be found below.',\n",
       "  '\\\\n\\\\nrule-based \\\\nprobabilistic method \\\\nlearning-based \\\\ngraph-based \\\\nprogramming languages \\\\nclustering/blocking-based \\\\nontology \\\\npatterns \\\\nsorted neighborhood \\\\nalgorithms \\\\nhints \\\\n\\\\ntable  \\\\nrq – data synthesis.',\n",
       "  'method \\\\n\\\\nthe  method  proposed  by  kitchenham  and  charters  ( ) \\\\nis  one  of  the  most  widely  accepted  in  the  ﬁeld  of  soft- \\\\nware  engineering  although  it  has  received  some  critics  and \\\\n\\\\n\\\\xc \\\\n\\\\nj.g.',\n",
       "  'despite this fact, it still could not \\\\nbe considered a major method for software engineering research \\\\nsince, although it covers a multitude of subjects, it does not of- \\\\nten evaluate the quality of the primary studies obtained.',\n",
       "  'this section describes the method that has \\\\nlet us deeply search the most relevant papers related to the topic \\\\nthat  we  are  working  on  in  the  principal  digital  libraries.',\n",
       "  '\\\\nseveral conclusions regarding the improvement of the method are: \\\\nit  warns  to  withdraw  the  advice  to  use  structured  questions  to \\\\nconstruct the search strings and to include the advice to use the \\\\n\"quasi-gold standard\" concept, based on a limited manual search \\\\nto build the search strings and further evaluate the search process.',\n",
       "  '\\\\nergp: a combined entity resolution approach with genetic programming \\\\nlearning an accurate entity resolution model from crowdsourced labels \\\\nentity resolution for high velocity streams using semantic measures \\\\na conﬁdence-based entity resolution approach with incomplete information \\\\na framework for entity resolution with eﬃcient blocking \\\\nentity matching: a case study in the medical domain \\\\nan identiﬁcation ontology for entity matching \\\\nds-dedupe: a scalable, low network overhead data routing algorithm for inline cluster \\\\ndeduplication system \\\\na fast entity resolution method based on wave of records \\\\ncleaning framework for big data - object identiﬁcation and linkage \\\\nto compare or not to compare: making entity resolution more eﬃcient \\\\nentity resolution for high velocity streams using semantic measures \\\\nan ensemble blocking scheme for entity resolution of large and sparse datasets \\\\nunsupervised entity resolution on multi-type graphs \\\\nentity matching across multiple heterogeneous data sources \\\\neﬃcient entity resolution on heterogeneous records \\\\nlinked data entity resolution system enhanced by conﬁguration learning algorithm \\\\nlinking heterogeneous data in the semantic web using scalable and \\\\ndomain-independent candidate selection \\\\nusing memetic algorithm for instance coreference resolution \\\\nrule-based method for entity resolution \\\\nentity resolution in disjoint graphs: an application on genealogical data \\\\nparallel meta-blocking for scaling entity resolution over big heterogeneous data \\\\nminoan er: progressive entity resolution in the web of data \\\\nentity resolution in disjoint graphs: an application on genealogical data \\\\nsemantic-aware blocking for entity resolution \\\\nonline entity resolution using an oracle \\\\nentity resolution-based jaccard similarity coeﬃcient for heterogeneous distributed \\\\ndatabases \\\\na blocking scheme for entity resolution in the semantic web \\\\n\\\\nreference \\\\n\\\\n( ayat, akbarinia, afsarmanesh, & valduriez,  ) \\\\n( whang & garcia-molina,  ) \\\\n( wang, li, & gao,  ) \\\\n( bratus, rumshisky, khrabrov, magar, & thompson,  ) \\\\n\\\\n( ayat, akbarinia, afsarmanesh, & valduriez,  ) \\\\n( dharavath & kumar,  ) \\\\n( whang, marmaros, & garcia-molina,  ) \\\\n( fan, li, ma, tang, & yu,  ) \\\\n( fan, geerts, tang, & yu,  ) \\\\n( ali & cristianini,  ) \\\\n( ramadan, christen, & liang,  ) \\\\n( brando, frontini, & ganascia,  ) \\\\n( nuray-turan, kalashnikov, & mehrotra,  ) \\\\n( li, li, wang, & gao,  ) \\\\n( leita ˜o, calado, & herschel,  ) \\\\n( hermansson, kerola, johansson, jethava, & dubhashi,  ) \\\\n( hernández & koutrika,  ) \\\\n( fisher, christen, wang, & rahm,  ) \\\\n( shen, han, & wang,  ) \\\\n\\\\n( irmak & kraft,  ) \\\\n( shin, jung, lee, & kang,  ) \\\\n( papadakis, ioannou, niederée, palpanas, & nejdl,  ) \\\\n\\\\n( papadakis, ioannou, niederée, & fankhauser, a ) \\\\n( shu, chen, xiong, & meng,  ) \\\\n( yu,  ) \\\\n( yang, sun, tang, ma, & li,  ) \\\\n( sleeman & finin,  ) \\\\n( hsueh, lin, & chiu,  ) \\\\n\\\\n( calvanese, keet, nutt, rodríguez-muro, & stefanoni,  ) \\\\n\\\\n( g. d. a. costa, ) \\\\n( kejriwal,  ) \\\\n( frontini et al.,  ) \\\\n( kolb, köpcke, thor, databases, & systems,  ) \\\\n( sun, shen, kou, nie, & yu, a ) \\\\n( wang, oyama, kurihara, & kashima,  ) \\\\n( priya, prabhakar, & vasavi,  ) \\\\n( gu, zhang, cao, xu, & cuzzocrea,  ) \\\\n( shu et al.,  ) \\\\n( carvalho, laender, & meira,  ) \\\\n( bortoli, bouquet, & bazzanella,  ) \\\\n( sun, xiao, liu, & fu, b ) \\\\n\\\\n( liu, wang, & gao,  ) \\\\n( liu, kumar, & thomas,  ) \\\\n( papadakis, ioannou, niederée, palpanas, & nejdl, b ) \\\\n( priya et al.,  ) \\\\n( balaji et al.,  ) \\\\n( zhu, ghasemi-gol, szekely, galstyan, & knoblock,  ) \\\\n( kong, gao, xu, quian, & zhou,  ) \\\\n( lin, wang, li, & gao,  ) \\\\n( nguyen & ichise,  ) \\\\n( song, luo, & heﬂin,  ) \\\\n\\\\n( xue & wang,  ) \\\\n( li, li, & gao,  \\\\n( rahmani, ranjbar-sahraei, weiss, & tuyls,  ) \\\\n( efthymiou et al.,  ) \\\\n( efthymiou, stefanidis, & vassilis,  ) \\\\n( rahmani et al.,  ) \\\\n( wang, cui, & liang,  ) \\\\n( firmani, saha, & srivastava,  ) \\\\n( dharavath & singh,  ) \\\\n\\\\n( de assis costa & de oliveira,  ) \\\\n\\\\n\\\\xc \\\\n\\\\nj.g.',\n",
       "  'both use a speciﬁc method- \\\\nology,  deﬁne  the  number  of  databases  that  were  consulted  and \\\\napply a systematic process.',\n",
       "  '() , present a systematic review and a com- \\\\nparative analysis of cross-document coreference resolution meth- \\\\nods  and  tools  (cdcr).'],\n",
       " ['listed at least two benefits for con-\\\\nducting mixed method research on construction \\\\nsites.',\n",
       "  'östlund u, kidd l, wengström y, rowa-\\\\n\\\\ndewar n. combining qualitative and \\\\n\\\\nquantitative research within mixed method \\\\nresearch designs: a methodological review.',\n",
       "  'further studies with more focus on \\\\nunsafe behavior and accident causation are, there-\\\\nfore, recommended.\\\\n\\\\nthis review also showed the lack of longitudi-\\\\nnal and mixed method research with high quality \\\\n\\\\njose , vol.',\n",
       "  'although  a  qualitative \\\\napproach has been less common than other meth-\\\\nods  in  safety  research,  researchers  have  found \\\\nthat  qualitative  and  mixed  method  research  is \\\\nuseful for understanding workers’ perceptions of \\\\nsafety and risk.',\n",
       "  \"\\\\n\\\\n. ']\",\n",
       "  'the aim of this methodological and theoretical review is to explore \\\\nthe empirical factors influencing unsafe behaviors and accidents on construction sites.',\n",
       "  'the new integrated \\\\nconceptual model can be used by researchers and \\\\npractitioners  to  better  understand  the  factors \\\\ninfluencing safety performance.',\n",
       "  'however, further \\\\nresearch should be conducted to determine which \\\\nfactors consistently cause unsafe behaviors and \\\\naccidents and to define the influence mechanism \\\\nof distal factors on proximal factors.',\n",
       "  '\\\\n\\\\n\\\\xc international journal of occupational safety and\\\\nergonomics\\\\n\\\\nissn: - (print) - (online) journal homepage: https://www.tandfonline.com/loi/tose\\\\n\\\\nfactors influencing unsafe behaviors and\\\\naccidents on construction sites: a review\\\\n\\\\nyahya khosravi, hassan asilian-mahabadi, ebrahim hajizadeh, narmin\\\\nhassanzadeh-rangi, hamid bastani & amir h. behzadan\\\\n\\\\nto cite this article: yahya khosravi, hassan asilian-mahabadi, ebrahim hajizadeh, narmin\\\\nhassanzadeh-rangi, hamid bastani & amir h. behzadan () factors influencing unsafe\\\\nbehaviors and accidents on construction sites: a review, international journal of occupational\\\\nsafety and ergonomics, :, -, doi: ./..\\\\nto link to this article:  https://doi.org/./..\\\\n\\\\npublished online:  jan .\\\\n\\\\nsubmit your article to this journal \\\\n\\\\narticle views: \\\\n\\\\nview related articles \\\\n\\\\nview crossmark data\\\\n\\\\nciting articles:  view citing articles \\\\n\\\\nfull terms & conditions of access and use can be found at\\\\n\\\\nhttps://www.tandfonline.com/action/journalinformation?journalcode=tose\\\\n\\\\n\\\\xcinternational journal of occupational safety and ergonomics (jose) , vol.',\n",
       "  ', no.'],\n",
       " ['this\\\\n‘homogeneous’ screening method increased the precision\\\\nfrom .',\n",
       "  \"th and pg contributed to the manuscript and all the revisions.\\\\nall authors read and approved the final manuscript.\\\\n\\\\n']\",\n",
       "  '), which permits unrestricted use, distribution, and reproduction in any\\\\nmedium, provided the original work is properly credited.',\n",
       "  'conse-\\\\nquently, many systematic reviews are out of date [, ].\\\\nwith all these challenges, there is a need to adopt tech-\\\\nniques from computer science that can semi-automate\\\\n\\\\n©  rathbone et al.',\n",
       "  'systematic reviews have also be-\\\\ncome more time consuming due to the growth in the\\\\nvolume and scatter of randomised trials [], additional\\\\nreporting steps [–], and the incorporation of more\\\\ncomplex methodologies such as network meta-analysis\\\\nand the acquisition of clinical study reports [].',\n",
       "  'this produces imprecise search results; some-\\\\ntimes less than  % of studies screened are included in a\\\\nsystematic review [, ].',\n",
       "  'the large number of citations re-\\\\ntrieved is partly due to the inadequate coding of studies\\\\nindexed in biomedical databases such as medline and\\\\n\\\\n* correspondence: jrathbon@bond.edu.au\\\\ncentre for research in evidence-based practice, bond university, gold coast,\\\\naustralia\\\\n\\\\nembase.',\n",
       "  'typically, this involves a team of reviewers\\\\ninspecting thousands of records that are produced from\\\\ndatabase searches.',\n",
       "  '%) and increased the number of missed citations.\\\\nconclusions: semi-automated title and abstract screening with abstrackr has the potential to save time and\\\\nreduce research waste.\\\\n\\\\nbackground\\\\nsystematic reviews require a comprehensive search and\\\\nappraisal of the literature to identify all relevant studies\\\\nfor inclusion.',\n",
       "  'sensitivity analysis performed with the larger echo dataset increased the workload saving ( %)\\\\nbut reduced the precision (.'],\n",
       " ['with\\\\nthe increase in frequency of various type of empirical studies in soft-\\\\nware engineering (se), slrs are becoming increasingly important\\\\nas a method to systematically gather and analyze the results from\\\\nthese studies.',\n",
       "  \"while rq examines the\\\\noverall priority, it is quite likely that novice slr authors will\\\\n\\\\n\\\\xc information and software technology  () –\\\\n\\\\ncontents lists available at sciencedirect\\\\n\\\\ninformation and software technology\\\\n\\\\njournal homepage: www.elsevier.com/locate/infsof\\\\n\\\\nidentiﬁcation of slr tool needs – results of a community workshop\\\\nedgar hassler a, jeffrey c. carver b,∗\\\\n\\\\n, david hale a, ahmed al-zubidy b\\\\n\\\\na department of information systems, statistics, and management sciences, the university of alabama, tuscaloosa, al , united states\\\\nb department of computer science, the university of alabama, tuscaloosa, al , united states\\\\n\\\\na r t i c l e\\\\n\\\\ni n f o\\\\n\\\\na b s t r a c t\\\\n\\\\narticle history:\\\\nreceived  september \\\\nrevised  october \\\\naccepted  october \\\\navailable online  october \\\\n\\\\nkeywords:\\\\nsystematic literature review\\\\ncommunity workshops\\\\nresearch infrastructure\\\\ntool features\\\\n\\\\n. ']\",\n",
       "  'therefore, to help focus develop-\\\\nment efforts of tool builders, it is important to prioritize those\\\\nfeatures.\\\\n\\\\nrq: does the experience level of the slr author affect the de-\\\\nvelopment priority of the features?',\n",
       "  'objective:the goal of this work was to consult the software engineering\\\\nresearchers who conduct slrs to identify and prioritize the necessary slr tool features.',\n",
       "  'method: to gather\\\\ninformation required to address this goal, we invited slr authors to participate in an interactive  h workshop\\\\nstructured around the nominal group technique.',\n",
       "  'results: the workshop outcomes indicated that search &\\\\nselection and collaboration are the two highest priority tool features.',\n",
       "  'the results also showed that most of\\\\nthe high-priority features are not well-supported in current tools.',\n",
       "  'conclusion: these results support and\\\\nextend the results of prior work.',\n",
       "  'slr tool authors can use these ﬁndings to guide future development efforts.\\\\n\\\\n©  elsevier b.v. all rights reserved.\\\\n\\\\nthe systematic literature review (slr) process is a formal, re-\\\\npeatable, documented process for identifying, evaluating, and ana-\\\\nlyzing the literature relevant to a speciﬁc topic or question [].',\n",
       "  'a  mapping study identiﬁed  slrs published\\\\nin the se literature [] between  and .'],\n",
       " ['one common clustering method is the\\\\nk-means algorithm, in which a centroid is calculated representing the\\\\nmean or median point of a study cluster.',\n",
       "  'their work found\\\\nthat boosting algorithms scale well to a large number of dimensions\\\\nwhen used with binary feature representations and the appropriate\\\\nontology.\\\\n\\\\nwallace, trikalinos, lau, brodley and schmid [] employ support\\\\nvector machines in combination with supervised learning and estimate\\\\nthe method reduces the number of studies to be reviewed by % with\\\\nno loss of recall.',\n",
       "  'the primary sms simulation is based on a relatively large (\\\\ndocuments) corpus with .% tp studies, while the slr test case study\\\\nis based on a relatively small ( documents) corpus with .% tp\\\\nstudies.\\\\n\\\\nthe vsm and lsa algorithms are then applied to the test slr corpus\\\\nusing the same method as discussed for the primary sms dataset.',\n",
       "  \"the potential bias was minimized by expert\\\\nreview of the protocol, review of the sms publication selection by two\\\\nindependent researchers, followed by conducting a test/retest sample.\\\\nhowever, one must cognizant of the risk regardless.\\\\n\\\\n. ']\",\n",
       "  'hassler et al.\\\\n\\\\ninformation and software technology  () –\\\\n\\\\nvtm was found to reduce the study selection time (regardless of re-\\\\nsearcher experience) and improve selection eﬀectiveness for experi-\\\\nenced researchers [].\\\\n\\\\na related study explores the use of vtm during selection review\\\\nwithin the selection execution step, conducted to validate classiﬁcation\\\\ndecisions and reduce false negatives when the observed quality cri-\\\\nterion demands [].',\n",
       "  'each bag of words representation is then translated\\\\ninto an n-dimensional vector in which each cell in the vector equates to\\\\nthe frequency count of a term used in the document.',\n",
       "  'the vector space\\\\nmodel (vsm) represents a common algorithm basis for processing,\\\\ncomparing, and visualizing the document vector.',\n",
       "  'vsm is proposed here\\\\nas an automated study selection / classiﬁer algorithm, and is further\\\\ndiscussed in section ..\\\\n\\\\nhierarchical models [] produce a tree of document clusters (a\\\\ndendrogram), with a single, all-inclusive cluster at the top, intermediate\\\\nclusters underneath, and individual singleton clusters at the bottom.\\\\nthe resulting dendrogram provides a corpus taxonomy or hierarchical\\\\nindex.\\\\n\\\\npartitional models (including vsm) build un-nested, single-level\\\\nclusters of related studies [].',\n",
       "  'from this, the primary\\\\ndocument topic(s) are determined, which must be assigned meaning by\\\\nthe researcher.',\n",
       "  'document clustering allows the researchers to focus on\\\\nthe core set of primary topics and reduces distractions from irrelevant\\\\nterms.\\\\n\\\\n... visual text mining\\\\n\\\\nvisual text mining (vtm) is emerging as a popular and eﬀective\\\\ntechnique to support slrs [], building on and supporting the natural\\\\nhuman power of visual information processing.'],\n",
       " [\"we also describe the tools currently\\\\nused by slr researchers.\\\\n']\",\n",
       "  'these barriers\\\\nresult from limitations in digital library search facilities, lack of complete tool support,\\\\nand limited infrastructure to support se slrs (hassler et al.',\n",
       "  'when performing\\\\nslrs, se researchers face more barriers than medical researchers because the medical\\\\nfield is more mature with respect to slrs and has better infrastructure and digital library\\\\nsupport (kitchenham et al.',\n",
       "  ').',\n",
       "  'problems\\\\nthat occur during search have implications throughout the slr process (kitchenham and\\\\ncharters ).\\\\n\\\\nse researchers tend to follow a similar slr process as used in other fields, i.e.\\\\ndevelop research questions, identify key words, and systematically search relevant dig-\\\\nital libraries for potentially relevant studies (tranfield et al.',\n",
       "  'in this paper, we focus specifically\\\\non the search phase because it is critical to the success of the systematic study.',\n",
       "  'conversely, the goal\\\\nof the selection phase is to assess the studies identified during the search phase to identify\\\\nthose that provide evidence about the research questions.',\n",
       "  'the rigor of the search process is one of the key factors that\\\\ndifferentiates a systematic review from other types of literature reviews.',\n",
       "  'the goal of the\\\\nsearch phase is to use an unbiased search process, driven by the research questions, to find\\\\nas many studies as possible.',\n",
       "  'differentiate the search phase from the selection phase.'],\n",
       " [\"fernández-alemán b,, i. kadi a, asoftware project management research team, ensias,university mohammed v of rabat, morocco bdepartment of informatics and systems, faculty of computer science, university of murcia, spain abstract ']\",\n",
       "  'the objective of this paper is to review the use of preprocessing techniques in clinical datasets.',\n",
       "  'please\\\\nnote that during the production process errors may be discovered which could affect the content, and\\\\nall legal disclaimers that apply to the journal pertain.\\\\n\\\\n \\\\xcaccepted manuscriptaccepted manuscripthighlights \\\\ufb perform a systematic map of  studies on the application of data preprocessing in healthcare.',\n",
       "  '\\\\ufb analyze and classify the selected studies according to their publication years and channels, research type, empirical type and contribution type.',\n",
       "  '\\\\ufb researchers have paid a considerable amount of attention to preprocessing in medical dm in last decade  \\\\ufb a significant number of the selected studies used data reduction and cleaning preprocessing tasks \\\\ufb the discipline in which preprocessing has received most attention are: cardiology, endocrinology and oncology   \\\\xcaccepted manuscriptaccepted manuscripta systematic map of medical data preprocessing in knowledge discovery  a. idri a,*, h. benhar a,, j.l.',\n",
       "  'fernández-alemán b,, i. kadi a, asoftware project management research team, ensias,university mohammed v of rabat, morocco bdepartment of informatics and systems, faculty of computer science, university of murcia, spain abstract background and objective: datamining (dm) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns.',\n",
       "  'however, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data.',\n",
       "  'these challenges lead to a serious bias in predictive modeling and reduce the performance of dm techniques.',\n",
       "  'data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for dm techniques.',\n",
       "  'methods: we performed a systematic map of studies regarding the application of data preprocessing to healthcare and published between january  and december .'],\n",
       " ['\\\\nresearch method .',\n",
       "  '\\\\nresearch method .',\n",
       "  'meanwhile, knowledge-based approaches have been extensively used in software\\\\ndevelopment for decades, however, the software engineering community lacks a comprehensive under-\\\\nstanding on how knowledge-based approaches are used in software documentation, especially documen-\\\\ntation of software architecture design.\\\\nobjective: the objective of this work is to explore how knowledge-based approaches are employed in\\\\nsoftware documentation, their inﬂuences to the quality of software documentation, and the costs and\\\\nbeneﬁts of using these approaches.\\\\nmethod: we use a systematic literature review method to identify the primary studies on knowledge-\\\\nbased approaches in software documentation, following a pre-deﬁned review protocol.\\\\nresults: sixty studies are ﬁnally selected, in which twelve quality attributes of software documents, four\\\\ncost categories, and nine beneﬁt categories of using knowledge-based approaches in software documen-\\\\ntation are identiﬁed.',\n",
       "  'meanwhile, knowledge-based approaches have been extensively used in software\\\\ndevelopment for decades, however, the software engineering community lacks a comprehensive under-\\\\nstanding on how knowledge-based approaches are used in software documentation, especially documen-\\\\ntation of software architecture design.\\\\nobjective: the objective of this work is to explore how knowledge-based approaches are employed in\\\\nsoftware documentation, their inﬂuences to the quality of software documentation, and the costs and\\\\nbeneﬁts of using these approaches.\\\\nmethod: we use a systematic literature review method to identify the primary studies on knowledge-\\\\nbased approaches in software documentation, following a pre-deﬁned review protocol.\\\\nresults: sixty studies are ﬁnally selected, in which twelve quality attributes of software documents, four\\\\ncost categories, and nine beneﬁt categories of using knowledge-based approaches in software documen-\\\\ntation are identiﬁed.',\n",
       "  \"the cost of retrieving information from documents is the major concern\\\\nwhen using knowledge-based approaches in software documentation.\\\\n']\",\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.'],\n",
       " ['a case study using the\\\\nnewly proposed method is given in section .',\n",
       "  'a description of a new method for performing smss driven\\\\nby the margin of error is presented in section .',\n",
       "  \"['\\\\n\\\\nresearch topic\\\\n\\\\nevidence on a\\\\n\\\\nthis paper proposes a new method for performing systematic\\\\nmapping studies (smss) suitable when the number of identiﬁed pri-\\\\nmary studies is very large and their classiﬁcation would require en-\\\\normous resources.\",\n",
       "  'introduction\\\\n\\\\nresearch topic\\\\n\\\\nevidence on a\\\\n\\\\nthis paper proposes a new method for performing systematic\\\\nmapping studies (smss) suitable when the number of identiﬁed pri-\\\\nmary studies is very large and their classiﬁcation would require en-\\\\normous resources.',\n",
       "  '()).\\\\nidentifying primary studies is one of the most crucial steps in any srs.\\\\nin webster and watson () backward and forward snowballing have\\\\nbeen proposed as the main method to ﬁnd primary studies, which has\\\\nbeen shown later in jalali and wohlin (), badampudi et al.',\n",
       "  'for example, the number of screened publications in\\\\nsyriani et al.',\n",
       "  '.',\n",
       "  'or double sampling technique\\\\n(cochran, ) can be used.',\n",
       "  'in double sampling, a small proportion\\\\n(e.g., %) of a population is examined to estimate the probability p.\\\\nthe main idea of the proposed approach is to select primary studies\\\\nrandomly from the population until the requested margin of error is\\\\nsurpassed (technically this is achieved simply by checking if the counter\\\\nfor already classiﬁed primary studies is equal to n′).',\n",
       "  '(),  instead of  (the\\\\nsize of population was ) in febrero et al.'],\n",
       " [\"(cid:)  elsevier inc. all rights reserved.\\\\n\\\\nkeywords: systematic review; meta-analysis; clinical trial registry; indexed search engine; machine learning; text mining\\\\n\\\\n. ']\",\n",
       "  'this operational step\\\\nis prone to potential bias related to the source of information,\\\\nspeciﬁcity, and completeness of search strings.',\n",
       "  'an\\\\nsr is the synthesis and evaluation of all relevant literature\\\\non a speciﬁc topic, aimed to make the available knowledge\\\\nmore accessible to physicians, care providers, and decision\\\\nmakers [].',\n",
       "  'conducting an sr is not an easy task because\\\\nit must follow speciﬁc guidelines and protocols to ensure\\\\n\\\\nfunding: this research did not receive any speciﬁc grant from funding\\\\n\\\\nagencies in the public, commercial, or not-for-proﬁt sectors.\\\\n\\\\nconﬂicts of interest: none.\\\\n the work was performed during an internship at the unit of biosta-\\\\ntistics, epidemiology, and public health, department of cardiac, thoracic,\\\\nand vascular sciences, university of padova, via loredan ,  pa-\\\\ndova, italy.\\\\nfax: þ \\\\n\\\\n* corresponding author.',\n",
       "  'tel.',\n",
       "  ': þ  ;\\\\n\\\\n.\\\\n\\\\ne-mail address: ileana.baldi@unipd.it (i. baldi).\\\\n\\\\nhttps://doi.org/./j.jclinepi...\\\\n-/(cid:)  elsevier inc. all rights reserved.\\\\n\\\\nreproducibility of the methods.',\n",
       "  'after the deﬁnition of review\\\\nquestions, researchers should accurately identify evidence\\\\nfrom articles, studies, and any other relevant documentation.\\\\nthis selection process consists of an active search through\\\\nonline and ofﬂine literature repositories and the identiﬁca-\\\\ntion of evidence from a large amount of irrelevant informa-\\\\ntion [].',\n",
       "  'in the search phase, researchers use keyword\\\\ncombinations to create queries that are able to ﬁlter docu-\\\\nmentations in large medical databases.',\n",
       "  'after appli-\\\\ncation of queries, researchers manually complete the study\\\\nselection process by a screening of titles, abstracts, and full\\\\ntexts and assess the papers’ eligibility.',\n",
       "  'the ability of the instru-\\\\n\\\\nment to distinguish on-topic from off-topic articles ranged from an area under the receiver operator characteristic curve of .% to .%.\\\\n\\\\nconclusion: the proposed machine learning instrument has the potential to help researchers identify relevant studies in the sr process\\\\nby reducing workload, without losing sensitivity and at a small price in terms of speciﬁcity.'],\n",
       " ['\\\\nonce the best method was selected, a more user-friendly and convenient toole was programmed \\\\nfor researchers.',\n",
       "  'the additional method refinement techniques \\\\nwere  evaluated  separately  (see  methods  section).',\n",
       "  'in  comparison  to  manually  screening  titles  and  abstracts,  combining  this  method \\\\nspecific automatic text classification method with topic-specific automated text classification \\\\ncould potentially save hours of work by, for the most part, reducing the number of irrelevant \\\\nrecords to manually screen.',\n",
       "  '\\\\nthe document frequency method measures the number of times a term t occurs in a document \\\\n(i.e., the text representing a record).',\n",
       "  'numerous entries labelled as negative and containing \\\\nempirical  research  method  keywords  were  incorrectly  identified  by  the  algorithm.',\n",
       "  '\\\\ntf-idf  is  the  most  common  method  for  term  weighting  and  it  balances  the  local \\\\nrepresentativeness of a term within a document and the global discrimination of the term in the \\\\nwhole  dataset.',\n",
       "  'the  method \\\\ndevelopment  component  of  the  quebec-spor  support  unit  is  currently  building  and \\\\ntesting  a  website  to  disseminate  the  automated  text  classification  of  empirical  records \\\\n(atcer) and a user guide.',\n",
       "  '\\\\n\\\\n\\\\xc  \\\\n\\\\ndiscriminating between empirical studies \\\\nand nonempirical works using automated \\\\n\\\\nalexis langlois, jian-yun nie, james thomas, quan nha hong, pierre \\\\n\\\\ntext classification \\\\n\\\\npluye \\\\n\\\\naugust ,  \\\\n\\\\nobjective: identify the most performant automated text classification method (e.g., algorithm) \\\\nfor differentiating empirical studies from nonempirical works in order to facilitate systematic \\\\nmixed studies reviews.',\n",
       "  'information  gain  can  be  translated  as  the \\\\ndifference between the portion of irrelevant entries considering all features and the portion of \\\\nirrelevant entries givena specific feature:   \\\\n \\\\n() \\\\nwhere h(e) is the portion of irrelevant entries in the collection e and          is the portion of \\\\nirrelevant entries in e given a feature t.   \\\\nthe       statistic  test  method  measures  the  dependency  between  a  term  and  its  category \\\\n(empirical or nonempirical):   \\\\n\\\\n                   \\\\n\\\\n          \\\\n\\\\n \\\\n                                     \\\\n\\\\n              \\\\n\\\\n() \\\\n\\\\nwhere  a  is  the  number  of  times  term  t  and  category  c  co-occur,  b  is  the  number  of  times  t \\\\noccurs without c, c is the number of times  c occurs without xtitt, d is the number of times \\\\nneither c nor t occurs and n is the number of documents.',\n",
       "  'in  total,  , \\\\nrelevant concepts were extracted from the dictionary and added to the vectors.'],\n",
       " ['the method used to collect and analyse the data is\\\\ndescribed in the third section, followed by a section where we present\\\\nthe results of the analysis undertaken with the data obtained.',\n",
       "  'selecting fewer than  topics would reduce explained\\\\nvariability sharply and a higher k could add little to the explained\\\\nvariability.\\\\n\\\\n.. topic modelling\\\\n\\\\nthe lda model was run using the gibbs sampling method with\\\\n iterations (griﬃths and steyvers ().',\n",
       "  'single term\\\\n(unigrams) and two-term (bigrams) n-grams were selected for analysis.\\\\nthe document-term matrix was treated for sparsity and revealed a total\\\\nof  n-grams over  documents.\\\\n\\\\nin order to group latent topics discussed in the literature according\\\\nto co-occurrence of words,\\\\nlatent dirichlet allocation (lda) topic\\\\nmodels using gibbs sampling method (cao, xia, li, zhang, & tang,\\\\n; geman & geman, ; griﬃths & steyvers, ) was used.\\\\nregarding selection of the k number of topics that could best represent\\\\nthe underlying groups of discussions in the papers, a set of possible lda\\\\nmodels were developed with k =  topics to k =  topics.',\n",
       "  'in this vein, future research could analyse how vr\\\\ntechnology could contribute to service recovery or engagement pro-\\\\ncesses.\\\\n\\\\noverall, when considering the whole set of studies analysed on vr\\\\nin marketing, we can highlight four major gaps: (i) a lack of studies\\\\ndevoted to the post-purchase phase and in the second place the studies\\\\nassociated to the pre-purchase phase, (ii) no studies examining how\\\\nconsumers\\' past experience can inﬂuence their decision-making process\\\\nand consumption behaviour, (iii) the majority of studies using graduate\\\\nand undergraduate students to participant in experiments and surveys,\\\\nwhich is not representative of other consumers, (iv) sample size is\\\\nusually <  for\\\\nsettings\\\\n(without a real existence) and higher in the case of real ﬁlms about a\\\\nlandscape, a hotel or a store which researchers ask participants to vi-\\\\nsualize using vr technology, (v) although second life (sl) is one of the\\\\nmost mature virtual worlds (vws), we ﬁnd only four studies conducting\\\\nexperiments in this scenario.\\\\n\\\\nthat develop artiﬁcial virtual\\\\n\\\\nstudies\\\\n\\\\n. \"]',\n",
       "  'these notions are intrinsically related because greater im-\\\\nmersion is commonly related to a stronger sense of presence as well as\\\\nthe opposite.',\n",
       "  'users\\\\ncan experience ar through a direct vision device like a head-mounted\\\\nsee-through device (e.g., hololens, other ar glasses and retinal dis-\\\\nplays), or an indirect vision display like a hand-held see-through display\\\\n(e.g., tablets and smartphones).',\n",
       "  'both types of devices have a limited\\\\nﬁeld of vision which does not provide the user with a complete view of\\\\n\\\\n\\\\n\\\\n\\\\xcs.m.c.',\n",
       "  'loureiro et al.\\\\n\\\\njournal of business research xxx (xxxx) xxx–xxx\\\\n\\\\nthe reality that is augmented or a full sense of presence.',\n",
       "  'sar is com-\\\\npletely detached from the users, allowing them to have free hands, eyes\\\\nand head and can assume diﬀerent techniques as explained by bimber\\\\nand raskar (), such as screen-based video see-through displays,\\\\nspatial optical see-through displays and projection-based spatial dis-\\\\nplays.',\n",
       "  'projector-based spatial displays project images directly on the\\\\nsurfaces of a physical object and usually take advantage of the volumes\\\\nof that object.'],\n",
       " ['if we only included partial results\\\\nof extremely large yields, we could risk missing relevant references and bias the results of the review regardless of\\\\nthe method used to select a subset.\\\\n\\\\nwe also note that google ﬁlters results on the basis of browser version, geographic location and previously\\\\nentered search strings (bates, ).',\n",
       "  'if we only included partial results\\\\nof extremely large yields, we could risk missing relevant references and bias the results of the review regardless of\\\\nthe method used to select a subset.\\\\n\\\\nwe also note that google ﬁlters results on the basis of browser version, geographic location and previously\\\\nentered search strings (bates, ).',\n",
       "  \")\\\\nsimple two-term search strategy example –\\\\nindex to theses – great britain, ireland (july , )\\\\n\\\\ngoogle.ca (testing of different searches – november , )\\\\nsearch for “all of these words”, terms occur anywhere in text, english language\\\\n\\\\n(participat* and ergonomic*)\\\\n\\\\ns# participatory ergonomic\\\\ns# participatory ergonomics\\\\ns# participative ergonomic\\\\ns# participative ergonomics\\\\n\\\\nappendix b: listing of conference proceedings that were handsearched\\\\nconference proceeding\\\\n\\\\nyear\\\\n\\\\nassociation of canadian ergonomists\\\\nhealthcare ergonomics conference\\\\nhuman factors association of canada\\\\ninternational ergonomists association\\\\ninternational conference on computer-aided ergonomics and safety\\\\npremus\\\\n\\\\n–, –, –\\\\n\\\\n, , , , \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\",\n",
       "  'at the time, the full or modiﬁed search strategy was not possible\\\\nin four of the grey literature databases, and so the simple two-term strategy was used instead: canada institute\\\\nfor scientiﬁc and technical information, foreign doctoral dissertations, index to theses – great britain and ireland,\\\\nand proceedings first.',\n",
       "  'searching for the terms as a “phrase” or for “all of these words” found “anywhere in text” produced\\\\nbetween   and   hits, respectively in google (english language only), and  and  in google\\\\nscholar.',\n",
       "  'testing of the simple search (participatory\\\\nand ergonomic) in both web search engines, using the advanced search screen, produced predictably large\\\\nresults.',\n",
       "  'it should be noted that these are less a feature\\\\nof the search strategies themselves than the indexing and search functionality of the various sources.\\\\n\\\\n.. web searches using google.ca, google scholar and repositories\\\\n\\\\nit was not possible to run the full search in google.ca or google scholar.',\n",
       "  'this was the case for the following databases: business source premier,\\\\nccinfoweb, cinahl, embase, ergonomic abstracts, and medline.',\n",
       "  'this is in contrast to the peer-reviewed literature, where a greater percentage of documents was captured\\\\nby the full or modiﬁed strategies.',\n",
       "  'however, the simple search strategy was effective in capturing a greater percentage of the\\\\ngrey literature progressing to data extraction than the full/modiﬁed search in isi proceedings, papersfirst and\\\\nscopus.'],\n",
       " [\"instead, most organizations are using social and digital media\\\\n communities on select programs in an experimental fashion.\\\\n\\\\nthis whitepaper summarizes high-level findings from this nine-month study beginning with an\\\\nassessment of current practices and usage for each of the primary areas outlined above and ending\\\\nwith considerations, recommended best practices and top reference citations to inform further\\\\nthinking and discussion.\\\\n\\\\nsocial and digital media communities\\\\nin clinical research\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\xc industry usage of social and \\\\ndigital media communities \\\\n\\\\nin clinical research\\\\n\\\\na tufts center for the study of drug development white paper\\\\n\\\\nj u n e      \\\\n\\\\n\\\\xc\\\\xc']\",\n",
       "  '\\\\n\\\\nto date, research sponsors and cros have neither established specific company policies nor for-\\\\nmalized coordinated processes.',\n",
       "  '\\\\n\\\\nfive primary areas were explored:\\\\n\\\\n() general policies and principles of social and digital media use in clinical research\\\\n\\\\n() social and digital media community use in patient recruitment and retention \\\\n\\\\n() use of social and digital media communities for development planning and study design\\\\n\\\\n() social and digital media community use in pharmacovigilance and adverse event reporting\\\\n\\\\n() use of digital and social media for social listening \\\\n\\\\nsocial and digital media—here defined as websites, technologies and software applications used\\\\ninteractively to communicate and share information—are gaining ground as important means to\\\\nimprove the clinical research process through more effective engagement of patient communities.\\\\nat this time, however, regulatory agencies – specifically the u.s. food and drug administration\\\\n(fda) and the european medicines agency (ema) – have not provided clarity or guidelines specifi-\\\\ncally addressing the use of social and digital media communities in clinical research.',\n",
       "  'tufts csdd also conducted an online\\\\nsurvey among english-speaking adult patients to assess their reactions to providing input into pro-\\\\ntocol design.',\n",
       "  '\\\\n\\\\nas part of this effort, tufts csdd conducted landscape assessments to gather case examples and to\\\\nidentify vendors offering social and digital media solutions.',\n",
       "  \"['\\\\n\\\\nbetween march and december , the tufts center for the study of drug development (tufts\\\\ncsdd) convened a working group of  pharmaceutical and biotechnology companies, and\\\\n contract research organizations (cros) to assess current and anticipated use of social and digital\\\\nmedia communities in clinical research; to identify challenges, receptivity and concerns about\\\\nusage; and to develop a comprehensive set of management principles and policies designed to\\\\n optimize the value and minimize risk posed by social and digital media use in clinical research.\"],\n",
       " [\"crowdsourcing\\\\nmay represent a useful approach to reducing the cost of identifying literature for\\\\nsystematic reviews.\\\\n\\\\nkeywords\\\\ncrowdsourcing (mesh), evidence‐based medicine (mesh), review literature as topic (mesh), study\\\\nselection, systematic review methods\\\\n\\\\n | ']\",\n",
       "  'crowdworkers completed screening in  to  days, costing $\\\\nto $, a cost reduction of up to % compared to trained experts.',\n",
       "  'other algorithms\\\\nincreased the fraction of irrelevant articles excluded at some cost to the inclusion of\\\\nrelevant studies.',\n",
       "  'the most inclusive algorithm (designating a citation as relevant if\\\\nany worker did) identified % to % of the citations that were ultimately included\\\\nin the reviews while excluding % to % of irrelevant citations.',\n",
       "  'we aggregated responses from multiple workers\\\\ninto an overall decision to include or exclude the citation using  of  algorithms and\\\\ncompared the performance of these algorithms to the corresponding decisions of\\\\ntrained experts.',\n",
       "  'for each citation, workers answered  or  questions that were\\\\nequivalent to the eligibility criteria.',\n",
       "  'we used\\\\namazon mechanical turk as our platform and  previously conducted systematic\\\\nreviews as examples.',\n",
       "  'we explore the use of crowdsourcing (distributing tasks to\\\\nuntrained workers via the web) to reduce the cost of screening citations.',\n",
       "  ';–.\\\\n\\\\nwileyonlinelibrary.com/journal/jrsm\\\\n\\\\n\\\\n\\\\n\\\\xc received:  february \\\\n\\\\nrevised:  may \\\\n\\\\naccepted:  may \\\\n\\\\ndoi: ./jrsm.\\\\n\\\\no r i g i n a l a r t i c l e\\\\n\\\\nan exploration of crowdsourcing citation screening for\\\\nsystematic reviews\\\\n\\\\nmichael l. mortensen | gaelen p. adam\\\\nbyron c. wallace\\\\n\\\\n| thomas a. trikalinos | tim kraska |\\\\n\\\\n netcompany a/s, aarhus c, denmark\\\\n health services, policy and practice, brown\\\\nuniversity, providence, ri, usa\\\\n computer science, brown university,\\\\nprovidence, ri, usa\\\\n college of computer and information\\\\nscience, northeastern university, boston,\\\\nma, usa\\\\n\\\\ncorrespondence\\\\nbyron c wallace, northeastern university,\\\\nboston ma , usa.\\\\nemail: byron@ccs.neu.edu\\\\nfunding information\\\\nagency for healthcare research (ahrq),\\\\ngrant/award number: rhs;\\\\nnational institutes of health, grant/award\\\\nnumber: uhca; brown university\\\\n\\\\nsystematic reviews are increasingly used to inform health care decisions, but are\\\\nexpensive to produce.',\n",
       "  'research synthesis methods published by john wiley & sons ltd\\\\n\\\\nres syn meth.'],\n",
       " ['https://doi.org/\\\\n./jrsm.\\\\n\\\\n\\\\xc\"]',\n",
       "  'the cochrane collaboration; .\\\\n\\\\n.',\n",
       "  'in: higgins j, green s, eds.',\n",
       "  'lefebvre c, manheimer e, glanville j. chapter : searching for\\\\nstudies.',\n",
       "  'since rayyan helps\\\\nscreeners identify potentially relevant abstracts early in the\\\\nscreening process, the full text retrieval process could begin\\\\nwhile continuing screening abstracts.\\\\n\\\\nreference\\\\n\\\\n.',\n",
       "  'rayyan‐assisted screening might help the review team\\\\nattain a higher workflow efficiency.',\n",
       "  'the blinding and\\\\nrecord labelling functions were considered particularly use-\\\\nful.',\n",
       "  'the screeners found that rayyan was\\\\nuser friendly, and that it helped create a more enjoyable,\\\\n\\\\neffective, and consistent review process.',\n",
       "  \"we can there-\\\\nfore confirm that rayyan's performance met or exceeded the\\\\nclaims made by its developers at cochrane colloquium .\\\\nin addition, our small user survey indicated that rayyan may\\\\nprovide other advantages to the review process (over manual\\\\nscreening methods).\",\n",
       "  'out of .\\\\ndiscussion the text mining function in rayyan successfully helped reviewers\\\\nidentify relevant studies early in the screening process.\\\\n\\\\nkeywords\\\\nabstract screening, review efficiency, systematic reviews, text mining\\\\n\\\\n | \" \"\\\\n\\\\nthe text mining–based ranking function of rayyan effec-\\\\ntively assisted reviewers to identify relevant records early in\\\\nthe review process for all  reviews evaluated.'],\n",
       " ['an slr is a research method originat-\\\\ning from the field of medicine (nkomo and hoobler ;\\\\nvalentine ) and studies in the domains of engineering\\\\nand social science have started to adopt this methodological\\\\napproach more frequently (coetzer and sitlington ).',\n",
       "  'also, appendix  provides the basic concepts\\\\nand related terminologies; appendix  provides the abbrevia-\\\\ntion of the used terms in the paper; and appendix  provides\\\\nthe publishing information of the reviewed articles in section .\\\\n\\\\n systematic review\\\\n\\\\na systematic literature review (slr) is a critical assessment and\\\\nevaluation of all research studies that address a particular issue.\\\\nthe researchers use an organized method of locating, assem-\\\\nbling, and evaluating a body of literature on a particular topic\\\\nusing a set of specific criteria.',\n",
       "  ').',\n",
       "  'in\\\\nthis section, an slr is used to perform a comprehensive and\\\\nsystematic study of the online knowledge sharing mecha-\\\\nnisms.',\n",
       "  'then, the validity of the study selection procedure\\\\nwas evaluated as described below.',\n",
       "  'in the following subsec-\\\\ntions, we describe the search process, including the article\\\\nselection process and classification.\\\\n\\\\n\\\\xcinf syst front () :–\\\\n\\\\n.',\n",
       "  'article selection process\\\\n\\\\nthe article selection strategy is consisted three main stages as\\\\nfollow:\\\\n\\\\nstage : automated search based on the keyword bonline\\\\nknowledge sharing^, via an electronic search using\\\\nonline scientific databases.\\\\n\\\\nstage : selection based on the title of the papers.\\\\nstage : selection based on the reputation and validity of the\\\\n\\\\njournals.\\\\n\\\\nin stage , google scholar and electronic databases such as\\\\nsciencedirect, springerlink, web of science, ieee are used in\\\\nthe slr process.',\n",
       "  'for keyword (knowledge sharing online), to\\\\nfind relevant articles.',\n",
       "  'the study was based on articles that\\\\nwere found in the electronic databases depicted in table .\\\\n\\\\nstage  begins by setting certain practical screening\\\\ncriteria.',\n",
       "  'other con-\\\\nstructs such as personal value, organization\\'s commit-\\\\nment or social norm may be determinants of the ethical\\\\ndimension that influencing knowledge sharing.\\\\n\\\\n \"]'],\n",
       " ['as this research wanted to extend current empirical\\\\nknowledge, the period from  until the research concluded in august  was nominated.\\\\n\\\\n. \"]',\n",
       "  'scientiﬁc research journal (scirj), (), –.\\\\ngarbett, c. ().',\n",
       "  'fluck), joel.scanlan@utas.edu.au (j.d.',\n",
       "  'scanlan).\\\\n\\\\nhttps://doi.org/./j.compedu...\\\\nreceived  january ; received in revised form  june ; accepted  june \\\\navailable online  june \\\\n-/ ©  elsevier ltd. all rights reserved.\\\\n\\\\n\\\\xcr.m.',\n",
       "  'paton et al.\\\\n\\\\ncomputers & education  () –\\\\n\\\\nsectors are attentive to the world of work but it is the application of knowledge and skills that diﬀer.',\n",
       "  \"another point of diﬀerence is the\\\\nlearner's educational level on course entry.\",\n",
       "  'vet courses typically have no, or low-level entry requirements, whereas universities\\\\nrequire the completion of year  and an academic achievement score that meets the intellectual and competitive demands of each\\\\ncourse.',\n",
       "  'vet courses also have a relatively short timeframe with most qualiﬁcations completed in three to  months of full-time\\\\nstudy.',\n",
       "  'for universities, the course length is considerably longer and it can take the learner three-four years of full-time study to ﬁnish.\\\\npaton, scanlan, and fluck () in their detailed study of moocs oﬀered by australian universities, international universities and\\\\nvet providers found signiﬁcant diﬀerences between the proportions of learners that completed mooc courses for each educational\\\\ncontext.',\n",
       "  'the ﬁndings indicated that % of vet learners completed their courses as opposed to % for australian universities and\\\\n% for transnational universities.'],\n",
       " [\"thus, there is no guarantee that other researchers could\\\\nachieve the same result as the primary studies classification presented herein.\\\\n\\\\n. ']\",\n",
       "  'conducting the slr\\\\nthis section presents the main steps to conduct the slr.',\n",
       "  'a secondary study), and not the outcomes of some specific research work\\\\n(i.e.',\n",
       "  'considering the\\\\npurpose of this slr, as well as its respective identified research questions, we defined\\\\nthe following criteria:\\\\n\\\\nb.. inclusion criteria\\\\nic- the paper essentially addresses data mining, i.e., data mining is directly related\\\\nto the main scope of the work rather than to data mining terms merely mentioned in a\\\\ngeneralized manner.\\\\n\\\\nic- the paper essentially addresses business processes (including workflow),\\\\ni.e., business processes and/or workflow rely directly to the main scope of the work rather\\\\nthan to business processes/workflow terms merely mentioned in a generalized manner.\\\\n\\\\nic- both data mining and business processes are addressed together in the paper to\\\\npresent a process mining approach rather than each one of them being addressed\\\\nindependently.\\\\n\\\\nic- the paper presents as its main objective the use of ann or svm as a technique\\\\n\\\\nto implement data mining tasks in the process mining context.\\\\n\\\\nb.. exclusion criteria\\\\nec- the paper is not electronically available on the web.\\\\nec- the paper is not presented entirely in the english language.\\\\nec- the paper is not related primarily to the computer science or information\\\\nthe paper is related primarily to medicine or industrial\\\\n\\\\nsystems fields (e.g.\\\\nengineering).\\\\n\\\\nec- the data register identified after applying the search string does not actually\\\\nrefer to a scientific paper, but to some non-peer reviewed publication, such as: technical\\\\nreports; books and book chapters; proceedings’ prefaces; and journal’s editorials.\\\\n\\\\nec- the paper presents some type of review, such as a survey or some slr\\\\n(i.e.',\n",
       "  'a study, identified after applying the search\\\\nstring, is selected as primary study if it meets all the predefined inclusion criteria; but it\\\\nis eliminated if it meets any of the predefined exclusion criteria.',\n",
       "  'we specified a set of inclusion and exclusion\\\\ncriteria based on the analysis scope and the quality of the papers found to guarantee\\\\nthat only works actually related to the context of process mining with ann or svm\\\\nwould be selected as the primary studies.',\n",
       "  'primary study selection strategy.',\n",
       "  'these adjusted\\\\nsearch strings have already embedded some additional restrictions, as part of this slr\\\\n\\\\n(“process mining” or “workflow mining” or “process mining” or “mining workflow” or ((“business\\\\nprocess” or workflow) and “data mining”)) and ((neural or som or “self organizing” or “self-\\\\norganizing” or “organizing map” or mlp or “multilayer perceptron” or “backpropagation” or\\\\n“back-propagation” or rbf or “radial basis function” or artmap or “adaptive resonance\\\\ntheory” or hopfield or lvq or “learning vector quantization”) or (“svm” or “svr” or “svc”\\\\nor “support vector” or “support-vector”))\\\\n\\\\ntable i.\\\\nsearch string\\\\n\\\\nscopus\\\\ntitle-abs-key((“process mining” or “processes mining” or “workflow mining” or “workflows\\\\nmining” or “mining process” or “mining processes” or “mining workflow” or “mining workflows”\\\\nor ((“business process” or “business processes” or workflow or workflows) and “data mining”))\\\\nand ((neural or som or “self organizing” or “self-organizing” or “organizing map” or\\\\n“organizing maps” or mlp or “multilayer perceptron” or “backpropagation” or “back-\\\\npropagation” or rbf or “radial basis function” or artmap or “adaptive resonance theory” or\\\\nhopfield or lvq or “learning vector quantization”) or (svm or svr or svc or “support\\\\nvector” or “support-vector”))) and pubyear w  and (limit-to(language, “english”))\\\\nand (limit-to(doctype, “cp”) or limit-to(doctype, “ar”) or limit-to(doctype, “ip”))\\\\nand (limit-to(subjarea, “comp”) or limit-to(subjarea, “engi”) or limit-to\\\\n(subjarea, “math”) or limit-to(subjarea, “busi”) or limit-to(subjarea, “mult”))\\\\nisi web of science\\\\ntopic ¼ ((“process mining” or “processes mining” or “workflow mining” or “workflows mining” or\\\\n“mining process” or “mining processes” or “mining workflow” or “mining workflows” or\\\\n((“business process” or “business processes” or workflow or workflows) and “data mining”)) and\\\\n((neural or som or “self organizing” or “self-organizing” or “organizing map” or “organizing\\\\nmaps” or mlp or “multilayer perceptron” or “backpropagation” or “back-propagation” or rbf\\\\nor “radial basis function” or artmap or “adaptive resonance theory” or hopfield or lvq or\\\\n“learning vector quantization”) or (“svm” or “svr” or “svc” or “support vector” or “support-\\\\nvector”))); refined by: language: (english) and document types: (proceedings paper or\\\\npaper) and research ares: (computer science or engineering or operations\\\\nresearch management science or mathematical computational biology or\\\\nmathematics or medical informatics or business economics or automation\\\\ncontrol systems or science technology other topics) timespan ¼ -.\\\\ndatabases ¼ sciexpanded, cpci-s, bkci-s\\\\n\\\\ntable ii.\\\\nsearch strings\\\\nspecific for each\\\\ndata source\\\\n\\\\n\\\\xcann and\\\\nsupport vector\\\\nmachines\\\\n\\\\n\\\\n\\\\nprotocol (as explained in the following inclusion and exclusion criteria), when the\\\\nspecific search engines for each data source enable doing it, in order to perform a pre-\\\\nfilter to discard applicable records for this slr.\\\\n\\\\nwe first applied the search at the end of  and reapplied it at the end of .\\\\nb.',\n",
       "  'table ii presents the search\\\\nstrings modified to fit the characteristics of each one of these engines.',\n",
       "  'the keywords used in the string were defined based on the knowledge and\\\\ninformation of one of the authors of this study, an expert on ann and svm.\\\\n\\\\nsince it was not possible to use the same exact string for both data sources, we had\\\\nto adjust the base search string shown in table i so that it could be directly applied to\\\\nthe search engines of each one of the data sources used.'],\n",
       " [\"finally, section  proposes a\\\\nreproducibility checklist and summarizes the conclusions of this\\\\nresearch.\\\\n\\\\n. ']\",\n",
       "  'the application of text mining\\\\ntechniques to citation screening in the context of systematic literature reviews is a relatively young and\\\\ngrowing computational ﬁeld with high relevance for software engineering, medical research and other\\\\nﬁelds.',\n",
       "  '[,] advised\\\\ncultivating reproducibility into a habit and everyday research cul-\\\\nture before its effect can be successfully noticed in publications.\\\\n\\\\nexplicit and unambiguous description of process and results is\\\\nthe ﬁrst step towards ensuring independent researchers can clearly\\\\nunderstand a study to the level that it can be reproduced by them\\\\n[].',\n",
       "  'undocumented implicit knowledge is often the main impedi-\\\\nment to the implementation of proposed algorithms and models\\\\n[].\\\\n\\\\ntechnology can support reproducibility [].',\n",
       "  'for example, it has\\\\nbeen suggested that researchers should utilize whenever they can,\\\\navailable libraries and packages that are easily accessible to the\\\\npublic, are robust and are continually maintained [,].',\n",
       "  'cross\\\\nplatform software should be chosen where possible for experiment\\\\n\\\\n\\\\xc journal of biomedical informatics  () –\\\\n\\\\ncontents lists available at sciencedirect\\\\n\\\\njournal of biomedical informatics\\\\n\\\\nj o u r n a l h o m e p a g e : w w w .',\n",
       "  'e l s e v i e r .',\n",
       "  'c o m / l o c a t e / y j b i n\\\\n\\\\nreproducibility of studies on text mining for citation screening in\\\\nsystematic reviews: evaluation and checklist\\\\n\\\\nbabatunde kazeem olorisade\\\\n\\\\n⇑\\\\n, pearl brereton, peter andras\\\\n\\\\nschool of computing and mathematics, keele university, staffs st bg, uk\\\\n\\\\na r t i c l e\\\\n\\\\ni n f o\\\\n\\\\na b s t r a c t\\\\n\\\\narticle history:\\\\nreceived  november \\\\nrevised  july \\\\naccepted  july \\\\navailable online  july \\\\n\\\\nkeywords:\\\\ncitation screening\\\\nsystematic review\\\\nreproducibility\\\\ntext mining\\\\nreproducible research\\\\n\\\\ncontext: independent validation of published scientiﬁc results through study replication is a pre-\\\\ncondition for accepting the validity of such results.',\n",
       "  'in computation research, full replication is often\\\\nunrealistic for independent results validation, therefore, study reproduction has been justiﬁed as the\\\\nminimum acceptable standard to evaluate the validity of scientiﬁc claims.',\n",
       "  'however, there is little work so far on reproduction studies in the ﬁeld.\\\\nobjective: in this paper, we investigate the reproducibility of studies in this area based on information\\\\ncontained in published articles and we propose reporting guidelines that could improve reproducibility.\\\\nmethods: the study was approached in two ways.'],\n",
       " ['the  keywords  can  be  the  method  used  for  the  purpose\\\\nof  the  study,  e.g.',\n",
       "  'more  speciﬁcally,\\\\nthe  research  method  used  was  a  systematic  literature  review  on\\\\nempirical  studies  concerning  design  patterns  and  software  quality\\\\nattributes.',\n",
       "  'in  this\\\\nwork  we   have  grouped  papers  into  studies  and  report  them  both.\\\\nthe  main  criterion  for  merging  papers  into  studies  was  the  similar-\\\\nity  of  research  method  and  questions.',\n",
       "  'in\\\\n[p]  the  authors’  method  suggests  pattern-based  architecting  for\\\\ndocumenting  design  decisions  in  real-time  (table  ).\\\\n\\\\n...  miscellaneous  issues  on  design  patterns\\\\n\\\\nconcerning  research  on  generic  issues  on  gof  patterns,  nine  ()\\\\nstudies  have  been  identiﬁed.',\n",
       "  'however,  some  papers  that  have  been  reported\\\\nfrom  zhang  and  budgen  ()  are  not  reported  in  this  mapping\\\\nstudy  because  of  the  narrower  searching  space,  in  the  sense  that  we\\\\nonly  searched  within  speciﬁc  journal  and  conference  proceedings.\\\\nthe  table  summarizes  how  many  and  which  studies  employ  which\\\\nresearch  method  (as  described  in  glass  et  al.',\n",
       "  'hence,  although  we  have  not  performed  a  system-\\\\natic  quality  assessment  for  the  primary  studies  in  our  review,  we\\\\nbelieve  that  the  quality  of  the  selected  papers  is  good  enough  for\\\\nthe  purpose  of  our  study.\\\\n\\\\nfor  the  studies  that  deal  with  software  quality,  additional  infor-\\\\n\\\\nmation  has  been  retrieved:\\\\n\\\\n[q]  patterns  investigated  (name  of  pattern)\\\\n[q]  quality  attributes  investigated\\\\n[q]  software  metrics  used  (if  any)\\\\n[q]  research  method  used\\\\nall  retained  articles  have  been  examined  by  all  three  authors.\\\\nevery  author  has  completed  data  extraction  for  every  primary\\\\nstudy  separately.',\n",
       "  'for  every  study,  we\\\\nextracted  the  following  data:\\\\n\\\\n[a]  type  of  publication  (journal,  conference,  workshop)\\\\n[a]  published  in  (journal  or  conference  name)\\\\n[a]  year  of  publication\\\\n[a]  keywords  (the  keywords  have  been  extracted  from  authors’\\\\n\\\\nexpert  judgment)\\\\n\\\\ntable  \\\\narticle  inclusion–exclusion  phases.\\\\n\\\\nstep \\\\n\\\\nremaining  papers\\\\n\\\\nidentify  relevant  studies–search  digital  libraries \\\\nexclude  studies  on  the  basis  of  titles \\\\nexclude  studies  on  the  basis  of  abstracts \\\\nobtain  studies  and  select  the  most  relevant  to  design\\\\n\\\\npatterns  on  the  basis  of  full  text\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nthe  data  collected  for  variables,  type  of  publication  (a),  published\\\\nin  (a),  year  of  publication  (a),  and  research  method  used  (q)  were\\\\nused  to  provide  descriptive  statistics,  mostly  frequency  tables,  on\\\\ndesign  pattern  research.',\n",
       "  'our  results,\\\\npointed  out  ﬁve  main  subtopics  on  design  pattern  research,  namely\\\\n(a)  design  pattern  formalization,  (b)  design  pattern  detection,  (c)  effect\\\\nof  design  patterns  on  software  quality,   (d)  design  pattern  application,\\\\nand  (e)  miscellaneous.\\\\n\\\\n..  research  subtopics  activity\\\\n\\\\nthe  results  of  table    suggest  that  the  most  popular  subtopics  of\\\\ndesign  pattern  research  is  design  pattern  detection  and  the  inves-\\\\ntigation  of  the  effect  of  patterns  on  software  quality,  followed  by\\\\ntechniques  for  formulating  design  patterns.\\\\n\\\\nfurthermore,  concerning  the  studies  that  assess  the  effect  of\\\\ndesign  pattern  application  on  software  quality,  we   have  found\\\\nout  that  .%  employ  an  empirical  research  method  (table  ).\\\\nin  (glass  et  al.,  ;  höfer  and  tichy,  ),  it  is  reported  that\\\\nin  general  software  engineering  research,  i.e.,  not  only  design\\\\npattern  research,  the  fraction  of  studies  that  employ  empirical  vali-\\\\ndation  methods  is  between  %  and  %.',\n",
       "  'in  [p,  p,  and  p]  refer  to  patterns’  past,  present  and\\\\nfuture,  they  investigate  run-time  behavior  of  several  patterns  and\\\\npropose  metrics  for  measuring  design  pattern  usage  intensity.\\\\n\\\\ntable  \\\\nkeywords  for  pattern  application.\\\\n\\\\nkeyword \\\\n\\\\nimplementation \\\\n\\\\ntransformation \\\\nautomated  method \\\\nabstraction \\\\nanti-patterns \\\\ngenerative  patterns \\\\njava \\\\npattern  composition\\\\nreengineering \\\\ncomponent  adaptation \\\\ndocumentation \\\\npattern-based  architecting \\\\npractical  experience \\\\nprogramming  language \\\\nreal-time \\\\n\\\\n \\\\n\\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\\\\n#  papers \\\\n\\\\n#  studies \\\\n\\\\npapers\\\\n\\\\n \\\\n\\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\\\\np,  p,  p,  p,  p,\\\\np,  p\\\\np,  p,  p,  p,  p\\\\np,  p,  p,  p\\\\np,  p\\\\np,  p\\\\np,  p\\\\np,  p\\\\np,  p\\\\np,  p\\\\np\\\\np\\\\np\\\\np\\\\np\\\\np\\\\n\\\\ndocumentation \\\\nhtml \\\\nrun-time  behavior \\\\nclient  program \\\\nframework \\\\npattern  application  density \\\\npattern  categorization \\\\ntesting  framework \\\\n\\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\\\\np,  p\\\\np,  p\\\\np,  p\\\\np\\\\np\\\\np\\\\np\\\\np\\\\n\\\\n..  gof  patterns  and  software  quality  attributes\\\\n\\\\nthis  section,  presents  results  for  further  investigating  the  pri-\\\\nmary  studies  that  deal  with  the  effect  of  gof  design  patterns  on\\\\nsoftware  quality  attributes.\\\\n\\\\nin  table  ,  only  the  studies  that  deal  with  the  effect  of  patterns\\\\non  quality  attributes  are  considered  (in  total    primary  studies).\\\\ncomparing  our  retrieved  primary  study  dataset  on  the  effect  of\\\\npatterns  on  software  quality  attributes  with  the  one  of  zhang  and\\\\nbudgen  ()  we   observe  that  we   have  identiﬁed  and  studied  \\\\nadditional  papers.',\n",
       "  '/  the  journal  of  systems  and  software   () –  \\\\n\\\\ntable  \\\\ndata  categorization  overview.\\\\n\\\\nbasic  measures \\\\n\\\\nrq \\\\n\\\\nrq\\\\n\\\\nrq\\\\n\\\\nrq\\\\n\\\\ncount  of  keywords \\\\ncount  of  articles  per  year  for  every  research  subtopic\\\\ncount  of  keywords  per  research  subtopic \\\\ncount   of  research  methods  used  for  investigating  the  effect  of  gof  patterns  on\\\\nsoftware  quality  attributes\\\\n\\\\nmapping  among  design  patterns  &  software  quality  attributes\\\\ncount  of  positive  and  negative  critiques  on  every  pattern–quality  attribute  pair\\\\n\\\\nvariables  used\\\\n\\\\nkeywords  (a)\\\\nyear  of  publication  (a)\\\\ntype  of  publication  (a)\\\\npublished  in  (a)\\\\n\\\\nkeywords  (a)\\\\nresearch  method  used  (q)\\\\npattern  investigated  (q)\\\\nquality  attributes  investigated  (q)\\\\nsoftware  metrics  used  (q)\\\\n\\\\ntable  \\\\nprimary  study  keywords  frequency.\\\\n\\\\nkeyword \\\\n\\\\ndetection \\\\n\\\\nspeciﬁcation \\\\ndetection  algorithm \\\\n\\\\nquality \\\\ndetection  accuracy \\\\n\\\\ndetection  tool \\\\n\\\\ndetection  technique \\\\n\\\\nimplementation \\\\n\\\\nmaintainability \\\\nstructural \\\\nvisualization \\\\n\\\\n \\\\n\\\\n \\\\n \\\\n\\\\n \\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n \\\\n \\\\n\\\\n#  papers \\\\n\\\\n#  studies \\\\n\\\\nbrief  description\\\\n\\\\n \\\\n\\\\n \\\\n \\\\n\\\\n \\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n \\\\n \\\\n\\\\npapers  that  present  algorithms,  tools  or  methods  that  can  be  used  to  identify  gof  design  pattern\\\\ninstances  in  source  or  binary  code.\\\\npapers  that  discuss  possible  ways  of  presenting  and  specifying  gof  design  patterns.\\\\npapers  that  present  algorithms  that  can  be  used  to  identify  gof  design  pattern  instances  in  source\\\\nor   binary  code.\\\\npapers  that  deal  with  the  effect  of  gof  design  patterns  on  software  quality.\\\\npapers  that  deal  with  the  detection  accuracy  of  algorithms,  tools  or  methods  that  can  be  used  to\\\\nidentify  gof  design  pattern  instances  in  source  or  binary  code.\\\\npapers  that  present  tools  that  can  be  used  to  identify  gof  design  pattern  instances  in  source  or\\\\nbinary  code.\\\\npapers  that  present  techniques  that  can  be  used  to  identify  gof  design  pattern  instances  in  source\\\\nor   binary  code.\\\\npapers  that  exhibit  how  gof  design  patterns  can  be  implemented  on  various  languages,  or\\\\nautomatically  applied.\\\\npapers  that  deal  with  the  effect  of  gof  design  patterns  on  software  maintenace.\\\\npapers  that  somehow  deal  with  only  one  category  of  gof  design  patterns,  i.e.'],\n",
       " ['however, their overall conclusion\\\\nwas that performance of the optimization method varies with the\\\\nresearch problem.\\\\n\\\\ncertainly, a more thorough comparison of parameter settings\\\\nfor evosvm is required as this classiﬁer has quite a few parame-\\\\nters.',\n",
       "  \"further, stability of performance for\\\\noptimized classiﬁers needs to be demonstrated over various med-\\\\nical review topics.\\\\n\\\\n']\",\n",
       "  'the task is binary because we want to classify primary\\\\nstudies as being eligible or not for further consideration by the\\\\nreview team.',\n",
       "  '[].',\n",
       "  'their work entailed supervised machine learn-\\\\ning methods and natural language processing to identify rigorous\\\\nclinical trials in broad domains, such as therapy, rather than top-\\\\nical domains deﬁned by review questions.',\n",
       "  'based on the work of\\\\nhaynes and colleagues in a series of papers (e.g., see []), rigor\\\\nwas presumed if trials comparing treatments were randomized and\\\\ncontrolled.',\n",
       "  'however, identifying nonrandomized (nr) studies for\\\\ninclusion in systematic reviews is an important problem because\\\\nrandomized controlled trials (rcts) may be unlikely or even uneth-\\\\nical for some research questions [,].',\n",
       "  'for example, nr studies,\\\\nsuch as case-control, cross-sectional, and cohort studies, are com-\\\\nmonly employed to investigate exposure to environmental hazards,\\\\ndiagnostic test accuracy, disease etiology, human development,\\\\ninvasive surgery, adverse events, and rare disorders.',\n",
       "  'notably, in\\\\nwhat is perhaps the ﬁrst study to use machine learning methods to\\\\nidentify topically relevant trials for inclusion in systematic reviews,\\\\nclassiﬁcation involved randomized and controlled drug trials [],\\\\nwhich is in keeping with the foundational research of [].\\\\n\\\\nfor many review questions, the classiﬁcation task involves a mix\\\\nof designs because reviewers search for nr studies (if eligible) in\\\\naddition to rcts.',\n",
       "  'the latter are preferred because they tend to be\\\\nless biased relative to nr studies.'],\n",
       " ['the method \\\\nemployed for conducting the review is summarized in section  .',\n",
       "  'the method \\\\nemployed for conducting the review is summarized in section  .',\n",
       "  'finally, it gives in- \\\\nformation about the method of deployment of the prototype (i.e.',\n",
       "  'the column “type” in the table speciﬁes the method \\\\nof deployment of the tool i.e.',\n",
       "  '[] proposed a \\\\ndouble-submit cookie method which operates at the client -side for \\\\nprotecting the application against csrf attacks.',\n",
       "  'used for deﬁning mon- \\\\nitoring  properties,  and  event  handlers  that  communicate  the  re- \\\\nsults.',\n",
       "  '\\\\n\\\\nall  the  aforementioned  reviews  focus  on  any  one  of  the  fol- \\\\nlowing aspects: (i) developing a taxonomy for classifying attacks \\\\nand vulnerabilities, (ii) identifying the coding faults that are ex- \\\\nploited for launching attacks, and (iii) classifying the fault monitor- \\\\ning approaches.',\n",
       "  'li and xue [] discussed the various mech- \\\\nanisms employed at the server -side for protecting the web appli- \\\\ncations from vulnerabilities.',\n",
       "  '[] submitted a detailed review \\\\nabout the vulnerable points targeted to launch session hijacking at- \\\\ntacks and the mechanisms available for protecting the users from \\\\nthese types of attacks.',\n",
       "  'wedman et al.'],\n",
       " ['the latter includes the\\\\nmodel training process, classification algorithm, ensem-\\\\nble method and sampling technique used.',\n",
       "  'if the reviewer labels ,\\\\nabstracts, this method reduces their burden by a bit less\\\\nthan half, on average.',\n",
       "  'we plan on assembling -\\\\n systematic review datasets for use in a large-scale\\\\nvalidation of our method.\\\\n\\\\nconclusions\\\\nwe have presented a strategy for semi-automating the\\\\nlaborious, tedious task of citation screening for systema-\\\\ntic reviews, and provided evidence that our method can\\\\nsignificantly reduce reviewers’ workloads.',\n",
       "  'we use\\\\nsvms because they have empirically performed well\\\\nover high-dimensional text data in general [], and in\\\\nthe context of biomedical text classification in particular\\\\n[,].',\n",
       "  'for a recent survey of active learning, see\\\\nsettle’s literature review [].',\n",
       "  'in this work we focus on\\\\npool-based active learning with support vector\\\\nmachines (svms).\\\\n\\\\nbriefly, svms are classifiers that work by finding a\\\\nhyperplane that separates instances into their respective\\\\nclasses in feature-space [].',\n",
       "  'svms use kernel functions\\\\nto calculate the separating hyperplane in a computation-\\\\nally efficient manner, and can scale gracefully to pro-\\\\nblems with high-dimensional data (e.g., text).',\n",
       "  'a kernel\\\\nfunction returns the inner product between feature vec-\\\\ntors mapped into a high-dimensional space.',\n",
       "  'in many\\\\ncases the inner product can be calculated without expli-\\\\ncitly computing these higher dimensional feature vec-\\\\ntors, allowing for fast, scalable computation.',\n",
       "  \"it is a modified version\\\\nof our python-based active learning framework.\\\\nclick here for file\\\\n[ http://www.biomedcentral.com/content/supplementary/---\\\\n-s.zip ]\\\\n\\\\n']\"],\n",
       " ['\\\\nrelated smells: god method ( riel,  ), brain method ( vidal et al.,  ).',\n",
       "  '\\\\nthis smell occurs when a method is too long to understand.',\n",
       "  '\\\\n\\\\nsmell detection method \\\\n\\\\nreference \\\\n\\\\n#smells \\\\n\\\\nlanguages/ artifacts \\\\n\\\\nmetrics-based \\\\n\\\\ndexun et al.',\n",
       "  '\\\\nthis smell occurs when a method accepts a long list of parameters.',\n",
       "  'the table also shows number of smells detected by each \\\\nof the method and target language/artifact.',\n",
       "  'each detection method starts from the code (or source artifact) and goes through various steps to detect smells.',\n",
       "  'on the other hand, if the class \\\\nonly contains data ﬁelds without any method deﬁnition, \\\\nit is a smell.',\n",
       "  '\\\\n\\\\nthis smell occurs when a method seems more interested in a class other than the one it actually is in.',\n",
       "  '\\\\n\\\\neach  detection  method  comes  with  a  set  of  strengths  and \\\\nweaknesses.',\n",
       "  '\\\\n\\\\nreferences \\\\n\\\\ndetection method \\\\n\\\\nmetrics-based \\\\nmetrics-based \\\\nmetrics-based \\\\nmetrics-based \\\\nrule/heuristic-based \\\\nrule/heuristic-based \\\\nmachine learning-based \\\\nrule/heuristic-based \\\\nmetrics-based \\\\nmachine learning-based \\\\nrule/heuristic-based \\\\n\\\\nmarinescu () \\\\nmunro () \\\\nsalehie et al.'],\n",
       " ['the observed rate at which eligible study records were\\\\nidentiﬁed in practice within each consecutive set of prioritised records assigned for manual screening) with\\\\nthe bir (used in this instance as a proxy estimate of the rate at which we would have expected to identify\\\\neligible study records had we used the unobserved counterfactual method of conventional screening).',\n",
       "  'the purpose\\\\nof this method is to act as a counterpoint to the automated technologies; whereas in atr and ac, the results are\\\\nheavily determined by those studies already identiﬁed as being relevant; rt offers another perspective on potential\\\\nrelevance, offering some protection against the problem of hasty generalisation (see main text article, introduction).\\\\nfor further work on the use of rt, see small and colleagues (small et al., ).\\\\n\\\\nhybrids\\\\n\\\\nas well as using each of the previous technologies alone, we also used them in combination with one another\\\\nby ordering the results of the ac using atr or rt.',\n",
       "  \"conservation biology : –.\\\\n\\\\n. ']\",\n",
       "  'the total number of tm prioritised records that\\\\nwe manually screened within the time and resources available for this task was   records.',\n",
       "  'a similar picture emerges from figure , in that initial\\\\nresults from using atr are good, but performance tails off before most relevant studies have been identiﬁed;\\\\na key difference in figure  is that the performance of rt was clearly much poorer than in the ca review\\\\n(figure ).',\n",
       "  'it shows that while atr prioritised screening was much more\\\\neffective than conventional screening to begin with, performance quickly tailed off (atr–) and thereafter, we\\\\nobtained better results from hybrid models and using rt.',\n",
       "  'figures  and  show the\\\\nrelative performance of each tm technology in terms of its associated oir : biru in the ca (figure ) and ee\\\\n(figure ) reviews.\\\\n\\\\nthe lower blue line in figure  shows the sequence in which we used each tm technology in the ca review—\\\\nfrom atr, through hybrid models to using rt.',\n",
       "  'had we used conventional methods, our estimates indicate that we would have identiﬁed\\\\n<% of these further records.\\\\n\\\\nin each review, the overall oir : biru masks considerable variation between the different, sequentially\\\\napplied tm technologies and hybrids in terms of their respective performance.',\n",
       "  'this represents .% of eligible records estimated to be present in the full records set\\\\nafter this point.',\n",
       "  'in the ee\\\\nreview, we identiﬁed and selected a further  provisionally eligible records after the point at which use\\\\nof tm was initiated.'],\n",
       " ['[] introduced a per-question\\\\nclassification method that uses an ensemble of classi-\\\\n\\\\n\\\\xcmo et al.',\n",
       "  'according to\\\\nwallace et al.',\n",
       "  'we then represent each study as a distribution of lda topics.',\n",
       "  'additionally, we enrich topics\\\\nderived using lda with multi-word terms identified by using an automatic term recognition (atr) tool.',\n",
       "  'for evaluation\\\\npurposes, we carry out automatic identification of relevant studies using support vector machine (svm)-based\\\\nclassifiers that employ both our novel topic-based representation and the bow representation.\\\\nresults: our results show that the svm classifier is able to identify a greater number of relevant studies when using\\\\nthe lda representation than the bow representation.',\n",
       "  'these observations hold for two systematic reviews of the\\\\nclinical domain and three reviews of the social science domain.\\\\nconclusions: a topic-based feature representation of documents outperforms the bow representation when\\\\napplied to the task of automatic citation screening.',\n",
       "  'the proposed term-enriched topics are more informative and less\\\\nambiguous to systematic reviewers.\\\\nkeywords: topic model, text mining, machine learning, systematic reviews\\\\n\\\\nbackground\\\\nthe screening phase of systematic reviews aims to iden-\\\\ntify citations relevant to a research topic, according to a\\\\ncertain pre-defined protocol [–] known as the popula-\\\\ntion, the intervention, the comparator and the outcome\\\\n(pico) framework.',\n",
       "  'this framework seeks to identify\\\\nthe population, the intervention, the comparator and\\\\nthe outcome.',\n",
       "  'this process is usually performed man-\\\\nually, which means that reviewers need to read thou-\\\\nsands of citations during the screening phase, due to the\\\\nrapid growth of the biomedical literature [], making it\\\\nan expensive and time-consuming process.',\n",
       "  '[], an experienced reviewer is able to screen\\\\n\\\\n*correspondence: maxmo@gmail.com\\\\nschool of computer science, national centre for text mining, the university of\\\\nmanchester, manchester, uk\\\\n\\\\ntwo abstracts per minute on average, with more com-\\\\nplex abstracts taking longer.'],\n",
       " ['\\\\nresearch method .', \"\\\\n']\", '.', '.', '.', '.', '.', '.', '.', '.'],\n",
       " ['this\\\\nmethod allowed for fall detection through use of the for-\\\\nmer method when there are no significant occlusions, and\\\\nthrough utilization of the latter method when the subject\\\\nis fully occluded after a fall.\\\\n\\\\nthe third method, presented by planinc et al.',\n",
       "  'this\\\\nmethod allowed for fall detection through use of the for-\\\\nmer method when there are no significant occlusions, and\\\\nthrough utilization of the latter method when the subject\\\\nis fully occluded after a fall.\\\\n\\\\nthe third method, presented by planinc et al.',\n",
       "  'if an object falls over, a false positive will\\\\noccur.\\\\n\\\\nthe second method was developed by rougier et al.',\n",
       "  'if an object falls over, a false positive will\\\\noccur.\\\\n\\\\nthe second method was developed by rougier et al.',\n",
       "  'the reported rate of successful\\\\nfall detection utilizing this method on simulated events\\\\nperformed by five participants was as high as %.',\n",
       "  'the reported rate of successful\\\\nfall detection utilizing this method on simulated events\\\\nperformed by five participants was as high as %.',\n",
       "  '[] developed a method of full body\\\\ngait analysis through the use of kinect-based data and a\\\\nmultiple additive regression tree algorithm [,].',\n",
       "  '[] developed a method of full body\\\\ngait analysis through the use of kinect-based data and a\\\\nmultiple additive regression tree algorithm [,].',\n",
       "  'two main\\\\nbenefits cited for this general preference of the kinect-\\\\nonly system were the remote range provided and the\\\\nmore comfortable method of human-computer interac-\\\\ntion.',\n",
       "  'two main\\\\nbenefits cited for this general preference of the kinect-\\\\nonly system were the remote range provided and the\\\\nmore comfortable method of human-computer interac-\\\\ntion.'],\n",
       " [\"\\\\n\\\\n. ']\",\n",
       "  'thus, the \\\\ntesting is performed with a ﬁnite set of test cases, suitably selected \\\\nfrom the usually inﬁnite executions domain, against the expected \\\\nbehavior” [] .',\n",
       "  'furthermore, some of them take into \\\\naccount the changes in the context by providing speciﬁc test cases for each context conﬁguration (static \\\\nperspective) during the test execution.',\n",
       "  'these  studies revealed ﬁve challenges affecting the design of \\\\ntest cases and  challenges regarding the testing of cass.',\n",
       "  'besides, seven tcdt are not empirically eval- \\\\nuated.',\n",
       "  '\\\\nconclusion: a few tcdt partially support the testing of cass.',\n",
       "  'however, it has not been observed evidence \\\\non any tcdt supporting the truly context-aware testing, which that can adapt the expected output based \\\\non the context variation (dynamic perspective) during the test execution.',\n",
       "  'it is an open issue deserving \\\\ngreater attention from researchers to increase the testing coverage and ensure users conﬁdence in cass.',\n",
       "  '\\\\n©  elsevier b.v. all rights reserved.',\n",
       "  \"\\\\n\\\\n. '\"],\n",
       " [\"the trained ann is used to regain a gsr estimate at\\\\nthese four stations, which proves the ann method outperforms the\\\\njapan aerospace exploration agency (jaxa) retrieval method at\\\\nthese sites; moreover, yang's/or young's method also performs\\\\nwell.\",\n",
       "  'the k-fold cross-validation method was\\\\nimplied for mlp forecaster validation.',\n",
       "  'according to experimental results,\\\\nthe proposed method is efﬁcient for such predictions.',\n",
       "  \"the yang's method may retrieve gsr with high accuracy, but\\\\n\\\\ndoes not estimate gsr on regional scales.\",\n",
       "  'according to results, the forecasted series using\\\\nthe proposed method is virtually the same as the tested one with\\\\n\\\\n\\\\xca.',\n",
       "  'the results determine that the radiation\\\\nforecast outcomes are much more precise and better when the\\\\nproposed method is employed.',\n",
       "  'in this paper, the authors developed a reliability-tested, novel\\\\nneural network-based monitoring and fault detection method us-\\\\ning a solar hot water system.',\n",
       "  'the pre-\\\\nsented method can be applied to model systems that are either\\\\ndifﬁcult to model analytically or whose model is not available.',\n",
       "  'presents the research method that was adopted for\\\\n\\\\nsystematic review.\\\\n\\\\n.. planning the review\\\\n\\\\nthis review is planned by proposing research questions relevant\\\\nto the research objectives.',\n",
       "  'in this study, the ann method helped to predict the\\\\nexpected daily energy output for typical operating conditions, as\\\\nwell as the temperature level the storage tank could reach by the\\\\nend of the daily operation cycle.'],\n",
       " ['the incremental cost-effectiveness ratio, or icer [])\\\\nas a result of implementing each of the four variant study\\\\nidentification procedures (process models), compared with\\\\nthe least effective method in terms of its recall.',\n",
       "  'the method applied in the review), members of\\\\nthe ‘case study’ review team prospectively recorded the time\\\\nallocated by each member of research staff to the comple-\\\\ntion of title-abstract and full-text screening, as well as the\\\\ntime allocated to full-text retrieval, and to discuss and re-\\\\nsolve disagreements about the eligibility (coding) of full-text\\\\nstudy reports.',\n",
       "  'finally, the ‘single screening\\\\nwith text mining’ model was selected because text mining\\\\nhas,\\\\nin recent years, been advanced as a tool that can\\\\nsubstantively reduce screening workload in systematic\\\\nreviews; however, further evaluation is needed before it can\\\\nbe considered a reliable and widely accepted approach\\\\n[–].\\\\n‘safety first’ was the method actually applied in\\\\nthe ‘case study’ systematic review.',\n",
       "  'while one of\\\\nthe ‘false negative’ studies did provide a distinctive per-\\\\nspective concerning the influence of workplace-based\\\\nlearning in general practice on patient care [], we be-\\\\nlieve this study would have been identified by one of the\\\\ntwo complementary search methods deployed in the ‘case\\\\n\\\\nstudy’ review (namely, stakeholder consultation; the other\\\\ncomplementary search method used, namely backward\\\\ncitation tracking [, ], would not have identified this\\\\nstudy as it was not cited in reference lists of studies incor-\\\\nporated into the in-depth syntheses).',\n",
       "  'to reflect our strong\\\\naversion to excluding a record of a study that in fact meets\\\\neligibility criteria: a ‘false negative’), compared with the\\\\nleast effective model in terms of its recall.',\n",
       "  'next, two reviewers (r and r) are allocated se-\\\\nquential batches of the same – title-abstract records\\\\nfor independent manual screening.',\n",
       "  'systematic reviews  () : \\\\n\\\\npage  of \\\\n\\\\nsafety first\\\\nthe first step in the ‘safety first’ process model (as in all\\\\nfour approaches) is that all title-abstract records retrieved\\\\nby electronic searches and other search methods are\\\\nuploaded to a screening platform [] and de-duplicated,\\\\nwith unique records entering the title-abstract screening\\\\nstage.',\n",
       "  'each of the four variant\\\\napproaches (process models) is described below.\\\\n\\\\n\\\\xcshemilt et al.',\n",
       "  'these can be viewed,\\\\nrespectively, as representing more (‘safety first’) and less\\\\n(‘single screening’) cautious approaches to the title-abstract\\\\nscreening stage (see below).',\n",
       "  'two of\\\\nthe other three ‘process models’ were selected for investiga-\\\\ntion because they are commonly used variants on a conven-\\\\ntional ‘double screening’ approach.'],\n",
       " ['method  involved selecting the\\\\nnegative examples whose average distances (a measure of\\\\nsimilarity/dissimilarity) to the three farthest positive exam-\\\\nples are the smallest; method  involved selecting the\\\\nnegative examples whose average distances to the three\\\\nclosest positive examples are the smallest; method  in-\\\\nvolved selecting the negative examples whose average dis-\\\\ntances to the three closest positive examples are the\\\\nlargest; method  involved removing those examples that\\\\nparticipated in tomek links (see [] for a definition);\\\\nmethod  involved selecting negative examples randomly.\\\\nma concluded that random undersampling did not per-\\\\nform the best.',\n",
       "  'generally, the weight is set to the ratio of the\\\\nnumber of positive instances to the number of negative\\\\ninstances.\\\\n\\\\ncompared to an un-weighted method or an aggressive\\\\nundersampling method (described below), miwa et al.\\\\nreported better performance of active learning models\\\\non a variety of imbalanced datasets [].',\n",
       "  'london: eppi-centre software, social science research unit,\\\\ninstitute of education; .\\\\njonnalagadda s, petitti d. a new iterative method to reduce workload in\\\\nsystematic review process.',\n",
       "  'if there are only a small\\\\nnumber of includable studies in the entire dataset, then\\\\nsuch penalties might not be implementable.\\\\n\\\\nhuman input\\\\nma proposed using active learning as a method for as-\\\\nsuring high recall [].',\n",
       "  'the\\\\nremaining  evaluations do not compare aspects of the\\\\nmethodology; rather, they report on the effectiveness of\\\\none chosen method for implementing text mining\\\\n[,,,,,,-,,,,-].\\\\n\\\\nunsurprisingly, study design is associated with certain\\\\ntypes of comparisons (see table ).',\n",
       "  'that is,\\\\nthe record must present a detailed method or\\\\nevaluation of a method.\\\\n\\\\nthe second stage of screening was conducted by one\\\\nresearcher (aom), with queried records checked by the\\\\nsecond researcher (jt) (reviewer agreement was % at\\\\nthis stage).',\n",
       "  'this\\\\nsolution is clearly only possible when two reviewers are\\\\nreviewing every abstract—something which is common,\\\\nbut by no means universal, practice.\\\\n\\\\nfurther information on this topic\\\\na machine learning-based method able to deal with\\\\nover-inclusive screening as well as data imbalance is\\\\ncost-sensitive learning [].',\n",
       "  'whilst the con-\\\\ncept of obtaining an unbiased set of training material\\\\nusing a random sample is widely employed, wallace and\\\\n\\\\ncolleagues have outlined an explicit iterative method to\\\\ndetermine whether the variation in likely ‘includes’ has\\\\nbeen explored adequately enough for active learning to\\\\nbegin [].',\n",
       "  'they\\\\nfound that text mining performance was slightly poorer\\\\nin the social scientific literature than the clinical domain\\\\nand that certain enhancements could improve this.\\\\n\\\\nwallace and colleagues suggest a method to be used\\\\nin review updates which enable reviewers to determine\\\\nwhether a semi-automated approach is viable [].',\n",
       "  'systematic reviews , :\\\\nhttp://www.systematicreviewsjournal.com/content///\\\\n\\\\npage  of \\\\n\\\\nbackground\\\\nthe problem: lack of precision in systematic searches\\\\nsystematic reviews are a widely used method to bring\\\\ntogether the findings from multiple studies in a reliable\\\\nway and are often used to inform policy and practice,\\\\nsuch as guideline development [,].'],\n",
       " [\"\\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\n \\\\n\\\\nmanuscript acceptedaccepted manuscript\\\\xc. ']\",\n",
       "  '*  .',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n\\\\n.',\n",
       "  '\\\\n.',\n",
       "  '\\\\n.']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\noverview of systematic literature review method .',\n",
       " '\\\\noverview of systematic literature review method .',\n",
       " '\\\\noverview of systematic literature review method .',\n",
       " \"\\\\n']\",\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('conclusion', 'NN', 'O'), ('and', 'CC', 'O'), ('discussion', 'NN', 'O'), ('and', 'CC', 'O'), ('justification', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word conclusion is extracted and added to the query list\n",
      "The word discussion is extracted and added to the query list\n",
      "The word justification is extracted and added to the query list\n"
     ]
    }
   ],
   "source": [
    "#To fetch the conclusion for each paper\n",
    "QA3 = extractConclusion(other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_cleaned\n",
    "def clean(data):\n",
    "    data_cleaned=[]\n",
    "    for line in data:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r'\\d+', '', line)\n",
    "        #line = re.sub(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+','', line)\n",
    "        #line = line.translate(str.maketrans('','', string.punctuation))\n",
    "        #line = line.strip()\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        line = line.replace(\"\\\\n\", \"\")\n",
    "        #line = sent_tokenize(line)\n",
    "        \n",
    "        data_cleaned.append(line)\n",
    "    return data_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA1_Data = []\n",
    "for k in range(len(QA1)):\n",
    "    CleanedData = (QA1[k])\n",
    "    CleanedData = clean(CleanedData)\n",
    "    QA1_Data.append(CleanedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA2_Data = []\n",
    "for l in range(len(QA2)):\n",
    "    CleanedData = (QA2[l])\n",
    "    CleanedData = clean(CleanedData)\n",
    "    QA2_Data.append(CleanedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA3_Data = []\n",
    "for m in range(len(QA3)):\n",
    "    CleanedData = (QA1[m])\n",
    "    CleanedData = clean(CleanedData)\n",
    "    QA3_Data.append(CleanedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the respective answers for the QA1\n",
    "#Is the aim and the objective stated clearly?\n",
    "QA1_Ans = {'PDFName': [], 'QA1_ans': [] }\n",
    "for c,d in zip(files, QA1_Data):    \n",
    "    QA1_Ans['PDFName'].append(c)\n",
    "    QA1_Ans['QA1_ans'].append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the respective answers for the QA2\n",
    "#This can answer two questions partially \n",
    "#Adequate description of the sample used and the methods for identifying and recruiting the sample\n",
    "#Adequate description of methods used to analyse the data (partially)\n",
    "QA2_Ans = {'PDFName': [], 'QA2_ans': [] }\n",
    "for e,f in zip(files, QA2_Data):    \n",
    "    QA2_Ans['PDFName'].append(e)\n",
    "    QA2_Ans['QA2_ans'].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the respective answers for the QA3\n",
    "#Does the study provide clearly stated findings with credible results and justified conclusions\n",
    "QA3_Ans = {'PDFName': [], 'QA3_ans': [] }\n",
    "for g,h in zip(files, QA3_Data):    \n",
    "    QA3_Ans['PDFName'].append(g)\n",
    "    QA3_Ans['QA3_ans'].append(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the answers to the QA1,QA2,QA3 to .xslx\n",
    "\n",
    "#the final results are exported to the excel to let the user read it and score/assess the paper accordingly\n",
    "from pandas import DataFrame\n",
    "\n",
    "df1 = DataFrame(QA1_Ans, columns= ['PDFName', 'QA1_ans'])\n",
    "export_excel = df1.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\QA1_Answer.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n",
    "\n",
    "df2 = DataFrame(QA2_Ans, columns= ['PDFName', 'QA2_ans'])\n",
    "export_excel = df2.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\QA2_Answer.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n",
    "\n",
    "df3 = DataFrame(QA3_Ans, columns= ['PDFName', 'QA3_ans'])\n",
    "export_excel = df3.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\QA3_Answer.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
