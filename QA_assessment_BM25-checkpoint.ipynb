{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pooja Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.image import ImageWriter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from pathlib import *\n",
    "\n",
    "import time\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import operator\n",
    "\n",
    "from nltk.chunk import tree2conlltags\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfRender():\n",
    "    global documentSet\n",
    "    global mydoc\n",
    "    mydoc ={}\n",
    "    pdf_files =[]\n",
    "    allLines =[]\n",
    "    FILE_PATH = Path(r'E:\\MasterThesis\\FinalPapers\\papersforQAModelling\\test')\n",
    "    #FILE_PATH = Path(r'E:\\MasterThesis\\FinalPapers\\papersforQAModelling')\n",
    "    #FILE_PATH = Path('E:/MasterThesis/FinalPapers')\n",
    "    pdf_files = list(FILE_PATH.glob('*.pdf'))\n",
    "    #An Array which stores the full text of each document\n",
    "    documentSet = pdfparser(pdf_files)\n",
    "    mydoc = dict(zip(pdf_files,documentSet))\n",
    "    #print(len(documentSet))\n",
    "    return documentSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(rawContents):    \n",
    "    cleaned = tokenizeContent(rawContents)    \n",
    "    cleaned1 = removeStopWordsFromTokenized(cleaned)    \n",
    "    cleaned2 = performPorterStemmingOnContents(cleaned1)    \n",
    "    cleaned3 = removePunctuationFromTokenized(cleaned2)    \n",
    "    cleaned4 = convertItemsToLower(cleaned3)    \n",
    "    return cleaned4    \n",
    "        \n",
    "def tokenizeContent(contentsRaw):    \n",
    "    tokenized = nltk.tokenize.sent_tokenize(contentsRaw)    \n",
    "    return tokenized    \n",
    "    \n",
    "def removeStopWordsFromTokenized(contentsTokenized):    \n",
    "    stop_word_set = set(nltk.corpus.stopwords.words(\"english\"))    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in stop_word_set]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def performPorterStemmingOnContents(contentsTokenized):    \n",
    "    porterStemmer = nltk.stem.PorterStemmer()    \n",
    "    filteredContents = [porterStemmer.stem(word) for word in contentsTokenized]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def removePunctuationFromTokenized(contentsTokenized):    \n",
    "    excludePuncuation = set(string.punctuation)    \n",
    "    \n",
    "    # manually add additional punctuation to remove    \n",
    "    doubleSingleQuote = '\\'\\''    \n",
    "    doubleDash = '--'    \n",
    "    doubleTick = '``'    \n",
    "    \n",
    "    excludePuncuation.add(doubleSingleQuote)    \n",
    "    excludePuncuation.add(doubleDash)    \n",
    "    excludePuncuation.add(doubleTick)    \n",
    "    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in excludePuncuation]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def convertItemsToLower(contentsRaw):    \n",
    "    filteredContents = [term.lower() for term in contentsRaw]    \n",
    "    return filteredContents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfparser(pdffileS):\n",
    "    global finalDocumentSet\n",
    "    finalDocumentSet = []\n",
    "    global pdfEx\n",
    "    pdfEx = []\n",
    "    global fullText\n",
    "    for pdffile in pdffileS:\n",
    "        #full= fullText\n",
    "        # Create a example words list(Please add all the related keywords needed)\n",
    "        words_list = [\"Introduction\", \"INTRODUCTION\", \"Background\", \"BACKGROUND\", \"Objective\",\"Objectives\", \"Methods\"]\n",
    "        #print(words_list)\n",
    "        with open(pdffile, mode='rb') as f:\n",
    "            fullText = np.array([])\n",
    "            pdfName = os.path.basename(pdffile)\n",
    "            print(pdfName)\n",
    "            #documents = fullText\n",
    "            #words_list = []\n",
    "            #print(words_list)\n",
    "            #fp = open(data, 'rb')\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            retstr = io.StringIO()\n",
    "            codec = 'utf-8'\n",
    "            laparams = LAParams()\n",
    "            data =[]\n",
    "            details_page = []\n",
    "            abstract = []\n",
    "            device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "            # Create a PDF interpreter object.\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            # Process each page contained in the document.\n",
    "            count = 0\n",
    "            for page in PDFPage.get_pages(f):\n",
    "                interpreter.process_page(page)\n",
    "                data = retstr.getvalue()\n",
    "                details_page.append(data)\n",
    "\n",
    "            #print(\"There are\", len(words_list), \"in the words list\")\n",
    "            stri = \" \"\n",
    "            details = stri.join(details_page)\n",
    "            words = details.split()\n",
    "            place = []\n",
    "            dummy_check = []\n",
    "            removed_words = []\n",
    "\n",
    "            print(words_list)\n",
    "            for c, a in enumerate(words):\n",
    "                for b in words_list:\n",
    "                    if b == a and b not in dummy_check:\n",
    "                        print(b, a)\n",
    "                        place.append(details.find(\"{}\".format(b)))\n",
    "                        dummy_check.append(b)\n",
    "                    #  place.append(words.index(a))\n",
    "                    elif b not in words:\n",
    "                        print(b)\n",
    "                        removed_words.append(b)\n",
    "                        words_list.remove(b)\n",
    "                        print(\"The word\", b, \"was not found in the pdf file\")\n",
    "\n",
    "            #print(list(zip(words_list, place)))\n",
    "            final_array = list(zip(words_list, place))\n",
    "            #final_array.sort()\n",
    "            final_array.sort(key=operator.itemgetter(1))\n",
    "            # print(\"Sorting the final array\")\n",
    "            #print(final_array)\n",
    "\n",
    "            # print(\"Extracting the relevant texts from pdf\")\n",
    "            # print(\" \")\n",
    "            print(final_array)\n",
    "            if len(final_array) > 1:\n",
    "                listint = final_array[0]\n",
    "                list2int = final_array[1]\n",
    "                counter = 0\n",
    "\n",
    "                for each in (final_array):\n",
    "                    if counter < len(final_array) - 2:\n",
    "                        new = (details.split(listint[0])[1].split(list2int[0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #print(listint[0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        #print(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        counter = counter + 1\n",
    "                        listint = final_array[0 + counter]\n",
    "                        list2int = final_array[1 + counter]\n",
    "\n",
    "                    elif counter < len(final_array) - 1:\n",
    "                        new = (details.split(final_array[counter][0])[1].split(final_array[counter + 1][0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        counter = counter + 1\n",
    "\n",
    "                    else:\n",
    "                        new = (details.split(final_array[counter][0])[1])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "            else:\n",
    "                new = (details.split(final_array[0][0])[1])\n",
    "                # new = sent_tokenize(new)\n",
    "                #documents.append(new)\n",
    "                fullText = np.append(fullText, new)\n",
    "                # print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                # print(\" \")\n",
    "                \n",
    "        #finalDocumentSet = {pdfName : fullText}\n",
    "        \n",
    "        data=finalDocumentSet.append(fullText)\n",
    "        myName=pdfEx.append(pdfName)\n",
    "        #print(\"Testing==\",finalDocumentSet)\n",
    "        #data = finalDocumentSet.get(pdfName)\n",
    "        #finalDocumentSet = finalDocumentSet\n",
    "        data = str(data)\n",
    "        \n",
    "        data = processData(data)\n",
    "        #data = data.replace(r'\\\\n', \"\")\n",
    "        data = [i.replace('\\\\n', \"\") for i in data]\n",
    "        data = [i.replace('\\\\x0', \"\") for i in data]\n",
    "        words_list = words_list + removed_words\n",
    "        print(\"Updated words list:\")\n",
    "        print(words_list)\n",
    "\n",
    "    #print(len(finalDocumentSet))\n",
    "    \n",
    "    #mydoc = dict(zip(myName,data))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-survey-of-prevalence-of-narrative-and-systematic-reviews-in-five-major-medical-journals2017BMC-Medical-Research-MethodologyOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Objective', 'Objectives', 'Methods']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Objectives\n",
      "The word Objectives was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Objective\n",
      "The word Objective was not found in the pdf file\n",
      "Background Background\n",
      "Methods Methods\n",
      "[('Background', 300), ('Methods', 1051)]\n",
      "Updated words list:\n",
      "['Background', 'Methods', 'Introduction', 'BACKGROUND', 'Objectives', 'INTRODUCTION', 'Objective']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['none']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(finalDocumentSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in f:\\python\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: numpy in f:\\python\\lib\\site-packages (from rank-bm25) (1.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens_questions(question):\n",
    "    tokenized_question = question.split()\n",
    "    create_chunks = nltk.ne_chunk(nltk.pos_tag(tokenized_question))\n",
    "    assign_pos_tags = tree2conlltags(create_chunks)\n",
    "    return assign_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos(question):\n",
    "    noun_add = []\n",
    "    assign_pos_tags = create_tokens_questions(question)\n",
    "    print(assign_pos_tags)\n",
    "    for i in range(0, len(assign_pos_tags) - 1):\n",
    "        if (assign_pos_tags[i][1] == 'NN' and assign_pos_tags[i + 1][1] == 'NN'):\n",
    "            extract_nouns = assign_pos_tags[i] + assign_pos_tags[i + 1]\n",
    "            noun_add.append(extract_nouns)\n",
    "\n",
    "        elif assign_pos_tags[i][1] == 'NNP':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "        elif assign_pos_tags[i][1] == 'NN':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "    return noun_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_document = finalDocumentSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDocs = []\n",
    "def conductSentenceExtraction_Objective():\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in demo_document]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    question = \"What are the aim and objective of the study?\"\n",
    "    noun_add = extract_pos(question)\n",
    "    print(noun_add)\n",
    "    get_final_results = bm25.get_top_n(noun_add, demo_document, n=10)\n",
    "    rawDocs.append(get_final_results)\n",
    "    #print(get_final_results)\n",
    "    return rawDocs\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP', 'O'), ('are', 'VBP', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('the', 'DT', 'O'), ('study?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "['aim', 'objective']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[': We surveyed the five highest-ranked medical journals (The New England Journal of Medicine, The Lancet, The\\nJournal of the American Medical Association, The BMJ, and Annals of Internal Medicine) for narrative and systematic reviews\\npublished between June 2015 and June 2016. We independently selected and extracted the data from the\\nreviews by strictly following the pre-determined eligibility criteria (Systematic and narrative reviews that focused on\\nthe management of diseases). We conducted regression analyses to investigate the associations among review type,\\nnumber of citations, and IF. We also descriptively reported narrative reviews containing some methodology that might\\nbe reproducible.\\nResults: Two hundred seventy-five reviews were included: 75 (27%) systematic; 126 (46%) narrative with some\\nmethodology reported, and 74 (27%) narrative reviews. In comparison to systematic reviews, narrative reviews\\nwere more frequently published in journals with higher IF (risk ratio [RR] = 1.114 (95% CI 1.080 to 1.149). Systematic reviews\\nreceived more citations than narrative reviews (group formed by narrative and narrative with some methodology reported\\n(RR = 0.985 95% CI 0.978 to 0.991).\\nConclusions: Non-systematic evidence is the most prevalent type of evidence in reviews published in the five highest-ranked\\ngeneral medical journals. Narrative reviews were more frequently published in journals with higher IF. We recommend that\\njournals limit their space for narrative information, and to address clinical research questions, these journals consider\\npublishing systematic evidence exclusively.\\nKeywords: Review, Systematic review, Bias, Methodological study, Journal impact factor\\n\\n* Correspondence: clovisfaggion@yahoo.com; clovisfaggionjr@gmail.com\\n1Department of Periodontology and Operative Dentistry, Faculty of Dentistry,\\nUniversity of Münster, Waldeyerstraße 30, 48149 Münster, Germany\\nFull list of author information is available at the end of the article\\n\\n© The Author(s). 2017 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0\\nInternational License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and\\nreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\\nthe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver\\n(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.\\n\\n\\x0c Faggion et al. BMC Medical Research Methodology  (2017) 17:176 \\nDOI 10.1186/s12874-017-0453-y\\n\\nR ES EAR CH A R T I C LE\\nA survey of prevalence of narrative and\\nsystematic reviews in five major medical\\njournals\\nClovis Mariano Faggion Jr1*, Nikolaos P. Bakas2 and Jason Wasiak3\\n\\nOpen Access\\n\\nAbstract\\n\\nBackground: Systematic reviews may provide less biased evidence than narrative reviews because they observe a\\nstrict methodology, similarly to primary studies. Hence, for clinical research questions, systematic reviews should be\\nthe study design of choice. It would be important to evaluate the prevalence and characteristics of narrative and\\nsystematic reviews published in prominent medical journals. Researchers and clinicians give great value to articles\\npublished in such scientific journals. This study sought to evaluate the prevalence and characteristics of narrative and\\nsystematic reviews in the five highest-ranked general medical journals and investigate the associations among type of\\nreview, number of citations, and impact factor (IF).\\n',\n",
       "  ': Systematic reviews may provide less biased evidence than narrative reviews because they observe a\\nstrict methodology, similarly to primary studies. Hence, for clinical research questions, systematic reviews should be\\nthe study design of choice. It would be important to evaluate the prevalence and characteristics of narrative and\\nsystematic reviews published in prominent medical journals. Researchers and clinicians give great value to articles\\npublished in such scientific journals. This study sought to evaluate the prevalence and characteristics of narrative and\\nsystematic reviews in the five highest-ranked general medical journals and investigate the associations among type of\\nreview, number of citations, and impact factor (IF).\\n']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conductSentenceExtraction_Objective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"[': we surveyed the five highest-ranked medical journals (the new england journal of medicine, the lancet, thejournal of the american medical association, the bmj, and annals of internal medicine) for narrative and systematic reviewspublished between june 2015 and june 2016.\", 'we independently selected and extracted the data from thereviews by strictly following the pre-determined eligibility criteria (systematic and narrative reviews that focused onthe management of diseases).', 'we conducted regression analyses to investigate the associations among review type,number of citations, and if.', 'we also descriptively reported narrative reviews containing some methodology that mightbe reproducible.results: two hundred seventy-five reviews were included: 75 (27%) systematic; 126 (46%) narrative with somemethodology reported, and 74 (27%) narrative reviews.', 'in comparison to systematic reviews, narrative reviewswere more frequently published in journals with higher if (risk ratio [rr] = 1.114 (95% ci 1.080 to 1.149).', 'systematic reviewsreceived more citations than narrative reviews (group formed by narrative and narrative with some methodology reported(rr = 0.985 95% ci 0.978 to 0.991).conclusions: non-systematic evidence is the most prevalent type of evidence in reviews published in the five highest-rankedgeneral medical journals.', 'narrative reviews were more frequently published in journals with higher if.', 'we recommend thatjournals limit their space for narrative information, and to address clinical research questions, these journals considerpublishing systematic evidence exclusively.keywords: review, systematic review, bias, methodological study, journal impact factor* correspondence: clovisfaggion@yahoo.com; clovisfaggionjr@gmail.com1department of periodontology and operative dentistry, faculty of dentistry,university of münster, waldeyerstraße 30, 48149 münster, germanyfull list of author information is available at the end of the article© the author(s).', '2017 open access this article is distributed under the terms of the creative commons attribution 4.0international license (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, andreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link tothe creative commons license, and indicate if changes were made.', 'the creative commons public domain dedication waiver(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.c faggion et al.', 'bmc medical research methodology  (2017) 17:176 doi 10.1186/s12874-017-0453-yr es ear ch a r t i c lea survey of prevalence of narrative andsystematic reviews in five major medicaljournalsclovis mariano faggion jr1*, nikolaos p. bakas2 and jason wasiak3open accessabstractbackground: systematic reviews may provide less biased evidence than narrative reviews because they observe astrict methodology, similarly to primary studies.', 'hence, for clinical research questions, systematic reviews should bethe study design of choice.', 'it would be important to evaluate the prevalence and characteristics of narrative andsystematic reviews published in prominent medical journals.', 'researchers and clinicians give great value to articlespublished in such scientific journals.', \"this study sought to evaluate the prevalence and characteristics of narrative andsystematic reviews in the five highest-ranked general medical journals and investigate the associations among type ofreview, number of citations, and impact factor (if).', ': systematic reviews may provide less biased evidence than narrative reviews because they observe astrict methodology, similarly to primary studies.\", 'hence, for clinical research questions, systematic reviews should bethe study design of choice.', 'it would be important to evaluate the prevalence and characteristics of narrative andsystematic reviews published in prominent medical journals.', 'researchers and clinicians give great value to articlespublished in such scientific journals.', \"this study sought to evaluate the prevalence and characteristics of narrative andsystematic reviews in the five highest-ranked general medical journals and investigate the associations among type ofreview, number of citations, and impact factor (if).']\"]]\n"
     ]
    }
   ],
   "source": [
    "demoDoc = []\n",
    "for i in range(len(rawDocs)):\n",
    "    doc = str(rawDocs[i])\n",
    "    doc = processData(doc)\n",
    "    doc = [i.replace('\\\\n', \"\") for i in doc]\n",
    "    doc = [i.replace('\\\\x0', \"\") for i in doc]\n",
    "    demoDoc.append(doc)\n",
    "print(demoDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(finalDocumentSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
