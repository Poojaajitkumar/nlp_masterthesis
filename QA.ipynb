{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pooja Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Pooja\n",
      "[nltk_data]     Ajit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.image import ImageWriter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from pathlib import *\n",
    "\n",
    "import time\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import operator\n",
    "\n",
    "from nltk.chunk import tree2conlltags\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfRender():\n",
    "    global documentSet\n",
    "    global mydoc\n",
    "    mydoc ={}\n",
    "    pdf_files =[]\n",
    "    allLines =[]\n",
    "    FILE_PATH = Path(r'E:\\MasterThesis\\FinalPapers\\testData_91\\LDA')\n",
    "    #FILE_PATH = Path('E:/MasterThesis/FinalPapers')\n",
    "    pdf_files = list(FILE_PATH.glob('*.pdf'))\n",
    "    #An Array which stores the full text of each document\n",
    "    documentSet = pdfparser(pdf_files)\n",
    "    mydoc = dict(zip(pdf_files,documentSet))\n",
    "    #print(len(documentSet))\n",
    "    return documentSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pdfparser(pdffileS):\n",
    "    global finalDocumentSet\n",
    "    finalDocumentSet = []\n",
    "    global pdfEx\n",
    "    pdfEx = []\n",
    "    global files\n",
    "    global fullText\n",
    "    files = []\n",
    "    for pdffile in pdffileS:\n",
    "        #full= fullText\n",
    "        # Create a example words list(Please add all the related keywords needed)\n",
    "        words_list = [\"Introduction\", \"INTRODUCTION\", \"Background\", \"BACKGROUND\", \"Conclusion\", \"Conclusions\",\n",
    "                      \"CONCLUSION\", \"Acknowledgements\"]\n",
    "        #print(words_list)\n",
    "        pdfName = os.path.basename(pdffile)\n",
    "        files.append(pdfName)\n",
    "        with open(pdffile, mode='rb') as f:\n",
    "            fullText = np.array([])\n",
    "            print(pdfName)\n",
    "            #files.append(pdfName)\n",
    "            #documents = fullText\n",
    "            #words_list = []\n",
    "            #print(words_list)\n",
    "            #fp = open(data, 'rb')\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            retstr = io.StringIO()\n",
    "            codec = 'utf-8'\n",
    "            laparams = LAParams()\n",
    "            data =[]\n",
    "            details_page = []\n",
    "            abstract = []\n",
    "            device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "            # Create a PDF interpreter object.\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            # Process each page contained in the document.\n",
    "            count = 0\n",
    "            for page in PDFPage.get_pages(f):\n",
    "                interpreter.process_page(page)\n",
    "                data = retstr.getvalue()\n",
    "                details_page.append(data)\n",
    "\n",
    "            #print(\"There are\", len(words_list), \"in the words list\")\n",
    "            stri = \" \"\n",
    "            details = stri.join(details_page)\n",
    "            words = details.split()\n",
    "            place = []\n",
    "            dummy_check = []\n",
    "            removed_words = []\n",
    "\n",
    "            print(words_list)\n",
    "            for c, a in enumerate(words):\n",
    "                for b in words_list:\n",
    "                    if b == a and b not in dummy_check:\n",
    "                        print(b, a)\n",
    "                        place.append(details.find(\"{}\".format(b)))\n",
    "                        dummy_check.append(b)\n",
    "                    #  place.append(words.index(a))\n",
    "                    elif b not in words:\n",
    "                        print(b)\n",
    "                        removed_words.append(b)\n",
    "                        words_list.remove(b)\n",
    "                        print(\"The word\", b, \"was not found in the pdf file\")\n",
    "\n",
    "            #print(list(zip(words_list, place)))\n",
    "            final_array = list(zip(words_list, place))\n",
    "            #final_array.sort()\n",
    "            final_array.sort(key=operator.itemgetter(1))\n",
    "            # print(\"Sorting the final array\")\n",
    "            #print(final_array)\n",
    "\n",
    "            # print(\"Extracting the relevant texts from pdf\")\n",
    "            # print(\" \")\n",
    "            print(final_array)\n",
    "            if len(final_array) > 1:\n",
    "                listint = final_array[0]\n",
    "                list2int = final_array[1]\n",
    "                counter = 0\n",
    "\n",
    "                for each in (final_array):\n",
    "                    if counter < len(final_array) - 2:\n",
    "                        new = (details.split(listint[0])[1].split(list2int[0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #print(listint[0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        #print(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        counter = counter + 1\n",
    "                        listint = final_array[0 + counter]\n",
    "                        list2int = final_array[1 + counter]\n",
    "\n",
    "                    elif counter < len(final_array) - 1:\n",
    "                        new = (details.split(final_array[counter][0])[1].split(final_array[counter + 1][0])[0])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "                        counter = counter + 1\n",
    "\n",
    "                    else:\n",
    "                        new = (details.split(final_array[counter][0])[1])\n",
    "                        #new = sent_tokenize(new)\n",
    "                        #documents.append(new)\n",
    "                        fullText = np.append(fullText, new)\n",
    "                        #print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                        #print(\" \")\n",
    "            else:\n",
    "                new = (details.split(final_array[0][0])[1])\n",
    "                # new = sent_tokenize(new)\n",
    "                #documents.append(new)\n",
    "                fullText = np.append(fullText, new)\n",
    "                # print(final_array[counter][0], \":\", [' '.join(new)])\n",
    "                # print(\" \")\n",
    "                \n",
    "        #finalDocumentSet = {pdfName : fullText}\n",
    "        \n",
    "        data=finalDocumentSet.append(fullText)\n",
    "        myName=pdfEx.append(pdfName)\n",
    "        #print(\"Testing==\",finalDocumentSet)\n",
    "        #data = finalDocumentSet.get(pdfName)\n",
    "        #finalDocumentSet = finalDocumentSet\n",
    "        data = str(data)\n",
    "        \n",
    "        data = processData(data)\n",
    "        #data = data.replace(r'\\\\n', \"\")\n",
    "        data = [i.replace('\\\\n', \"\") for i in data]\n",
    "        data = [i.replace('\\\\x0', \"\") for i in data]\n",
    "        words_list = words_list + removed_words\n",
    "        print(\"Updated words list:\")\n",
    "        print(words_list)\n",
    "\n",
    "    #print(len(finalDocumentSet))\n",
    "    \n",
    "    #mydoc = dict(zip(myName,data))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(rawContents):    \n",
    "    cleaned = tokenizeContent(rawContents)    \n",
    "    cleaned1 = removeStopWordsFromTokenized(cleaned)    \n",
    "    cleaned2 = performPorterStemmingOnContents(cleaned1)    \n",
    "    cleaned3 = removePunctuationFromTokenized(cleaned2)    \n",
    "    cleaned4 = convertItemsToLower(cleaned3)    \n",
    "    return cleaned4    \n",
    "        \n",
    "def tokenizeContent(contentsRaw):    \n",
    "    tokenized = nltk.tokenize.sent_tokenize(contentsRaw)    \n",
    "    return tokenized    \n",
    "    \n",
    "def removeStopWordsFromTokenized(contentsTokenized):    \n",
    "    stop_word_set = set(nltk.corpus.stopwords.words(\"english\"))    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in stop_word_set]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def performPorterStemmingOnContents(contentsTokenized):    \n",
    "    porterStemmer = nltk.stem.PorterStemmer()    \n",
    "    filteredContents = [porterStemmer.stem(word) for word in contentsTokenized]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def removePunctuationFromTokenized(contentsTokenized):    \n",
    "    excludePuncuation = set(string.punctuation)    \n",
    "    \n",
    "    # manually add additional punctuation to remove    \n",
    "    doubleSingleQuote = '\\'\\''    \n",
    "    doubleDash = '--'    \n",
    "    doubleTick = '``'    \n",
    "    \n",
    "    excludePuncuation.add(doubleSingleQuote)    \n",
    "    excludePuncuation.add(doubleDash)    \n",
    "    excludePuncuation.add(doubleTick)    \n",
    "    \n",
    "    filteredContents = [word for word in contentsTokenized if word not in excludePuncuation]    \n",
    "    return filteredContents    \n",
    "    \n",
    "def convertItemsToLower(contentsRaw):    \n",
    "    filteredContents = [term.lower() for term in contentsRaw]    \n",
    "    return filteredContents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1002@asi.23250.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1649), ('Conclusion', 10356)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "10.1002@jrsm.1094.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 1849), ('Conclusion', 189547), ('Acknowledgements', 231278)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusion', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'Conclusions', 'INTRODUCTION', 'CONCLUSION']\n",
      "A-systematic-literature-review-of-actionable-alert-identification-techniques-for-automated-static-code-analysis2011Information-and-Software-Technology.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Acknowledgements Acknowledgements\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2948), ('Acknowledgements', 22793), ('Conclusions', 23242)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "Application-of-distance-measurement-NLP-methods-for-address-and-location-matching-in-logistics2020Studies-in-Computational-Intelligence.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1002), ('Conclusion', 157828)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Background', 'CONCLUSION']\n",
      "Effective-study-selection-using-text-mining-or-a-singlescreening-approach-A-study-protocol2018Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 342), ('Acknowledgements', 86289)]\n",
      "Updated words list:\n",
      "['Background', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'Conclusions', 'INTRODUCTION', 'Conclusion', 'CONCLUSION']\n",
      "Entity-reconciliation-in-big-data-sources-A-systematic-mapping-study2017Expert-Systems-with-Applications.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 2614), ('Conclusions', 352569)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "Exploring-the-endocrine-activity-of-air-pollutants-associated-with-unconventional-oil-and-gas-extraction2018Environmental-Health-A-Global-Access-Science-SourceOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 319), ('Conclusions', 331407), ('Acknowledgements', 333986)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "hassler2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 2844), ('Background', 10859), ('Conclusion', 683784)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "How-to-conduct-systematic-reviews-more-expeditiously2015Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "Introduction Introduction\n",
      "[('Introduction', 2755), ('Background', 50704), ('Conclusion', 78140), ('Acknowledgements', 80551)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'CONCLUSION']\n",
      "Identification-and-prioritization-of-SLR-search-tool-requirements-an-SLR-and-a-survey2019Empirical-Software-Engineering.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusions Conclusions\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1756), ('Conclusions', 1756), ('Conclusion', 4512)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements']\n",
      "idri2018.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 4871), ('Conclusion', 6855), ('Background', 12026)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n",
      "kosar2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusion Conclusion\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 1737), ('Conclusion', 300281), ('Conclusions', 301196)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusion', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements']\n",
      "langlois2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusion Conclusion\n",
      "[('Conclusion', 414920)]\n",
      "Updated words list:\n",
      "['Conclusion', 'Introduction', 'Background', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'CONCLUSION', 'BACKGROUND']\n",
      "loureiro2018.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "[('Introduction', 1736), ('Conclusions', 479238)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Acknowledgements', 'Conclusion']\n",
      "mahood2013.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 1767), ('Background', 8490), ('Conclusion', 249784), ('Acknowledgements', 399758)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'CONCLUSION']\n",
      "Metaanalysis-of-quality-of-life-outcomes-following-diabetes-selfmanagement-training2008Diabetes-Educator.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions Conclusions\n",
      "[('Conclusions', 4265)]\n",
      "Updated words list:\n",
      "['Conclusions', 'Introduction', 'Background', 'Conclusion', 'CONCLUSION', 'INTRODUCTION', 'Acknowledgements', 'BACKGROUND']\n",
      "olofsson2017.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Background Background\n",
      "BACKGROUND BACKGROUND\n",
      "CONCLUSION CONCLUSION\n",
      "[('Background', 654), ('BACKGROUND', 1866), ('CONCLUSION', 89245)]\n",
      "Updated words list:\n",
      "['Background', 'BACKGROUND', 'CONCLUSION', 'Introduction', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'Conclusions']\n",
      "Optimal-literature-search-for-systematic-reviews-in-surgery2018Langenbecks-Archives-of-Surgery.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "[('Background', 482), ('Conclusions', 1604)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion', 'Acknowledgements']\n",
      "Overview-of-datasynthesis-in-systematic-reviews-of-studies-on-outcome-prediction-models2013BMC-Medical-Research-MethodologyOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Background', 386), ('Conclusion', 1921)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusion', 'Introduction', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'CONCLUSION']\n",
      "Psychosocial-Predictors-Assessment-and-Outcomes-of-Cosmetic-Procedures-A-Systematic-Rapid-Evidence-Assessment2014Aesthetic-Plastic-Surgery.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Introduction Introduction\n",
      "[('Introduction', 580), ('Background', 2852), ('Conclusions', 3805)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Conclusion', 'Acknowledgements']\n",
      "Reproducibility-of-studies-on-text-mining-for-citation-screening-in-systematic-reviews-Evaluation-and-checklist2017Journal-of-Biomedical-Informatics.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background Background\n",
      "[('Introduction', 2988), ('Background', 16054)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'Conclusion', 'CONCLUSION']\n",
      "Research-state-of-the-art-on-GoF-design-patterns-A-mapping-study2013Journal-of-Systems-and-Software.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 2775), ('Conclusions', 631578), ('Acknowledgements', 634736)]\n",
      "Updated words list:\n",
      "['Introduction', 'Conclusions', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Background', 'Conclusion']\n",
      "Searching-for-qualitative-research-for-inclusion-in-systematic-reviews-A-structured-methodological-review2016Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Introduction Introduction\n",
      "[('Introduction', 227), ('Background', 1856), ('Conclusions', 1299582)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusions', 'INTRODUCTION', 'BACKGROUND', 'CONCLUSION', 'Conclusion', 'Acknowledgements']\n",
      "shemilt2013.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Acknowledgements Acknowledgements\n",
      "[('Introduction', 2120), ('Acknowledgements', 703866)]\n",
      "Updated words list:\n",
      "['Introduction', 'Acknowledgements', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Background', 'CONCLUSION', 'Conclusion']\n",
      "stansfield2017.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "Background\n",
      "The word Background was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "BACKGROUND BACKGROUND\n",
      "CONCLUSION CONCLUSION\n",
      "[('BACKGROUND', 2050), ('CONCLUSION', 233847)]\n",
      "Updated words list:\n",
      "['BACKGROUND', 'CONCLUSION', 'Introduction', 'Background', 'Conclusion', 'Acknowledgements', 'INTRODUCTION', 'Conclusions']\n",
      "Supporting-systematic-reviews-using-LDAbased-document-representations2015Systematic-ReviewsOpen-Access.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "Introduction\n",
      "The word Introduction was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "Conclusion\n",
      "The word Conclusion was not found in the pdf file\n",
      "Background Background\n",
      "Conclusions Conclusions\n",
      "Acknowledgements Acknowledgements\n",
      "[('Background', 346), ('Conclusions', 1710), ('Acknowledgements', 260371)]\n",
      "Updated words list:\n",
      "['Background', 'Conclusions', 'Acknowledgements', 'Introduction', 'BACKGROUND', 'CONCLUSION', 'INTRODUCTION', 'Conclusion']\n",
      "thelwall2014.pdf\n",
      "['Introduction', 'INTRODUCTION', 'Background', 'BACKGROUND', 'Conclusion', 'Conclusions', 'CONCLUSION', 'Acknowledgements']\n",
      "INTRODUCTION\n",
      "The word INTRODUCTION was not found in the pdf file\n",
      "BACKGROUND\n",
      "The word BACKGROUND was not found in the pdf file\n",
      "Conclusions\n",
      "The word Conclusions was not found in the pdf file\n",
      "Acknowledgements\n",
      "The word Acknowledgements was not found in the pdf file\n",
      "CONCLUSION\n",
      "The word CONCLUSION was not found in the pdf file\n",
      "Introduction Introduction\n",
      "Background Background\n",
      "Conclusion Conclusion\n",
      "[('Introduction', 1302), ('Background', 9910), ('Conclusion', 397363)]\n",
      "Updated words list:\n",
      "['Introduction', 'Background', 'Conclusion', 'INTRODUCTION', 'BACKGROUND', 'Conclusions', 'Acknowledgements', 'CONCLUSION']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['none']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1002@asi.23250.pdf'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from array import *\n",
    "finalDocumentSet.pop(0)\n",
    "files.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stansfield2017.pdf'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDocumentSet.pop(23)\n",
    "files.pop(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalDocumentSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the objectives for QA questions\n",
    "dataset_QA = {'fileName': [], 'content': [] }\n",
    "for a,b in zip(files, finalDocumentSet):    \n",
    "    dataset_QA['fileName'].append(a)\n",
    "    dataset_QA['content'].append(b)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the results to .xslx\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame(dataset_QA, columns= ['fileName', 'content'])\n",
    "export_excel = df.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\finalLDADataSet_QA.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract introduction\n",
    "introduction = []\n",
    "def extractIntroduction():\n",
    "    count = 0\n",
    "    for i in range(len(finalDocumentSet)):\n",
    "        #count = count + 1\n",
    "        #print(count)\n",
    "        doc = str(finalDocumentSet[i])\n",
    "        intro=re.search(\"|\".join([r'Background(.*?)Methods', r'2. Study objective(.*?)3. Methods', r'Introduction(.*?)Methods', r'Purpose(.*?)Methods', r'Introduction(.*?)Overview', r'Introduction(.*?)Method', r'Background(.*?)Main Text', r'Introduction(.*?)Methodology', r'Introduction(.*?) Related work', r'Context(.*?)Methods', r'Introduction(.*?)Methodology', r'Objectives(.*?)Methods', r'Introduction(.*?)Study Objective', r'Objective(.*?)Method', r'Introduction(.*?)Background' ]), str(doc)).group()           \n",
    "        #intro = sent_tokenize(intro)\n",
    "        introduction.append(intro)\n",
    "    return introduction      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_data = extractIntroduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intro_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedData = []\n",
    "for i in range(len(intro_data)):\n",
    "    data = str(intro_data[i])\n",
    "    #Text pre-processing\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'\\d+', '', data)\n",
    "    #data = re.sub(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+','', data)\n",
    "    data = data.replace(\"\\n\", \"\")\n",
    "    #data = data.strip()\n",
    "    data = sent_tokenize(data)\n",
    "    preprocessedData.append(data)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in f:\\python\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: numpy in f:\\python\\lib\\site-packages (from rank-bm25) (1.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens_questions(question):\n",
    "    tokenized_question = question.split()\n",
    "    create_chunks = nltk.ne_chunk(nltk.pos_tag(tokenized_question))\n",
    "    assign_pos_tags = tree2conlltags(create_chunks)\n",
    "    return assign_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos(question):\n",
    "    noun_add = []\n",
    "    assign_pos_tags = create_tokens_questions(question)\n",
    "    print(assign_pos_tags)\n",
    "    for i in range(0, len(assign_pos_tags) - 1):\n",
    "        if (assign_pos_tags[i][1] == 'NN' and assign_pos_tags[i + 1][1] == 'NN'):\n",
    "            extract_nouns = assign_pos_tags[i] + assign_pos_tags[i + 1]\n",
    "            noun_add.append(extract_nouns)\n",
    "        elif assign_pos_tags[i][1] == 'NNP':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "        elif assign_pos_tags[i][1] == 'NN':\n",
    "            extract_nouns = assign_pos_tags[i]\n",
    "            print(\"The word\", extract_nouns[0], \"is extracted and added to the query list\")\n",
    "            noun_add.append(extract_nouns[0])\n",
    "    return noun_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "introFinalData = []\n",
    "\n",
    "def conductSentenceExtraction(inputDoc):\n",
    "    for j in range(len(inputDoc)):\n",
    "        question = \"what is the aim and objective of this paper?\"\n",
    "        \n",
    "        #to do for the remaining question\n",
    "        \n",
    "        tokenized_corpus = [doc.split(\" \") for doc in inputDoc[j]]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        noun_add = extract_pos(question)\n",
    "        #print(noun_add)\n",
    "        get_final_results = bm25.get_top_n(noun_add, inputDoc[j], n=10)\n",
    "        introFinalData.append(get_final_results)\n",
    "        #print(get_final_results)\n",
    "    return introFinalData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n",
      "[('what', 'WP', 'O'), ('is', 'VBZ', 'O'), ('the', 'DT', 'O'), ('aim', 'NN', 'O'), ('and', 'CC', 'O'), ('objective', 'NN', 'O'), ('of', 'IN', 'O'), ('this', 'DT', 'O'), ('paper?', 'NN', 'O')]\n",
      "The word aim is extracted and added to the query list\n",
      "The word objective is extracted and added to the query list\n"
     ]
    }
   ],
   "source": [
    "QA1 = conductSentenceExtraction(preprocessedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(introFinalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['while broad searches are important to ensure that all of\\\\nthe potentially relevant literature is located, such exhaustive searching is costly and time-consuming.\\\\n\\\\nperhaps even more troublesome for reviewers is the issue of topic focus because systematic reviews can\\\\nsometimes aim to examine cross-cutting issues, such as inequalities, in order to draw conclusions which go\\\\nbeyond the focus of individual primary studies.',\n",
       "  'this technique and the software used (termine; frantzi et al., ) are described in the methods',\n",
       "  'citation chasing\\\\nor expert recommendations; woodman et al., ), but this may not be sufﬁcient for cross-cutting, diffuse or\\\\ncomplex topics.\\\\n\\\\na primary goal of a systematic review is to minimise bias when examining the evidence, and an important part\\\\nof that is the avoidance of systematically missing relevant evidence (higgins and green, ).',\n",
       "  'for example,\\\\ncommunity engagement interventions cut across many disciplines, topics and outcome domains including housing,\\\\ntransport, social inclusion, accident prevention and substance abuse (popay et al., ).',\n",
       "  'such breadth demands that\\\\nreviewers familiarise themselves with the terminology and research sources (journals, archives of research, etc.)',\n",
       "  'of\\\\nvaried disciplines.',\n",
       "  'also, searching broadly requires the location and screening of many reports in order to identify\\\\na much smaller quantity of relevant research evidence.',\n",
       "  'thus, the main focus of a review often differs signiﬁcantly from\\\\nthe questions asked in the primary research it contains; this means that issues of signiﬁcance to the review\\\\nmay not be referred to in the titles and abstracts of the primary studies, even though the primary studies actually\\\\ndo enable reviewers to answer the question they are addressing.',\n",
       "  'as an example, primary research is often\\\\nconducted with samples that are predominantly from disadvantaged groups, but the study might not mention\\\\nthis in either title or abstract when reducing health inequalities is not the focus of the intervention.',\n",
       "  'relevant\\\\nevidence is therefore likely to be missed by typical review methods that have an initial screening stage in which\\\\nonly titles and abstracts are reviewed.'],\n",
       " ['objective: the goal of this work is to synthesize available research results to inform evidence-based\\\\nselection of actionable alert identiﬁcation techniques (aait).\\\\nmethod'],\n",
       " ['research\\\\nenvironment\\\\n\\\\n\\\\xcapplication of distance measurement nlp methods',\n",
       "  ').\\\\n\\\\nfig.',\n",
       "  'data in paired addresses would contain a degree of\\\\nrelationship-based security based on experience where those addresses that are not\\\\nlabeled as a “negative” system after some time puts them in properly paired [–]\\\\n(fig.',\n",
       "  'for this particular project researchers had access to partial data taken from\\\\ntwo-year history of matching statistics or unsorted shipments from the earlier period\\\\nthat was used for learning.',\n",
       "  'research environment\\\\n\\\\nas part of this research proposed model was developed in environment of approx-\\\\nimately ,, shipments which are handled annually in the express delivery\\\\nsystem.',\n",
       "  'within the business processes of express delivery several\\\\nsystems can beneﬁt from proposed solution: automatic routing of an espresso deliv-\\\\nery, inadequate or missing address breaks, dynamic routing of express delivery, more\\\\nadequate arrangement of ﬁxed routes, optimization and predicting the time required\\\\nfor each group to deliver shipments, statistics by individual groups and phases (e.g.\\\\n“at the time of delivery shipment for the exact day”) [–].\\\\n\\\\n.',\n",
       "  'mrsic\\\\n\\\\naddress between sender and receiver from the transaction system, address database\\\\nwith machine learning elements and the option to systematically learn through a mis-\\\\nmatched return address.',\n",
       "  '), intelligent information and database systems:\\\\nrecent developments, studies in computational intelligence ,\\\\nhttps://doi.org/./----_\\\\n\\\\n\\\\n\\\\n\\\\xc\\\\n\\\\nl.',\n",
       "  '(eds.',\n",
       "  'huk et al.'],\n",
       " ['to increase efficiency, two\\\\nmethods seem promising, which will be tested in the planned study: the use of text mining to prioritize search\\\\nresults as well as the involvement of only one person in the study selection process (single-screening approach).\\\\nthe aim of the present study is to examine the following questions related to the process of study selection: can\\\\nthe use of the rayyan or eppi reviewer tools to prioritize the results of study selection increase efficiency?',\n",
       "  'which advantages or disadvantages (e.g.,\\\\nshortened screening time or increase in the number of full texts ordered) does a single-screening versus a double-\\\\nscreening approach have?\\\\nmethods',\n",
       "  'how\\\\naccurately does a single-screening approach identify relevant studies?',\n",
       "  'background: systematic information retrieval generally requires a two-step selection process for studies, which is\\\\nconducted by two persons independently of one another (double-screening approach).'],\n",
       " ['() present an overview of research on \\\\ndata deduplication with the aim to provide a general assessment \\\\nof  useful  references  and  ideas  on  this  topic.',\n",
       "  '\\\\n\\\\nfrom the point of view of expert systems, er is an operational \\\\nintelligence process, whereby organizations can unify different and \\\\nheterogeneous data sources in order to match non-obvious enti- \\\\nties.',\n",
       "  'it  involves  identifying  entities  from  the  digital  world \\\\nthat refer to the same real-world entity.',\n",
       "  'er process plays a funda- \\\\nmental role in the context of information integration and manage- \\\\nment, aimed to infer a uniform and common structure from var- \\\\n\\\\n\\\\xcj.g.',\n",
       "  'enríquez et al.',\n",
       "  '/ expert systems with applications  () – \\\\n\\\\n \\\\n\\\\nious large-scale data collections, with which to suitably organize, \\\\nmatch and consolidate the information of the individual reposito- \\\\nries into one data set ( costa, cuzzocrea, manco, & ortale,  ).',\n",
       "  '\\\\nthis is a complex problem, since it is not trivial to assert that two \\\\nheterogeneous data instances represent the same real object.',\n",
       "  'het- \\\\nerogeneity can happen in data structure as well as in data values \\\\n( dorneles, gonçalves, & dos santos mello,  ).',\n",
       "  'this problem can \\\\nbe applied to many different domains such as: e-health, citations, \\\\nsmart cities, meteorological predictions, manufacturing and many \\\\nother different environments.',\n",
       "  'method'],\n",
       " ['in addition, a complex mixture of chemicals, including heavy metals, naturally-occurring\\\\nradioactive chemicals, and organic compounds are released from the formations and can enter air and water.\\\\ncompounds associated with uog activity have been linked to adverse reproductive and developmental outcomes\\\\nin humans and laboratory animal models, which is possibly due to the presence of endocrine active chemicals.\\\\nmethods',\n",
       "  'this process is known to use greater than , chemicals such as solvents, surfactants,\\\\ndetergents, and biocides.',\n",
       "  'this occurred largely because of the development of directional drilling and\\\\nhydraulic fracturing which allows access to fossil fuels from geologic formations that were previously not cost\\\\neffective to pursue.',\n",
       "  'background: in the last decade unconventional oil and gas (uog) extraction has rapidly proliferated throughout\\\\nthe united states (us) and the world.'],\n",
       " ['objective: this research proposes two training-by-example classiﬁers that are computationally simple, do not\\\\nrequire extensive training or tuning, ensure inclusion/exclusion consistency, and reduce researcher study se-\\\\nlection time: one based on vector space models (vsm), and a second based on latent semantic analysis (lsa).\\\\nmethod'],\n",
       " ['imple-\\\\nmenting the process of parallelisation will not reduce\\\\nthe costs but it will not increase the risk of bias either\\\\n(see table ).\\\\n\\\\nprocess parallelisation\\\\nalthough different steps of a sr can be carried out by\\\\ntwo reviewers in a linear fashion, where resources permit\\\\nmany tasks such as study selection, data extraction and\\\\nquality assessment can be divided amongst\\\\nseveral\\\\n\\\\ntable  the interrelationship between the three approaches to\\\\nthe conduct of reviews with expected impacts on speed, costs\\\\nand risk of bias\\\\n\\\\nprocess\\\\nparallelisation\\\\n\\\\nmethod',\n",
       "  'possible approaches to address the\\\\nissue of timeliness in the production of srs are to (a) implement process parallelisation, (b) adapt and apply\\\\ninnovative technologies, and/or (c) modify sr processes (e.g.',\n",
       "  'often,\\\\nclinical practice guideline developers or other decision-makers need to make informed decisions in a timely fashion\\\\n(e.g.',\n",
       "  'however, the conduct of srs can be a time-consuming and resource-intensive task.',\n",
       "  'systematic reviews  () : \\\\ndoi ./s---\\\\n\\\\nco m m e n t ar y\\\\nhow to conduct systematic reviews more\\\\nexpeditiously?\\\\nalexander tsertsvadze*, yen-fu chen, david moher, paul sutcliffe and noel mccarthy\\\\n\\\\nopen access\\\\n\\\\nabstract\\\\n\\\\nhealthcare consumers, researchers, patients and policy makers increasingly use systematic reviews (srs) to aid their\\\\ndecision-making process.',\n",
       "  'accessed on \\\\nnovember .\\\\n\\\\n\\\\xc tsertsvadze et al.',\n",
       "  '.\\\\nhttp://effectivehealthcare.ahrq.gov/index.cfm/search-for-guides-reviews-and-\\\\nreports/?productid=&pageaction=displayproduct.',\n",
       "  'rockville (md).',\n",
       "  'balk em, chung m, chen ml, trikalinos ta, kong win chang l.\\\\n\\\\nassessing the accuracy of google translate to allow data extraction\\\\nfrom trials published in non-english languages.',\n",
       "  'accessed  november .\\\\n\\\\n.'],\n",
       " ['these\\\\nrequirements will help tool builders ensure they focus their efforts appropriately.\\\\nmethod',\n",
       "  'objective to help alleviate some of the barriers in the search phase, we identify and pri-\\\\noritize slr search tool requirements based on input from the slr community.'],\n",
       " ['the objective of this paper is to review the use of preprocessing techniques in clinical datasets.',\n",
       "  'methods',\n",
       "  'data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for dm techniques.',\n",
       "  'these challenges lead to a serious bias in predictive modeling and reduce the performance of dm techniques.',\n",
       "  'however, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data.',\n",
       "  'background and objective: datamining (dm) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns.'],\n",
       " ['sms is a secondary study, a special\\\\nform of\\\\nsystematic review (sr), that reviews primary studies with the aim of\\\\nsynthesizing\\\\n(kitchenham and\\\\ncharters, ).',\n",
       "  'yet another form of sr is a systematic literature re-\\\\nview (slr), with the aim to identify, analyze and interpret all available\\\\nevidence on speciﬁc research questions.',\n",
       "  'related work',\n",
       "  'the authors of\\\\ncruzes and dybå () have also come to similar conclusions: “srs\\\\nthat involve the transformation of raw data, or that include large numbers of\\\\nprimary studies, require greater resources, and where the review question\\\\nand/or range of evidence is very broad, it may be necessary to sample.”\\\\nhowever, current practices in performing smss (e.g., engström and\\\\nruneson, ; barney et al., ; ampatzoglou et al., ; kosar\\\\net al., c) do not include random sampling, but the inclusion of\\\\nprimary studies obtained from two or more digital libraries (dls) with\\\\na\\\\nsnowballing\\\\n(kitchenham et al., ).',\n",
       "  'the diﬀerences between sms\\\\nand slr are subtle, but important.',\n",
       "  'a good discussion on the diﬀerences\\\\nbetween sms and slr can be found in kitchenham et al.',\n",
       "  '().',\n",
       "  'in\\\\nbrief, slr includes a more comprehensive and thorough investigation\\\\nof primary studies while pursuing more speciﬁc research questions with\\\\nhigh requirements of research synthesis (cruzes and dybå, ).\\\\nfurthermore, a quality assessment of the primary studies is necessary\\\\nduring slr.',\n",
       "  'according to the guidelines\\\\nin kitchenham and\\\\ncharters (), all relevant studies should be found whilst performing\\\\nslr.',\n",
       "  'on the other hand, the main goal of smss is to provide an over-\\\\nview of a broader research topic.'],\n",
       " ['\\\\n \\\\nmethod',\n",
       "  'objective: identify the most performant automated text classification method (e.g., algorithm) \\\\nfor differentiating empirical studies from nonempirical works in order to facilitate systematic \\\\nmixed studies reviews.'],\n",
       " ['overview',\n",
       "  'overall\\\\ndiscussion, conclusions and implications on the use of vr in marketing\\\\nappear in the last two sections.\\\\n\\\\n.',\n",
       "  'the total market size worldwide for virtual environments\\\\n(particularly virtual and augmented reality) is expected to move from\\\\n billion u.s. dollars in  to .',\n",
       "  'billion u.s. dollars in \\\\n(statista, ), thus showing that there are new market opportunities\\\\nto be explored.\\\\n\\\\nresearch on applied virtual reality (vr) dates back to the s\\\\nwith the work of relevant authors such as milgram, takemura, utsumi,\\\\nand kishino (), brooks (), slater and wilbur () and\\\\nsteuer ().',\n",
       "  'milgram et al.',\n",
       "  '(, p. ) propose a taxonomy to\\\\ndiﬀerentiate the technologies available for experiencing combinations\\\\nof reality and virtuality and describe vr as the environment “in which\\\\nthe participant-observer is totally immersed in a completely synthetic\\\\nworld, which may or may not mimic the properties of a real-world\\\\nenvironment”.',\n",
       "  'from the applications of vr envisaged by brooks ()\\\\nin the s as a vehicle for simulation and entertainment, the range of\\\\nacceptance and use of vr has enlarged considerably and now includes,\\\\nfor example, tourism (e.g., abergel, saleri, bergerot, & de luca, ;\\\\njeng, pai, & yeh, ; yeh, wang, li, & lin, ), retailing (e.g.,\\\\n\\\\nevans & wurster, ; krasonikolakis, vrechopoulos, & pouloudi,\\\\n) and medical and educational issues (e.g., abboudi et al., ).\\\\nseveral studies show that the product/brand stimuli can come from\\\\nconsumers´ experiences in virtual reality (e.g., bigné, llinares, &\\\\ntorrecilla, ; verhagen, vonkeman, feldberg, & verhagen, ;\\\\nyeh et al., ) with concepts such as attachment, engagement and\\\\nidentity being induced by virtual objects (e.g., grewal, roggeveen, &\\\\nnordfalt, ; koles & nagy, ; nagy & koles, ), as well as\\\\npurchase behaviours (krasonikolakis et al., ).',\n",
       "  \"thus, studies on this\\\\nﬁeld tend to apply the s(stimuli)-o(organism)-r(response) framework\\\\n(eroglu, machleit, & davis, ; roschk, loureiro, & breitsohl, ).\\\\nthis framework represents the stimuli (as atmospheric cues) inﬂuen-\\\\ncing consumers' emotional and cognitive states (organism), which, in\\\\nturn, result in approach or avoidance behaviour (e.g., intention to stay,\\\\nrevisit, purchase or not).\\\\n\\\\nthe extended adoption of vr technologies is promoting economic\\\\ngrowth and creating new opportunities (e.g., grewal et al., ;\\\\nverhagen et al., ).\",\n",
       "  'as these technologies evolve, they tend to in-\\\\ncreasingly inﬂuence marketing and business decisions.',\n",
       "  'this trend leads\\\\nto a call for studies revealing the state-of-the-art of research on vr.'],\n",
       " ['methods',\n",
       "  'we also discuss the beneﬁts\\\\nand challenges of including this literature in our systematic review, as well as the strengths and limitations to\\\\nour approach.\\\\n\\\\nainstitute for work & health, toronto, on, canada\\\\nbfaculty of information, university of toronto, toronto, on, canada\\\\ncschool of public health and health systems, university of waterloo, waterloo, on, canada\\\\n*correspondence to: quenby mahood, institute for work & health,  university avenue, suite , toronto, on mg e, canada.\\\\n†e-mail: qmahood@iwh.on.ca\\\\n\\\\ncopyright ©  john wiley & sons, ltd.\\\\n\\\\nres.',\n",
       "  'where publishing\\\\nis not the primary activity of the producing body.',\n",
       "  'grey literature may exhibit all or only some of these characteristics,\\\\nleading to “varying degrees of\\\\nagreement and consensus” (tillett and newbold, ) on what it is.\\\\n\\\\ngreynet, the grey literature network service, provides a deﬁnition:\\\\n\\\\ngrey literature is a ﬁeld in library and information science that deals with the production, distribution, and\\\\naccess to multiple document types produced on all\\\\nlevels of government, academics, business, and\\\\norganization in electronic and print formats not controlled by commercial publishing i.e.',\n",
       "  'the uncertainty comes from some of its core characteristics, such as not\\\\nproduced for commercial publication, not available through standard distribution means, no standard\\\\nbibliographic controls, not peer-reviewed, ephemeral and historically difﬁcult to ﬁnd (tillett and newbold,\\\\n).',\n",
       "  'mahood et al.\\\\n\\\\n.. background information about grey literature\\\\n\\\\ngrey literature is a term that dates back to the s and “refers not to the physical appearance of a document but\\\\nto the uncertain status of it” (auger, ).',\n",
       "  '\\\\n\\\\n\\\\xcq.',\n",
       "  'meth.',\n",
       "  'syn.',\n",
       "  'additionally, this information is important in advancing methodology in this area so that future\\\\nsystematic review teams can learn from previous ones.\\\\n\\\\nthe purpose of this paper is to provide a detailed account of one systematic review team’s experience in\\\\n\\\\nsearching for grey literature and including it throughout the stages of the review.\\\\n\\\\nin this account, based on a systematic review on participatory ergonomics, we provide a brief background\\\\nabout grey literature before describing our search and review of this literature.'],\n",
       " ['purpose\\\\n\\\\nmethods'],\n",
       " ['user experiences were collected.\\\\nmethods',\n",
       "  'objectives to examine the effectiveness of the text mining functionality of the\\\\nabstract screening tool rayyan.'],\n",
       " [\"these sources include bib-\\\\nliographic databases, reference lists, trials registries, and hand\\\\n\\\\n\\\\xc langenbeck's archives of surgery () :–\\\\nhttps://doi.org/./s---x\\\\n\\\\noriginal article\\\\n\\\\noptimal literature search for systematic reviews in surgery\\\\n\\\\nkäthe goossen  & solveig tenckhoff  & pascal probst , & kathrin grummich  & andré l. mihaljevic , &\\\\nmarkus w. büchler  & markus k. diener ,\\\\n\\\\nreceived:  july  /accepted:  november  /published online:  december \\\\n# springer-verlag gmbh germany, part of springer nature \\\\n\\\\nabstract\\\\n\\\\nbackground the aim of the present study was to determine empirically which electronic databases contribute best to a literature\\\\nsearch in surgical systematic reviews.\\\\nmethods\",\n",
       "  'the selection is oriented only by general\\\\nrecommendations to search multiple classes of sources and all\\\\nrelevant sources within each class.',\n",
       "  'these sources do not, however, specify\\\\nwhich databases systematic reviewers should choose beyond\\\\nthe general statement that bthree bibliographic databases [are]\\\\ngenerally considered to be the most important sources to\\\\nsearch for reports of trials—central, medline and\\\\nembase.^ the authors’ personal experience in past system-\\\\natic literature searches led to the hypothesis that embase\\\\nmay not be the optimal database for surgical topics of interest.\\\\nspecific guidance for database selection can be found in the\\\\nliterature for sr in some medical areas [–] but not for sur-\\\\ngical interventions.',\n",
       "  'evidence-based surgery has become firmly rooted, with\\\\nincreasing numbers of rct and sr published in the past two\\\\ndecades.\\\\n\\\\nample methodological research has led to the definition of\\\\nrecommendations for the diverse facets of the sr process,\\\\ncompiled in the cochrane handbook and prisma statement\\\\nand checklist [, ].',\n",
       "  'sr of ran-\\\\ndomized, controlled trials (rct) represent the highest possi-\\\\nble level of evidence on the oxford levels of evidence scale\\\\n\\\\nelectronic supplementary material the online version of this article\\\\n(https://doi.org/./s---x) contains supplementary\\\\nmaterial, which is available to authorized users.\\\\n\\\\n* markus k. diener\\\\n\\\\nmarkus.diener@med.uni-heidelberg.de\\\\n\\\\n\\\\n\\\\nstudy center of the german surgical society (sdgc), im\\\\nneuenheimer feld .,  heidelberg, germany\\\\n\\\\n department of general, visceral and transplantation surgery,\\\\n\\\\nuniversity hospital heidelberg, im neuenheimer feld ,\\\\n heidelberg, germany\\\\n\\\\n[].',\n",
       "  'they are instrumental in transfer-\\\\nring research results into evidence-based clinical practice\\\\nand ensuring the quality of medical interventions.',\n",
       "  'background\\\\n\\\\nsystematic reviews (sr) are a key element of the clinical\\\\ndecision-making process.'],\n",
       " ['pre-\\\\ndicted probabilities\\\\nregression analysis.\\\\nmethods',\n",
       "  'clinical and non-clinical patient\\\\ncharacteristics) in order to predict future events in indi-\\\\nviduals, and therefore focus on absolute risks, i.e.',\n",
       "  'out-\\\\ncome prediction studies, on the other hand, combine\\\\nmultiple factors (e.g.',\n",
       "  'relative risk) of this prognostic factor\\\\nwhich ideally is adjusted for potential confounders.',\n",
       "  'prognostic factor studies investi-\\\\ngate causal relationships, or pathways between a single\\\\n(prognostic) factor and an outcome, and focus on the ef-\\\\nfect size (e.g.',\n",
       "  'an important dis-\\\\ntinction in prognosis is made between prognostic factor\\\\nmodels, also called explanatory models and outcome\\\\n\\\\n* correspondence: to.vandenberg@vumc.nl\\\\ndepartment of epidemiology and biostatistics and the emgo institute for\\\\nhealth and care research, vu university medical centre, amsterdam, the\\\\nnetherlands\\\\nfull list of author information is available at the end of the article\\\\n\\\\nprediction models [,].',\n",
       "  'although there is abundant literature to\\\\nhelp researchers perform this type of research [-],\\\\nthere is still no widely agreed approach to building a\\\\nmultivariable prediction model [].',\n",
       "  'background\\\\nthe methodology for prognosis research is still under\\\\ndevelopment.'],\n",
       " ['we synthesised cosmetic inter-\\\\nvention research evidence covering psychosocial factors\\\\nassociated with requesting procedures and psychological\\\\noutcomes, effects of procedures on psychological out-\\\\ncomes, preintervention assessments for identifying those at\\\\nrisk, alternative therapy effectiveness, and issues\\\\nin\\\\nachieving informed consent.\\\\nmethods',\n",
       "  'introduction\\\\n\\\\nthe rates of cosmetic interventions undertaken in the uk\\\\nto enhance physical appearance have increased substan-\\\\ntially over the past decade [, ], with a wider, more\\\\n\\\\n\\\\xc aesth plast surg () :–\\\\ndoi ./s---\\\\n\\\\nr e v i e w\\\\n\\\\nexperimental/special topics\\\\n\\\\npsychosocial predictors, assessment, and outcomes of cosmetic\\\\nprocedures: a systematic rapid evidence assessment\\\\n\\\\nginny brunton • nicole paraskeva • jenny caird • karen schucan bird •\\\\njosephine kavanagh • irene kwan • claire stansﬁeld • nichola rumsey •\\\\njames thomas\\\\n\\\\nreceived:  december  / accepted:  june  / published online:  june \\\\n(cid:) springer science+business media new york and international society of aesthetic plastic surgery \\\\n\\\\nabstract\\\\nbackground recent breast implant complications led to a\\\\nuk government policy review of the evidence concerning\\\\ncosmetic interventions.'],\n",
       " ['however, there is little work so far on reproduction studies in the ﬁeld.\\\\nobjective: in this paper, we investigate the reproducibility of studies in this area based on information\\\\ncontained in published articles and we propose reporting guidelines that could improve reproducibility.\\\\nmethods',\n",
       "  'the application of text mining\\\\ntechniques to citation screening in the context of systematic literature reviews is a relatively young and\\\\ngrowing computational ﬁeld with high relevance for software engineering, medical research and other\\\\nﬁelds.',\n",
       "  'in computation research, full replication is often\\\\nunrealistic for independent results validation, therefore, study reproduction has been justiﬁed as the\\\\nminimum acceptable standard to evaluate the validity of scientiﬁc claims.',\n",
       "  'context: independent validation of published scientiﬁc results through study replication is a pre-\\\\ncondition for accepting the validity of such results.'],\n",
       " ['the  main  difference  of  zhang  and  budgen  ()  with\\\\nrespect  to  this  paper  is  the  aim  of  the  two  literature  reviews.',\n",
       "  'in\\\\nour  study,  we  do  not  aim  only  on  summarizing  empirical  evidence,\\\\nbut  to  gather  a  broader  dataset,  concerning  gof  design  pattern\\\\nresearch.',\n",
       "  '/  the  journal  of  systems  and  software   () –  \\\\n\\\\n\\\\n\\\\n#  papers \\\\n\\\\nimpact  factor/acceptance  rate \\\\n\\\\ndigital  sources\\\\n\\\\ntable  \\\\npublication  venues.\\\\n\\\\nname \\\\n\\\\nannual  computer  software  and  application  conference  (compsac) \\\\neuropean  conference  on  software  maintenance  and  reengineering  (csmr)\\\\ninternational  conference  on  software  engineering  (icse) \\\\ninternational  conference  on  software  maintenance  (icsm) \\\\nicse   workshops \\\\nieee   working  conference  on  reverse  engineering  (wcre) \\\\nieee   transactions  on  software  engineering  (tse) \\\\njournal  of  systems  and  software  (jss) \\\\ninformation  and  software  technology  (ist)\\\\ninternational  conference  on  automated  software  engineering  (ase) \\\\nobject  oriented  programming,  systems,  languages  and  applications  (oopsla) \\\\ninternational  conference  on  program  comprehension  (icpc) \\\\nieee   metrics  symposium  (metrics) \\\\nsymposium  on  empirical  software  engineering  and  measurement  (esem) \\\\nieee   software  (ieeesoft) \\\\nempirical  software  engineering  (ese) \\\\ninternational  symposium  on  software  reliability  engineering  (issre) \\\\nacm  sigsoft  symposium  on  foundation  of  software  engineering  (fse)\\\\nadvancements  in  software  engineering  (adse) \\\\nacm  transactions  on  programming  languages  and  systems  (toplas) \\\\nfse   workshops \\\\njournal  of  software:  evolution  and  process \\\\nsoftware  testing,  veriﬁcation  and  reliability  (stvr) \\\\nacm  transactions  on  software  engineering  and  method',\n",
       "  'until  now,  researchers  have  attempted  to  evaluate  the\\\\nuse  of  patterns  with  empirical,  i.e.',\n",
       "  'in  addition  to  that,  we  do  not  only  focus  on  the  effect\\\\nof  patterns  on  quality  attributes,  but  introduce  gof  design  patterns\\\\nresearch  subtopics,  as  well.\\\\n\\\\n.',\n",
       "  'software  quality  attributes\\\\n\\\\nsoftware  quality  models  are  usually  hierarchical  (dormey,  ;\\\\niso,  ).',\n",
       "  'in  this  paper,  we  use  iso/iec    as  reference\\\\nmodel  for  discussing  the  effect  of  design  patterns  on  software\\\\nquality  (iso,  ).',\n",
       "  'the  ﬁrst  level  of  iso    describes  six\\\\nquality  attributes,  i.e.,  portability,  functionality,  reliability,  usabil-\\\\nity,  efﬁciency,  and  maintainability,  which  are  further  divided  in\\\\nseveral  sub-characteristics  as  shown  in  fig.',\n",
       "  '.',\n",
       "  'next,  each  qual-\\\\nity  sub-attribute  (low-level  quality  attributes,  such  as  complexity,\\\\n\\\\ncohesion,  etc.'],\n",
       " ['an analysis of the publication formats and\\\\ninformation sources used for four systematic reviews in public health.\\\\nres synth methods',\n",
       "  ';:.\\\\nstansfield c, brunton g, rees r. search wide, dig deep: literature searching\\\\nfor qualitative research.',\n",
       "  'barbour rs, barbour m. evaluating and synthesising qualitative research: the\\\\n\\\\nneed to develop a distinctive approach.',\n",
       "  ';:–.\\\\n\\\\n.',\n",
       "  'j clin epidemiol.',\n",
       "  'the capture-mark-recapture\\\\ntechnique can be used as a stopping rule when searching in systematic\\\\nreviews.',\n",
       "  ';:–.\\\\nkastner m, straus se, mckibbon ka, goldsmith ch.',\n",
       "  'j adv nurs.',\n",
       "  'protective care-receiving: the active\\\\n\\\\nrole of care recipients.',\n",
       "  'russell ck, bunting sm, gregory dm.'],\n",
       " ['research synthesis methods',\n",
       "  'health development agency public health steering group, london.\\\\n\\\\n©  the authors.',\n",
       "  'chapter : analysing data and undertaking meta-analyses.',\n",
       "  '.',\n",
       "  ': –.\\\\n\\\\ndeeks jj, higgins jpt, altman dg.',\n",
       "  'journal of the american medical informantics association.',\n",
       "  'reducing workload in systematic review preparation using automated\\\\n\\\\ncitation classiﬁcation.',\n",
       "  'ihi’, arlington, va, –.\\\\n\\\\ncohen a, hersh w, peterson k, yen p. .',\n",
       "  'in\\\\nproceedings of the st acm international health informatics symposium.',\n",
       "  'evidence-\\\\nbased medicine, the essential role of systematic reviews, and the need for automated text mining tools.'],\n",
       " ['a\\\\nstudy is modelled as a bag-of-words (bow).\\\\nmethods',\n",
       "  'the vast majority of these machine learning methods exploit the same underlying principle, i.e.',\n",
       "  'this framework seeks to identify\\\\nthe population, the intervention, the comparator and\\\\nthe outcome.',\n",
       "  'this process is usually performed man-\\\\nually, which means that reviewers need to read thou-\\\\nsands of citations during the screening phase, due to the\\\\nrapid growth of the biomedical literature [], making it\\\\nan expensive and time-consuming process.',\n",
       "  'according to\\\\nwallace et al.',\n",
       "  '[], an experienced reviewer is able to screen\\\\n\\\\n*correspondence: maxmo@gmail.com\\\\nschool of computer science, national centre for text mining, the university of\\\\nmanchester, manchester, uk\\\\n\\\\ntwo abstracts per minute on average, with more com-\\\\nplex abstracts taking longer.',\n",
       "  'moreover, a reviewer needs\\\\nto identify all eligible studies (i.e.',\n",
       "  '– % recall) [, ]\\\\nin order to minimise publication bias.',\n",
       "  'the number of\\\\nrelevant citations is usually significantly lower than the\\\\nnumber of the irrelevant, which means that reviewers\\\\nhave to deal with an extremely imbalanced datasets.',\n",
       "  'to\\\\novercome these limitations, methods such as machine\\\\nlearning, text mining [, ], text classification [] and\\\\nactive learning [, ] have been used to partially automate\\\\nthis process, in order to reduce the workload, without\\\\nsacrificing the quality of the reviews.'],\n",
       " ['presumably, this total (and the three totals\\\\nthat will be given) includes all articles with at least one author\\\\nfrom the institution, and articles with multiple authors from\\\\nthe same institution are only counted once.\\\\n\\\\n(cid:) publications (from the institutional homepage): the number\\\\n\\\\nof publications listed in members’ proﬁles.\\\\n\\\\n(cid:) downloads (from the institution stats page): the number of\\\\ndownloads of the institutions’ publications in the previous\\\\nweek.\\\\n\\\\n(cid:) views (from the institution stats page): the number of views\\\\nof the institutions’ publication information pages in the pre-\\\\nvious week.\\\\n\\\\npublication statistics for each country were obtained by\\\\nsearching in october  for journal articles published in\\\\n in the wos and restricting the results to just the country\\\\nin question.\\\\n\\\\nmethods',\n",
       "  'for example, one is\\\\n“the proportion of the publications of a university that, com-\\\\npared with other publications in the same ﬁeld and in the same\\\\nyear, belong to the top % most frequently cited” and\\\\nanother is “the average number of citations of the publications\\\\nof a university, normalized for ﬁeld differences and pub-\\\\nlication year” (http://www.leidenranking.com/methodology/\\\\nindicators, december , ).',\n",
       "  'this can start\\\\nfrom attempting to get articles published in high-proﬁle\\\\njournals or conferences, but may also include depositing\\\\nthem in institutional or subject repositories, advertising\\\\nthem in listservs and social media, listing them in online\\\\ncurricula vitae (cvs), and listing or depositing them in aca-\\\\ndemic social network sites, including researchgate.',\n",
       "  'while\\\\nsome authors may believe that their work only needs to be\\\\nlisted in one place in order that other researchers may be\\\\nable to ﬁnd it, each additional listing of their work is another\\\\nchance for it to be found, especially by scholars who do not\\\\nconduct extensive literature searches or who just use a\\\\ngeneral search engine (haglund & olsson, ).',\n",
       "  'if an\\\\nauthor chooses to self-archive in only one place, then their\\\\nchoice of venue probably depends upon familiarity with the\\\\navailable options as well as ﬁeld and institutional norms.',\n",
       "  'it\\\\nmay also be that archiving in researchgate or other sites is\\\\nsometimes conducted by administrators on behalf of aca-\\\\ndemics, if an institution believes that it is important.\\\\n\\\\nassuming that the increased visibility beneﬁts of listing\\\\npublications in multiple places online outweigh the cost of\\\\nthe time taken to register them, individuals and organiza-\\\\ntions that adapt to new methods of disseminating research\\\\nonline seem likely to gain increased recognition.',\n",
       "  'this mul-\\\\ntiple online availability of research can presumably increase\\\\ncitation impact (xia, myers, & wilhoite, ).\\\\n\\\\ninstitutional rankings\\\\n\\\\nalthough research impact metrics can be used to evaluate\\\\nindividual academics, metrics for education, research, and\\\\nprestige are also used to rank and compare institutions.',\n",
       "  'there\\\\nare currently several international ranking schemes for uni-\\\\nversities, some of which use citations to an institution’s\\\\narticles to estimate its impact (buela-casal, gutiérrez-\\\\nmartínez, bermúdez-sánchez, & vadillo-muñoz, ).\\\\nnevertheless,\\\\nthere have been debates about whether\\\\n\\\\n\\\\n\\\\njournal of the association for information science and technology—(cid:)(cid:) \\\\ndoi: ./asi\\\\n\\\\n\\\\xcbibliometric methods should be used for ranking academic\\\\ninstitutions (e.g., van raan ; ioannidis et al., ).\\\\nthere are ﬁve well-known institutional ranking schemes:\\\\n\\\\n(cid:) qs world university rankings: aims to rank “the world’s top\\\\nuniversities” based on academic reputation (%, from a\\\\nglobal survey), employer reputation (%, from a global\\\\nsurvey), faculty-student ratio (%), citations per faculty\\\\n(%,\\\\ninternational\\\\nstudents (%), and the proportion of international faculty\\\\n(%)\\\\n(http://www.iu.qs.com/university-rankings/world\\\\n-university-rankings/, december , ).\\\\n\\\\nthe proportion of\\\\n\\\\nfrom scopus),\\\\n\\\\n(cid:) the times higher education (the) world university rank-\\\\nings: aims “to judge world class universities across all of their\\\\ncore missions—teaching, research, knowledge transfer and\\\\ninternational outlook” (http://www.timeshighereducation.co\\\\n.uk/world-university-rankings/-/world-ranking,\\\\ndecember , ) using the web of science (wos), an\\\\ninternational survey of senior academics and self-reported\\\\ndata.',\n",
       "  'the results are based on ﬁeld-normalized citations for \\\\nyears of publications (%), research reputation from a\\\\nsurvey (%), teaching reputation (%), various indicators\\\\nof the quality of the learning environment (%), ﬁeld-\\\\nnormalized publications per faculty (%), ﬁeld-normalized\\\\nincome per faculty (%), income from industry per faculty\\\\n(.%); and indicators for the proportion of international\\\\nstaff (.%), students (.%), and internationally coauthored\\\\npublications\\\\n(http://www\\\\n.timeshighereducation.co.uk/world-university-rankings/\\\\n-/world-ranking/methodology, december , ).\\\\n\\\\nﬁeld-normalized)\\\\n\\\\n(.%,\\\\n\\\\n(cid:) academic ranking of world universities (arwu): aims to\\\\nrank the “world top  universities” based on “the number of\\\\nalumni and staff winning nobel prizes and fields medals,\\\\nnumber of highly cited researchers selected by thomson\\\\nscientiﬁc, number of articles published in journals of nature\\\\nand science, number of articles indexed in science citation\\\\nindex—expanded and social sciences citation index,\\\\nand per capita performance with respect\\\\nto the size of\\\\nan institution” (http://www.shanghairanking.com/aboutarwu\\\\n.html, december , ).\\\\n\\\\n(cid:) cwts leiden ranking: aims to measure “the scientiﬁc per-\\\\nformance” of universities using bibliometric indicators based\\\\non wos data through a series of separate size- and ﬁeld-\\\\nnormalized indicators for different aspects of performance\\\\nrather than a combined overall ranking.',\n",
       "  'these are perhaps the most\\\\nsophisticated indicators, both in the nature of the calculations\\\\nand in the data cleaning for the indicators but only reﬂect\\\\nresearch performance aspects of a university.\\\\n\\\\n(cid:) webometrics ranking of world universities webometrics\\\\nranking: aims to show “the commitment of the institutions\\\\nto [open access publishing]\\\\nthrough carefully selected\\\\nweb indicators” (http://www.webometrics.info/en/node/,\\\\ndecember , ): hyperlinks from the rest of the web\\\\n(/), website size according to google (/), and the number\\\\n\\\\nof ﬁles in the website in “rich ﬁle formats” according to\\\\ngoogle scholar (/), but also the ﬁeld-normalized number of\\\\narticles in the most highly cited % of scopus publications\\\\n(/)\\\\n(http://www.webometrics.info/en/node/, december\\\\n, ).\\\\n\\\\ncurrent international ranking systems thus use a variety\\\\nof factors in their calculations, including web presence,\\\\nnumber of publications, citations to publications, and peer\\\\njudgments (aguillo, bar-ilan, levene, & ortega, ).\\\\ndespite typically reﬂecting a combination of different\\\\nfactors, as shown earlier, and with different objectives, they\\\\ntend to give similar rankings.']]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_cleaned\n",
    "def clean(data):\n",
    "    data_cleaned=[]\n",
    "    for line in data:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r'\\d+', '', line)\n",
    "        #line = re.sub(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+','', line)\n",
    "        #line = line.translate(str.maketrans('','', string.punctuation))\n",
    "        #line = line.strip()\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        line = line.replace(\"\\\\n\", \"\")\n",
    "        #line = sent_tokenize(line)\n",
    "        \n",
    "        data_cleaned.append(line)\n",
    "    return data_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA1_Data = []\n",
    "for k in range(len(QA1)):\n",
    "    CleanedData = (QA1[k])\n",
    "    CleanedData = clean(CleanedData)\n",
    "    QA1_Data.append(CleanedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA1_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['while broad searches are important to ensure that all ofthe potentially relevant literature is located, such exhaustive searching is costly and time-consuming.perhaps even more troublesome for reviewers is the issue of topic focus because systematic reviews cansometimes aim to examine cross-cutting issues, such as inequalities, in order to draw conclusions which gobeyond the focus of individual primary studies.',\n",
       "  'this technique and the software used (termine; frantzi et al., ) are described in the methods',\n",
       "  'citation chasingor expert recommendations; woodman et al., ), but this may not be sufﬁcient for cross-cutting, diffuse orcomplex topics.a primary goal of a systematic review is to minimise bias when examining the evidence, and an important partof that is the avoidance of systematically missing relevant evidence (higgins and green, ).',\n",
       "  'for example,community engagement interventions cut across many disciplines, topics and outcome domains including housing,transport, social inclusion, accident prevention and substance abuse (popay et al., ).',\n",
       "  'such breadth demands thatreviewers familiarise themselves with the terminology and research sources (journals, archives of research, etc.)',\n",
       "  'ofvaried disciplines.',\n",
       "  'also, searching broadly requires the location and screening of many reports in order to identifya much smaller quantity of relevant research evidence.',\n",
       "  'thus, the main focus of a review often differs signiﬁcantly fromthe questions asked in the primary research it contains; this means that issues of signiﬁcance to the reviewmay not be referred to in the titles and abstracts of the primary studies, even though the primary studies actuallydo enable reviewers to answer the question they are addressing.',\n",
       "  'as an example, primary research is oftenconducted with samples that are predominantly from disadvantaged groups, but the study might not mentionthis in either title or abstract when reducing health inequalities is not the focus of the intervention.',\n",
       "  'relevantevidence is therefore likely to be missed by typical review methods that have an initial screening stage in whichonly titles and abstracts are reviewed.'],\n",
       " ['objective: the goal of this work is to synthesize available research results to inform evidence-basedselection of actionable alert identiﬁcation techniques (aait).method'],\n",
       " ['researchenvironment\\\\xcapplication of distance measurement nlp methods',\n",
       "  ').fig.',\n",
       "  'data in paired addresses would contain a degree ofrelationship-based security based on experience where those addresses that are notlabeled as a “negative” system after some time puts them in properly paired [–](fig.',\n",
       "  'for this particular project researchers had access to partial data taken fromtwo-year history of matching statistics or unsorted shipments from the earlier periodthat was used for learning.',\n",
       "  'research environmentas part of this research proposed model was developed in environment of approx-imately ,, shipments which are handled annually in the express deliverysystem.',\n",
       "  'within the business processes of express delivery severalsystems can beneﬁt from proposed solution: automatic routing of an espresso deliv-ery, inadequate or missing address breaks, dynamic routing of express delivery, moreadequate arrangement of ﬁxed routes, optimization and predicting the time requiredfor each group to deliver shipments, statistics by individual groups and phases (e.g.“at the time of delivery shipment for the exact day”) [–]..',\n",
       "  'mrsicaddress between sender and receiver from the transaction system, address databasewith machine learning elements and the option to systematically learn through a mis-matched return address.',\n",
       "  '), intelligent information and database systems:recent developments, studies in computational intelligence ,https://doi.org/./----_\\\\xcl.',\n",
       "  '(eds.',\n",
       "  'huk et al.'],\n",
       " ['to increase efficiency, twomethods seem promising, which will be tested in the planned study: the use of text mining to prioritize searchresults as well as the involvement of only one person in the study selection process (single-screening approach).the aim of the present study is to examine the following questions related to the process of study selection: canthe use of the rayyan or eppi reviewer tools to prioritize the results of study selection increase efficiency?',\n",
       "  'which advantages or disadvantages (e.g.,shortened screening time or increase in the number of full texts ordered) does a single-screening versus a double-screening approach have?methods',\n",
       "  'howaccurately does a single-screening approach identify relevant studies?',\n",
       "  'background: systematic information retrieval generally requires a two-step selection process for studies, which isconducted by two persons independently of one another (double-screening approach).'],\n",
       " ['() present an overview of research on data deduplication with the aim to provide a general assessment of  useful  references  and  ideas  on  this  topic.',\n",
       "  'from the point of view of expert systems, er is an operational intelligence process, whereby organizations can unify different and heterogeneous data sources in order to match non-obvious enti- ties.',\n",
       "  'it  involves  identifying  entities  from  the  digital  world that refer to the same real-world entity.',\n",
       "  'er process plays a funda- mental role in the context of information integration and manage- ment, aimed to infer a uniform and common structure from var- \\\\xcj.g.',\n",
       "  'enríquez et al.',\n",
       "  '/ expert systems with applications  () –  ious large-scale data collections, with which to suitably organize, match and consolidate the information of the individual reposito- ries into one data set ( costa, cuzzocrea, manco, & ortale,  ).',\n",
       "  'this is a complex problem, since it is not trivial to assert that two heterogeneous data instances represent the same real object.',\n",
       "  'het- erogeneity can happen in data structure as well as in data values ( dorneles, gonçalves, & dos santos mello,  ).',\n",
       "  'this problem can be applied to many different domains such as: e-health, citations, smart cities, meteorological predictions, manufacturing and many other different environments.',\n",
       "  'method'],\n",
       " ['in addition, a complex mixture of chemicals, including heavy metals, naturally-occurringradioactive chemicals, and organic compounds are released from the formations and can enter air and water.compounds associated with uog activity have been linked to adverse reproductive and developmental outcomesin humans and laboratory animal models, which is possibly due to the presence of endocrine active chemicals.methods',\n",
       "  'this process is known to use greater than , chemicals such as solvents, surfactants,detergents, and biocides.',\n",
       "  'this occurred largely because of the development of directional drilling andhydraulic fracturing which allows access to fossil fuels from geologic formations that were previously not costeffective to pursue.',\n",
       "  'background: in the last decade unconventional oil and gas (uog) extraction has rapidly proliferated throughoutthe united states (us) and the world.'],\n",
       " ['objective: this research proposes two training-by-example classiﬁers that are computationally simple, do notrequire extensive training or tuning, ensure inclusion/exclusion consistency, and reduce researcher study se-lection time: one based on vector space models (vsm), and a second based on latent semantic analysis (lsa).method'],\n",
       " ['imple-menting the process of parallelisation will not reducethe costs but it will not increase the risk of bias either(see table ).process parallelisationalthough different steps of a sr can be carried out bytwo reviewers in a linear fashion, where resources permitmany tasks such as study selection, data extraction andquality assessment can be divided amongstseveraltable  the interrelationship between the three approaches tothe conduct of reviews with expected impacts on speed, costsand risk of biasprocessparallelisationmethod',\n",
       "  'possible approaches to address theissue of timeliness in the production of srs are to (a) implement process parallelisation, (b) adapt and applyinnovative technologies, and/or (c) modify sr processes (e.g.',\n",
       "  'often,clinical practice guideline developers or other decision-makers need to make informed decisions in a timely fashion(e.g.',\n",
       "  'however, the conduct of srs can be a time-consuming and resource-intensive task.',\n",
       "  'systematic reviews  () : doi ./s---co m m e n t ar yhow to conduct systematic reviews moreexpeditiously?alexander tsertsvadze*, yen-fu chen, david moher, paul sutcliffe and noel mccarthyopen accessabstracthealthcare consumers, researchers, patients and policy makers increasingly use systematic reviews (srs) to aid theirdecision-making process.',\n",
       "  'accessed on november .\\\\xc tsertsvadze et al.',\n",
       "  '.http://effectivehealthcare.ahrq.gov/index.cfm/search-for-guides-reviews-and-reports/?productid=&pageaction=displayproduct.',\n",
       "  'rockville (md).',\n",
       "  'balk em, chung m, chen ml, trikalinos ta, kong win chang l.assessing the accuracy of google translate to allow data extractionfrom trials published in non-english languages.',\n",
       "  'accessed  november ..'],\n",
       " ['theserequirements will help tool builders ensure they focus their efforts appropriately.method',\n",
       "  'objective to help alleviate some of the barriers in the search phase, we identify and pri-oritize slr search tool requirements based on input from the slr community.'],\n",
       " ['the objective of this paper is to review the use of preprocessing techniques in clinical datasets.',\n",
       "  'methods',\n",
       "  'data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for dm techniques.',\n",
       "  'these challenges lead to a serious bias in predictive modeling and reduce the performance of dm techniques.',\n",
       "  'however, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data.',\n",
       "  'background and objective: datamining (dm) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns.'],\n",
       " ['sms is a secondary study, a specialform ofsystematic review (sr), that reviews primary studies with the aim ofsynthesizing(kitchenham andcharters, ).',\n",
       "  'yet another form of sr is a systematic literature re-view (slr), with the aim to identify, analyze and interpret all availableevidence on speciﬁc research questions.',\n",
       "  'related work',\n",
       "  'the authors ofcruzes and dybå () have also come to similar conclusions: “srsthat involve the transformation of raw data, or that include large numbers ofprimary studies, require greater resources, and where the review questionand/or range of evidence is very broad, it may be necessary to sample.”however, current practices in performing smss (e.g., engström andruneson, ; barney et al., ; ampatzoglou et al., ; kosaret al., c) do not include random sampling, but the inclusion ofprimary studies obtained from two or more digital libraries (dls) withasnowballing(kitchenham et al., ).',\n",
       "  'the diﬀerences between smsand slr are subtle, but important.',\n",
       "  'a good discussion on the diﬀerencesbetween sms and slr can be found in kitchenham et al.',\n",
       "  '().',\n",
       "  'inbrief, slr includes a more comprehensive and thorough investigationof primary studies while pursuing more speciﬁc research questions withhigh requirements of research synthesis (cruzes and dybå, ).furthermore, a quality assessment of the primary studies is necessaryduring slr.',\n",
       "  'according to the guidelinesin kitchenham andcharters (), all relevant studies should be found whilst performingslr.',\n",
       "  'on the other hand, the main goal of smss is to provide an over-view of a broader research topic.'],\n",
       " [' method',\n",
       "  'objective: identify the most performant automated text classification method (e.g., algorithm) for differentiating empirical studies from nonempirical works in order to facilitate systematic mixed studies reviews.'],\n",
       " ['overview',\n",
       "  'overalldiscussion, conclusions and implications on the use of vr in marketingappear in the last two sections..',\n",
       "  'the total market size worldwide for virtual environments(particularly virtual and augmented reality) is expected to move from billion u.s. dollars in  to .',\n",
       "  'billion u.s. dollars in (statista, ), thus showing that there are new market opportunitiesto be explored.research on applied virtual reality (vr) dates back to the swith the work of relevant authors such as milgram, takemura, utsumi,and kishino (), brooks (), slater and wilbur () andsteuer ().',\n",
       "  'milgram et al.',\n",
       "  '(, p. ) propose a taxonomy todiﬀerentiate the technologies available for experiencing combinationsof reality and virtuality and describe vr as the environment “in whichthe participant-observer is totally immersed in a completely syntheticworld, which may or may not mimic the properties of a real-worldenvironment”.',\n",
       "  'from the applications of vr envisaged by brooks ()in the s as a vehicle for simulation and entertainment, the range ofacceptance and use of vr has enlarged considerably and now includes,for example, tourism (e.g., abergel, saleri, bergerot, & de luca, ;jeng, pai, & yeh, ; yeh, wang, li, & lin, ), retailing (e.g.,evans & wurster, ; krasonikolakis, vrechopoulos, & pouloudi,) and medical and educational issues (e.g., abboudi et al., ).several studies show that the product/brand stimuli can come fromconsumers´ experiences in virtual reality (e.g., bigné, llinares, &torrecilla, ; verhagen, vonkeman, feldberg, & verhagen, ;yeh et al., ) with concepts such as attachment, engagement andidentity being induced by virtual objects (e.g., grewal, roggeveen, &nordfalt, ; koles & nagy, ; nagy & koles, ), as well aspurchase behaviours (krasonikolakis et al., ).',\n",
       "  \"thus, studies on thisﬁeld tend to apply the s(stimuli)-o(organism)-r(response) framework(eroglu, machleit, & davis, ; roschk, loureiro, & breitsohl, ).this framework represents the stimuli (as atmospheric cues) inﬂuen-cing consumers' emotional and cognitive states (organism), which, inturn, result in approach or avoidance behaviour (e.g., intention to stay,revisit, purchase or not).the extended adoption of vr technologies is promoting economicgrowth and creating new opportunities (e.g., grewal et al., ;verhagen et al., ).\",\n",
       "  'as these technologies evolve, they tend to in-creasingly inﬂuence marketing and business decisions.',\n",
       "  'this trend leadsto a call for studies revealing the state-of-the-art of research on vr.'],\n",
       " ['methods',\n",
       "  'we also discuss the beneﬁtsand challenges of including this literature in our systematic review, as well as the strengths and limitations toour approach.ainstitute for work & health, toronto, on, canadabfaculty of information, university of toronto, toronto, on, canadacschool of public health and health systems, university of waterloo, waterloo, on, canada*correspondence to: quenby mahood, institute for work & health,  university avenue, suite , toronto, on mg e, canada.†e-mail: qmahood@iwh.on.cacopyright ©  john wiley & sons, ltd.res.',\n",
       "  'where publishingis not the primary activity of the producing body.',\n",
       "  'grey literature may exhibit all or only some of these characteristics,leading to “varying degrees ofagreement and consensus” (tillett and newbold, ) on what it is.greynet, the grey literature network service, provides a deﬁnition:grey literature is a ﬁeld in library and information science that deals with the production, distribution, andaccess to multiple document types produced on alllevels of government, academics, business, andorganization in electronic and print formats not controlled by commercial publishing i.e.',\n",
       "  'the uncertainty comes from some of its core characteristics, such as notproduced for commercial publication, not available through standard distribution means, no standardbibliographic controls, not peer-reviewed, ephemeral and historically difﬁcult to ﬁnd (tillett and newbold,).',\n",
       "  'mahood et al... background information about grey literaturegrey literature is a term that dates back to the s and “refers not to the physical appearance of a document butto the uncertain status of it” (auger, ).',\n",
       "  '\\\\xcq.',\n",
       "  'meth.',\n",
       "  'syn.',\n",
       "  'additionally, this information is important in advancing methodology in this area so that futuresystematic review teams can learn from previous ones.the purpose of this paper is to provide a detailed account of one systematic review team’s experience insearching for grey literature and including it throughout the stages of the review.in this account, based on a systematic review on participatory ergonomics, we provide a brief backgroundabout grey literature before describing our search and review of this literature.'],\n",
       " ['purposemethods'],\n",
       " ['user experiences were collected.methods',\n",
       "  'objectives to examine the effectiveness of the text mining functionality of theabstract screening tool rayyan.'],\n",
       " [\"these sources include bib-liographic databases, reference lists, trials registries, and hand\\\\xc langenbeck's archives of surgery () :–https://doi.org/./s---xoriginal articleoptimal literature search for systematic reviews in surgerykäthe goossen  & solveig tenckhoff  & pascal probst , & kathrin grummich  & andré l. mihaljevic , &markus w. büchler  & markus k. diener ,received:  july  /accepted:  november  /published online:  december # springer-verlag gmbh germany, part of springer nature abstractbackground the aim of the present study was to determine empirically which electronic databases contribute best to a literaturesearch in surgical systematic reviews.methods\",\n",
       "  'the selection is oriented only by generalrecommendations to search multiple classes of sources and allrelevant sources within each class.',\n",
       "  'these sources do not, however, specifywhich databases systematic reviewers should choose beyondthe general statement that bthree bibliographic databases [are]generally considered to be the most important sources tosearch for reports of trials—central, medline andembase.^ the authors’ personal experience in past system-atic literature searches led to the hypothesis that embasemay not be the optimal database for surgical topics of interest.specific guidance for database selection can be found in theliterature for sr in some medical areas [–] but not for sur-gical interventions.',\n",
       "  'evidence-based surgery has become firmly rooted, withincreasing numbers of rct and sr published in the past twodecades.ample methodological research has led to the definition ofrecommendations for the diverse facets of the sr process,compiled in the cochrane handbook and prisma statementand checklist [, ].',\n",
       "  'sr of ran-domized, controlled trials (rct) represent the highest possi-ble level of evidence on the oxford levels of evidence scaleelectronic supplementary material the online version of this article(https://doi.org/./s---x) contains supplementarymaterial, which is available to authorized users.* markus k. dienermarkus.diener@med.uni-heidelberg.destudy center of the german surgical society (sdgc), imneuenheimer feld .,  heidelberg, germany department of general, visceral and transplantation surgery,university hospital heidelberg, im neuenheimer feld , heidelberg, germany[].',\n",
       "  'they are instrumental in transfer-ring research results into evidence-based clinical practiceand ensuring the quality of medical interventions.',\n",
       "  'backgroundsystematic reviews (sr) are a key element of the clinicaldecision-making process.'],\n",
       " ['pre-dicted probabilitiesregression analysis.methods',\n",
       "  'clinical and non-clinical patientcharacteristics) in order to predict future events in indi-viduals, and therefore focus on absolute risks, i.e.',\n",
       "  'out-come prediction studies, on the other hand, combinemultiple factors (e.g.',\n",
       "  'relative risk) of this prognostic factorwhich ideally is adjusted for potential confounders.',\n",
       "  'prognostic factor studies investi-gate causal relationships, or pathways between a single(prognostic) factor and an outcome, and focus on the ef-fect size (e.g.',\n",
       "  'an important dis-tinction in prognosis is made between prognostic factormodels, also called explanatory models and outcome* correspondence: to.vandenberg@vumc.nldepartment of epidemiology and biostatistics and the emgo institute forhealth and care research, vu university medical centre, amsterdam, thenetherlandsfull list of author information is available at the end of the articleprediction models [,].',\n",
       "  'although there is abundant literature tohelp researchers perform this type of research [-],there is still no widely agreed approach to building amultivariable prediction model [].',\n",
       "  'backgroundthe methodology for prognosis research is still underdevelopment.'],\n",
       " ['we synthesised cosmetic inter-vention research evidence covering psychosocial factorsassociated with requesting procedures and psychologicaloutcomes, effects of procedures on psychological out-comes, preintervention assessments for identifying those atrisk, alternative therapy effectiveness, and issuesinachieving informed consent.methods',\n",
       "  'introductionthe rates of cosmetic interventions undertaken in the ukto enhance physical appearance have increased substan-tially over the past decade [, ], with a wider, more\\\\xc aesth plast surg () :–doi ./s---r e v i e wexperimental/special topicspsychosocial predictors, assessment, and outcomes of cosmeticprocedures: a systematic rapid evidence assessmentginny brunton • nicole paraskeva • jenny caird • karen schucan bird •josephine kavanagh • irene kwan • claire stansﬁeld • nichola rumsey •james thomasreceived:  december  / accepted:  june  / published online:  june (cid:) springer science+business media new york and international society of aesthetic plastic surgery abstractbackground recent breast implant complications led to auk government policy review of the evidence concerningcosmetic interventions.'],\n",
       " ['however, there is little work so far on reproduction studies in the ﬁeld.objective: in this paper, we investigate the reproducibility of studies in this area based on informationcontained in published articles and we propose reporting guidelines that could improve reproducibility.methods',\n",
       "  'the application of text miningtechniques to citation screening in the context of systematic literature reviews is a relatively young andgrowing computational ﬁeld with high relevance for software engineering, medical research and otherﬁelds.',\n",
       "  'in computation research, full replication is oftenunrealistic for independent results validation, therefore, study reproduction has been justiﬁed as theminimum acceptable standard to evaluate the validity of scientiﬁc claims.',\n",
       "  'context: independent validation of published scientiﬁc results through study replication is a pre-condition for accepting the validity of such results.'],\n",
       " ['the  main  difference  of  zhang  and  budgen  ()  withrespect  to  this  paper  is  the  aim  of  the  two  literature  reviews.',\n",
       "  'inour  study,  we  do  not  aim  only  on  summarizing  empirical  evidence,but  to  gather  a  broader  dataset,  concerning  gof  design  patternresearch.',\n",
       "  '/  the  journal  of  systems  and  software   () –  #  papers impact  factor/acceptance  rate digital  sourcestable  publication  venues.name annual  computer  software  and  application  conference  (compsac) european  conference  on  software  maintenance  and  reengineering  (csmr)international  conference  on  software  engineering  (icse) international  conference  on  software  maintenance  (icsm) icse   workshops ieee   working  conference  on  reverse  engineering  (wcre) ieee   transactions  on  software  engineering  (tse) journal  of  systems  and  software  (jss) information  and  software  technology  (ist)international  conference  on  automated  software  engineering  (ase) object  oriented  programming,  systems,  languages  and  applications  (oopsla) international  conference  on  program  comprehension  (icpc) ieee   metrics  symposium  (metrics) symposium  on  empirical  software  engineering  and  measurement  (esem) ieee   software  (ieeesoft) empirical  software  engineering  (ese) international  symposium  on  software  reliability  engineering  (issre) acm  sigsoft  symposium  on  foundation  of  software  engineering  (fse)advancements  in  software  engineering  (adse) acm  transactions  on  programming  languages  and  systems  (toplas) fse   workshops journal  of  software:  evolution  and  process software  testing,  veriﬁcation  and  reliability  (stvr) acm  transactions  on  software  engineering  and  method',\n",
       "  'until  now,  researchers  have  attempted  to  evaluate  theuse  of  patterns  with  empirical,  i.e.',\n",
       "  'in  addition  to  that,  we  do  not  only  focus  on  the  effectof  patterns  on  quality  attributes,  but  introduce  gof  design  patternsresearch  subtopics,  as  well..',\n",
       "  'software  quality  attributessoftware  quality  models  are  usually  hierarchical  (dormey,  ;iso,  ).',\n",
       "  'in  this  paper,  we  use  iso/iec    as  referencemodel  for  discussing  the  effect  of  design  patterns  on  softwarequality  (iso,  ).',\n",
       "  'the  ﬁrst  level  of  iso    describes  sixquality  attributes,  i.e.,  portability,  functionality,  reliability,  usabil-ity,  efﬁciency,  and  maintainability,  which  are  further  divided  inseveral  sub-characteristics  as  shown  in  fig.',\n",
       "  '.',\n",
       "  'next,  each  qual-ity  sub-attribute  (low-level  quality  attributes,  such  as  complexity,cohesion,  etc.'],\n",
       " ['an analysis of the publication formats andinformation sources used for four systematic reviews in public health.res synth methods',\n",
       "  ';:.stansfield c, brunton g, rees r. search wide, dig deep: literature searchingfor qualitative research.',\n",
       "  'barbour rs, barbour m. evaluating and synthesising qualitative research: theneed to develop a distinctive approach.',\n",
       "  ';:–..',\n",
       "  'j clin epidemiol.',\n",
       "  'the capture-mark-recapturetechnique can be used as a stopping rule when searching in systematicreviews.',\n",
       "  ';:–.kastner m, straus se, mckibbon ka, goldsmith ch.',\n",
       "  'j adv nurs.',\n",
       "  'protective care-receiving: the activerole of care recipients.',\n",
       "  'russell ck, bunting sm, gregory dm.'],\n",
       " ['research synthesis methods',\n",
       "  'health development agency public health steering group, london.©  the authors.',\n",
       "  'chapter : analysing data and undertaking meta-analyses.',\n",
       "  '.',\n",
       "  ': –.deeks jj, higgins jpt, altman dg.',\n",
       "  'journal of the american medical informantics association.',\n",
       "  'reducing workload in systematic review preparation using automatedcitation classiﬁcation.',\n",
       "  'ihi’, arlington, va, –.cohen a, hersh w, peterson k, yen p. .',\n",
       "  'inproceedings of the st acm international health informatics symposium.',\n",
       "  'evidence-based medicine, the essential role of systematic reviews, and the need for automated text mining tools.'],\n",
       " ['astudy is modelled as a bag-of-words (bow).methods',\n",
       "  'the vast majority of these machine learning methods exploit the same underlying principle, i.e.',\n",
       "  'this framework seeks to identifythe population, the intervention, the comparator andthe outcome.',\n",
       "  'this process is usually performed man-ually, which means that reviewers need to read thou-sands of citations during the screening phase, due to therapid growth of the biomedical literature [], making itan expensive and time-consuming process.',\n",
       "  'according towallace et al.',\n",
       "  '[], an experienced reviewer is able to screen*correspondence: maxmo@gmail.comschool of computer science, national centre for text mining, the university ofmanchester, manchester, uktwo abstracts per minute on average, with more com-plex abstracts taking longer.',\n",
       "  'moreover, a reviewer needsto identify all eligible studies (i.e.',\n",
       "  '– % recall) [, ]in order to minimise publication bias.',\n",
       "  'the number ofrelevant citations is usually significantly lower than thenumber of the irrelevant, which means that reviewershave to deal with an extremely imbalanced datasets.',\n",
       "  'toovercome these limitations, methods such as machinelearning, text mining [, ], text classification [] andactive learning [, ] have been used to partially automatethis process, in order to reduce the workload, withoutsacrificing the quality of the reviews.'],\n",
       " ['presumably, this total (and the three totalsthat will be given) includes all articles with at least one authorfrom the institution, and articles with multiple authors fromthe same institution are only counted once.(cid:) publications (from the institutional homepage): the numberof publications listed in members’ proﬁles.(cid:) downloads (from the institution stats page): the number ofdownloads of the institutions’ publications in the previousweek.(cid:) views (from the institution stats page): the number of viewsof the institutions’ publication information pages in the pre-vious week.publication statistics for each country were obtained bysearching in october  for journal articles published in in the wos and restricting the results to just the countryin question.methods',\n",
       "  'for example, one is“the proportion of the publications of a university that, com-pared with other publications in the same ﬁeld and in the sameyear, belong to the top % most frequently cited” andanother is “the average number of citations of the publicationsof a university, normalized for ﬁeld differences and pub-lication year” (http://www.leidenranking.com/methodology/indicators, december , ).',\n",
       "  'this can startfrom attempting to get articles published in high-proﬁlejournals or conferences, but may also include depositingthem in institutional or subject repositories, advertisingthem in listservs and social media, listing them in onlinecurricula vitae (cvs), and listing or depositing them in aca-demic social network sites, including researchgate.',\n",
       "  'whilesome authors may believe that their work only needs to belisted in one place in order that other researchers may beable to ﬁnd it, each additional listing of their work is anotherchance for it to be found, especially by scholars who do notconduct extensive literature searches or who just use ageneral search engine (haglund & olsson, ).',\n",
       "  'if anauthor chooses to self-archive in only one place, then theirchoice of venue probably depends upon familiarity with theavailable options as well as ﬁeld and institutional norms.',\n",
       "  'itmay also be that archiving in researchgate or other sites issometimes conducted by administrators on behalf of aca-demics, if an institution believes that it is important.assuming that the increased visibility beneﬁts of listingpublications in multiple places online outweigh the cost ofthe time taken to register them, individuals and organiza-tions that adapt to new methods of disseminating researchonline seem likely to gain increased recognition.',\n",
       "  'this mul-tiple online availability of research can presumably increasecitation impact (xia, myers, & wilhoite, ).institutional rankingsalthough research impact metrics can be used to evaluateindividual academics, metrics for education, research, andprestige are also used to rank and compare institutions.',\n",
       "  'thereare currently several international ranking schemes for uni-versities, some of which use citations to an institution’sarticles to estimate its impact (buela-casal, gutiérrez-martínez, bermúdez-sánchez, & vadillo-muñoz, ).nevertheless,there have been debates about whetherjournal of the association for information science and technology—(cid:)(cid:) doi: ./asi\\\\xcbibliometric methods should be used for ranking academicinstitutions (e.g., van raan ; ioannidis et al., ).there are ﬁve well-known institutional ranking schemes:(cid:) qs world university rankings: aims to rank “the world’s topuniversities” based on academic reputation (%, from aglobal survey), employer reputation (%, from a globalsurvey), faculty-student ratio (%), citations per faculty(%,internationalstudents (%), and the proportion of international faculty(%)(http://www.iu.qs.com/university-rankings/world-university-rankings/, december , ).the proportion offrom scopus),(cid:) the times higher education (the) world university rank-ings: aims “to judge world class universities across all of theircore missions—teaching, research, knowledge transfer andinternational outlook” (http://www.timeshighereducation.co.uk/world-university-rankings/-/world-ranking,december , ) using the web of science (wos), aninternational survey of senior academics and self-reporteddata.',\n",
       "  'the results are based on ﬁeld-normalized citations for years of publications (%), research reputation from asurvey (%), teaching reputation (%), various indicatorsof the quality of the learning environment (%), ﬁeld-normalized publications per faculty (%), ﬁeld-normalizedincome per faculty (%), income from industry per faculty(.%); and indicators for the proportion of internationalstaff (.%), students (.%), and internationally coauthoredpublications(http://www.timeshighereducation.co.uk/world-university-rankings/-/world-ranking/methodology, december , ).ﬁeld-normalized)(.%,(cid:) academic ranking of world universities (arwu): aims torank the “world top  universities” based on “the number ofalumni and staff winning nobel prizes and fields medals,number of highly cited researchers selected by thomsonscientiﬁc, number of articles published in journals of natureand science, number of articles indexed in science citationindex—expanded and social sciences citation index,and per capita performance with respectto the size ofan institution” (http://www.shanghairanking.com/aboutarwu.html, december , ).(cid:) cwts leiden ranking: aims to measure “the scientiﬁc per-formance” of universities using bibliometric indicators basedon wos data through a series of separate size- and ﬁeld-normalized indicators for different aspects of performancerather than a combined overall ranking.',\n",
       "  'these are perhaps the mostsophisticated indicators, both in the nature of the calculationsand in the data cleaning for the indicators but only reﬂectresearch performance aspects of a university.(cid:) webometrics ranking of world universities webometricsranking: aims to show “the commitment of the institutionsto [open access publishing]through carefully selectedweb indicators” (http://www.webometrics.info/en/node/,december , ): hyperlinks from the rest of the web(/), website size according to google (/), and the numberof ﬁles in the website in “rich ﬁle formats” according togoogle scholar (/), but also the ﬁeld-normalized number ofarticles in the most highly cited % of scopus publications(/)(http://www.webometrics.info/en/node/, december, ).current international ranking systems thus use a varietyof factors in their calculations, including web presence,number of publications, citations to publications, and peerjudgments (aguillo, bar-ilan, levene, & ortega, ).despite typically reﬂecting a combination of differentfactors, as shown earlier, and with different objectives, theytend to give similar rankings.']]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA1_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to save the pdf name and the respective answers for the QA1\n",
    "#Is the aim and the objective stated clearly\n",
    "QA1_Ans = {'PDFName': [], 'QA1_ans': [] }\n",
    "for c,d in zip(files, QA1_Data):    \n",
    "    QA1_Ans['PDFName'].append(c)\n",
    "    QA1_Ans['QA1_ans'].append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the answers to the QA1 to .xslx\n",
    "from pandas import DataFrame\n",
    "\n",
    "df1 = DataFrame(QA1_Ans, columns= ['PDFName', 'QA1_ans'])\n",
    "export_excel = df1.to_excel (r'E:\\MasterThesis\\FinalPapers\\excel_QA\\QA1_Answer.xlsx', index = None, header=True) #Don't forget to add '.xlsx' at the end of the path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
